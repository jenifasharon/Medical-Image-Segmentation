import os
os.listdir("/kaggle/input")
import os
import pandas as pd
import re

# ==============================
# Paths
# ==============================
AUG_BASE = "/kaggle/input/sample/AUGMENTED/DATASET_FINAL"
NOAUG_BASE = "/kaggle/input/sample/NOT-AUGMENTED/DATASET_FINAL"

AUG_IMG_DIR = os.path.join(AUG_BASE, "JPEGImages")
AUG_MASK_DIR = os.path.join(AUG_BASE, "Annotations")

NOAUG_IMG_DIR = os.path.join(NOAUG_BASE, "JPEGImages")
NOAUG_MASK_DIR = os.path.join(NOAUG_BASE, "Annotations")

# ==============================
# Extract slice key
# slice_case_00010_17_aug3.jpg â†’ slice_case_00010_17
# ==============================
def get_slice_key(fname):
    m = re.match(r"(slice_case_\d+_\d+)", fname)
    return m.group(1) if m else None

def list_files(folder):
    return [f for f in os.listdir(folder) if f.lower().endswith((".png",".jpg",".jpeg"))]

def verify_pairs(img_dir, mask_dir, tag):
    img_files = list_files(img_dir)
    mask_files = list_files(mask_dir)

    img_map = {}
    for f in img_files:
        key = get_slice_key(f)
        if key:
            img_map.setdefault(key, []).append(f)

    mask_map = {}
    for f in mask_files:
        key = get_slice_key(f)
        if key:
            mask_map[key] = f

    valid_pairs = []
    unpaired_images = []
    unpaired_masks = []

    for key, imgs in img_map.items():
        if key in mask_map:
            for img in imgs:   # multiple augmented images â†’ one mask
                valid_pairs.append({
                    "image": os.path.join(img_dir, img),
                    "mask": os.path.join(mask_dir, mask_map[key])
                })
        else:
            unpaired_images.extend(imgs)

    for key, mask in mask_map.items():
        if key not in img_map:
            unpaired_masks.append(mask)

    df = pd.DataFrame(valid_pairs)
    df.to_csv(f"valid_image_mask_pairs_{tag}.csv", index=False)

    print(f"\n===== {tag.upper()} IMAGEâ€“MASK PAIRING SUMMARY =====")
    print("Total images        :", len(img_files))
    print("Total masks         :", len(mask_files))
    print("Valid matched pairs :", len(df))
    print("Unpaired images     :", len(unpaired_images))
    print("Unpaired masks      :", len(unpaired_masks))

    return df

# ==============================
# Run
# ==============================
aug_df = verify_pairs(AUG_IMG_DIR, AUG_MASK_DIR, "kits23_augmented")
noaug_df = verify_pairs(NOAUG_IMG_DIR, NOAUG_MASK_DIR, "kits23_not_augmented")

print("\n===== OVERALL KiTS23 SUMMARY =====")
print("Augmented valid pairs     :", len(aug_df))
print("Not-augmented valid pairs :", len(noaug_df))
print("Total valid pairs         :", len(aug_df) + len(noaug_df))
print("\nFiles generated:")
print(" - valid_image_mask_pairs_kits23_augmented.csv")
print(" - valid_image_mask_pairs_kits23_not_augmented.csv")
print(" - unpaired_images_kits23_augmented.txt")
print(" - unpaired_masks_kits23_augmented.txt")
print(" - unpaired_images_kits23_not_augmented.txt")
print(" - unpaired_masks_kits23_not_augmented.txt")
import os
import pandas as pd
import re
from sklearn.model_selection import train_test_split

# ==============================
# Paths
# ==============================
AUG_BASE   = "/kaggle/input/sample/AUGMENTED/DATASET_FINAL"
NOAUG_BASE = "/kaggle/input/sample/NOT-AUGMENTED/DATASET_FINAL"

AUG_IMG_DIR   = os.path.join(AUG_BASE, "JPEGImages")
AUG_MASK_DIR  = os.path.join(AUG_BASE, "Annotations")

NOAUG_IMG_DIR  = os.path.join(NOAUG_BASE, "JPEGImages")
NOAUG_MASK_DIR = os.path.join(NOAUG_BASE, "Annotations")

# ==============================
# Helpers
# ==============================
def get_slice_key(fname):
    # slice_case_00010_17_aug3.jpg â†’ slice_case_00010_17
    m = re.match(r"(slice_case_\d+_\d+)", fname)
    return m.group(1) if m else None

def get_patient_id(slice_key):
    # slice_case_00010_17 â†’ 00010
    return slice_key.split("_")[2]

def list_files(folder):
    return [f for f in os.listdir(folder)
            if f.lower().endswith((".png", ".jpg", ".jpeg"))]

def build_pairs(img_dir, mask_dir):
    img_files  = list_files(img_dir)
    mask_files = list_files(mask_dir)

    img_map = {}
    for f in img_files:
        key = get_slice_key(f)
        if key:
            img_map.setdefault(key, []).append(f)

    mask_map = {}
    for f in mask_files:
        key = get_slice_key(f)
        if key:
            mask_map[key] = f

    pairs = []
    for key, imgs in img_map.items():
        if key in mask_map:
            pid = get_patient_id(key)
            for img in imgs:  # augmented â†’ many images, one mask
                pairs.append({
                    "patient_id": pid,
                    "slice_key": key,
                    "image": os.path.join(img_dir, img),
                    "mask":  os.path.join(mask_dir, mask_map[key])
                })

    return pd.DataFrame(pairs)

# ==============================
# 1) TRAINING â†’ AUGMENTED ONLY
# ==============================
train_df = build_pairs(AUG_IMG_DIR, AUG_MASK_DIR)
train_df.to_csv("train_pairs_augmented.csv", index=False)

print("\n===== TRAINING (AUGMENTED ONLY) =====")
print("Patients :", train_df.patient_id.nunique())
print("Pairs    :", len(train_df))

# ==============================
# 2) VALIDATION + TEST â†’ NON-AUGMENTED
# ==============================
eval_df = build_pairs(NOAUG_IMG_DIR, NOAUG_MASK_DIR)

# Patient-wise split (example: 50% val / 50% test)
patients = sorted(eval_df.patient_id.unique())
val_pat, test_pat = train_test_split(
    patients, test_size=0.5, random_state=42
)

val_df  = eval_df[eval_df.patient_id.isin(val_pat)]
test_df = eval_df[eval_df.patient_id.isin(test_pat)]

val_df.to_csv("val_pairs_not_augmented.csv", index=False)
test_df.to_csv("test_pairs_not_augmented.csv", index=False)

print("\n===== QUANTITATIVE ANALYSIS (NON-AUGMENTED) =====")
print("Validation patients :", val_df.patient_id.nunique())
print("Validation pairs    :", len(val_df))
print("Test patients       :", test_df.patient_id.nunique())
print("Test pairs          :", len(test_df))

# ==============================
# Summary
# ==============================
print("\n===== FINAL SPLIT SUMMARY =====")
print("Training (augmented) pairs :", len(train_df))
print("Validation (non-aug) pairs :", len(val_df))
print("Test (non-aug) pairs       :", len(test_df))

print("\nFiles generated:")
print(" - train_pairs_augmented.csv")
print(" - val_pairs_not_augmented.csv")
print(" - test_pairs_not_augmented.csv")
import os
import pandas as pd
import re
from sklearn.model_selection import train_test_split

# ==============================
# Dataset paths
# ==============================
AUG_IMG_DIR   = "/kaggle/input/sample/AUGMENTED/DATASET_FINAL/JPEGImages"
AUG_MASK_DIR  = "/kaggle/input/sample/AUGMENTED/DATASET_FINAL/Annotations"

NOAUG_IMG_DIR  = "/kaggle/input/sample/NOT-AUGMENTED/DATASET_FINAL/JPEGImages"
NOAUG_MASK_DIR = "/kaggle/input/sample/NOT-AUGMENTED/DATASET_FINAL/Annotations"

# ==============================
# Helpers
# ==============================
def get_slice_key(fname):
    # slice_case_00010_17_aug2.png â†’ slice_case_00010_17
    m = re.match(r"(slice_case_\d+_\d+)", fname)
    return m.group(1) if m else None

def get_patient_id(slice_key):
    # slice_case_00010_17 â†’ 00010
    return slice_key.split("_")[2]

def build_pairs(img_dir, mask_dir):
    images = [f for f in os.listdir(img_dir)
              if f.lower().endswith((".png",".jpg",".jpeg"))]
    masks  = [f for f in os.listdir(mask_dir)
              if f.lower().endswith((".png",".jpg",".jpeg"))]

    img_map = {}
    for f in images:
        key = get_slice_key(f)
        if key:
            img_map.setdefault(key, []).append(f)

    mask_map = {}
    for f in masks:
        key = get_slice_key(f)
        if key:
            mask_map[key] = f

    pairs = []
    for key, imgs in img_map.items():
        if key in mask_map:
            pid = get_patient_id(key)
            for img in imgs:
                pairs.append({
                    "patient_id": pid,
                    "image": os.path.join(img_dir, img),
                    "mask":  os.path.join(mask_dir, mask_map[key])
                })

    return pd.DataFrame(pairs)

# =====================================================
# 1) TRAINING â†’ AUGMENTED ONLY
# =====================================================
train_df = build_pairs(AUG_IMG_DIR, AUG_MASK_DIR)

print("\n===== TRAINING (AUGMENTED ONLY) =====")
print("Pairs    :", len(train_df))
print("Patients :", train_df.patient_id.nunique())

train_df.to_csv("train_augmented_patientwise.csv", index=False)

# =====================================================
# 2) VALIDATION + TEST â†’ NON-AUGMENTED ONLY
# =====================================================
eval_df = build_pairs(NOAUG_IMG_DIR, NOAUG_MASK_DIR)

print("\n===== NON-AUGMENTED DATA =====")
print("Pairs    :", len(eval_df))
print("Patients :", eval_df.patient_id.nunique())

# ------------------------------
# Patient-wise split (50 / 50)
# ------------------------------
patients = sorted(eval_df.patient_id.unique())

val_pat, test_pat = train_test_split(
    patients, test_size=0.5, random_state=42
)

val_df  = eval_df[eval_df.patient_id.isin(val_pat)].reset_index(drop=True)
test_df = eval_df[eval_df.patient_id.isin(test_pat)].reset_index(drop=True)

# =====================================================
# Final summary
# =====================================================
print("\n===== FINAL DATASET SPLIT =====")
print("Training (augmented) :", len(train_df))
print("Validation (non-aug) :", len(val_df))
print("Test (non-aug)       :", len(test_df))

print("\n===== PATIENT COUNTS =====")
print("Train patients :", train_df.patient_id.nunique())
print("Val patients   :", len(val_pat))
print("Test patients  :", len(test_pat))

# ==============================
# Save CSVs
# ==============================
val_df.to_csv("val_not_augmented_patientwise.csv", index=False)
test_df.to_csv("test_not_augmented_patientwise.csv", index=False)

print("\nCSV files saved successfully.")
def print_patient_range(name, patients):
    patients = sorted(patients)
    print(f"{name} patients (range): {patients[0]} to {patients[-1]}")
    print(f"{name} patients (count): {len(patients)}\n")

print("\n===== PATIENT ID RANGES =====")
print_patient_range("Train", train_df.patient_id.unique())
print_patient_range("Validation", val_pat)
print_patient_range("Test", test_pat)
import os
import re
import pandas as pd
from sklearn.model_selection import train_test_split

# ======================================================
# PATHS
# ======================================================
AUG_IMG_DIR   = "/kaggle/input/sample/AUGMENTED/DATASET_FINAL/JPEGImages"
AUG_MASK_DIR  = "/kaggle/input/sample/AUGMENTED/DATASET_FINAL/Annotations"

NOAUG_IMG_DIR  = "/kaggle/input/sample/NOT-AUGMENTED/DATASET_FINAL/JPEGImages"
NOAUG_MASK_DIR = "/kaggle/input/sample/NOT-AUGMENTED/DATASET_FINAL/Annotations"

# ======================================================
# HELPERS
# ======================================================
def get_slice_key(fname):
    # slice_case_00010_17_aug2.png â†’ slice_case_00010_17
    m = re.match(r"(slice_case_\d+_\d+)", fname)
    return m.group(1) if m else None

def get_patient_id(fname):
    return fname.split("_")[2]

def build_pairs(img_dir, mask_dir):
    imgs = [f for f in os.listdir(img_dir) if f.lower().endswith((".png",".jpg",".jpeg"))]
    masks = [f for f in os.listdir(mask_dir) if f.lower().endswith((".png",".jpg",".jpeg"))]

    img_map = {}
    for f in imgs:
        key = get_slice_key(f)
        if key:
            img_map.setdefault(key, []).append(f)

    mask_map = {}
    for f in masks:
        key = get_slice_key(f)
        if key:
            mask_map[key] = f

    pairs = []
    unpaired_imgs = []

    for key, files in img_map.items():
        if key in mask_map:
            pid = get_patient_id(files[0])
            for img in files:
                pairs.append({
                    "patient_id": pid,
                    "image": os.path.join(img_dir, img),
                    "mask": os.path.join(mask_dir, mask_map[key])
                })
        else:
            unpaired_imgs.extend(files)

    return pd.DataFrame(pairs), unpaired_imgs

# ======================================================
# 1) TRAINING â†’ AUGMENTED ONLY
# ======================================================
train_df, _ = build_pairs(AUG_IMG_DIR, AUG_MASK_DIR)

# ======================================================
# 2) VALIDATION + TEST â†’ NON-AUGMENTED ONLY
# ======================================================
eval_df, unpaired_images = build_pairs(NOAUG_IMG_DIR, NOAUG_MASK_DIR)

# ======================================================
# PATIENT-WISE SPLIT (50 / 50)
# ======================================================
patients = sorted(eval_df.patient_id.unique())
val_pat, test_pat = train_test_split(patients, test_size=0.5, random_state=42)

val_df  = eval_df[eval_df.patient_id.isin(val_pat)].reset_index(drop=True)
test_df = eval_df[eval_df.patient_id.isin(test_pat)].reset_index(drop=True)

# ======================================================
# PRINT PATIENT RANGE + COUNT + SLICE COUNT
# ======================================================
def print_summary(name, df=None, patients=None):
    if df is not None:
        pats = sorted(df.patient_id.unique())
        slices = len(df)
    else:
        pats = sorted(patients)
        slices = eval_df[eval_df.patient_id.isin(pats)].shape[0]

    print(f"{name} patients (range): {pats[0]} to {pats[-1]}")
    print(f"{name} patients (count): {len(pats)}")
    print(f"{name} slices (count): {slices}\n")

print("\n===== FINAL PATIENT-WISE SUMMARY =====")
print_summary("Train (augmented)", df=train_df)
print_summary("Validation (non-aug)", patients=val_pat)
print_summary("Test (non-aug)", patients=test_pat)

# ======================================================
# SAVE PATIENT ID LISTS (IMPORTANT)
# ======================================================
pd.Series(sorted(train_df.patient_id.unique())).to_csv(
    "train_patients.txt", index=False, header=False
)
pd.Series(sorted(val_pat)).to_csv(
    "val_patients.txt", index=False, header=False
)
pd.Series(sorted(test_pat)).to_csv(
    "test_patients.txt", index=False, header=False
)

# ======================================================
# FINAL CHECK
# ======================================================
print("Valid non-augmented pairs :", len(eval_df))
print("Unpaired non-augmented images :", len(unpaired_images))
print("Validation + Test slices :", len(val_df) + len(test_df))

print("\nFiles saved:")
print(" - train_patients.txt")
print(" - val_patients.txt")
print(" - test_patients.txt")

# ======================================================
# PATIENT ID LISTS (FULL, NOT RANGES)
# ======================================================

train_patients = sorted(train_df.patient_id.unique())
val_patients   = sorted(val_pat)
test_patients  = sorted(test_pat)

print("\n===== PATIENT ID LISTS =====")

print(f"\nTraining patients (n={len(train_patients)}):")
print(train_patients)

print(f"\nValidation patients (n={len(val_patients)}):")
print(val_patients)

print(f"\nTest patients (n={len(test_patients)}):")
print(test_patients)

# ======================================================
# SAVE PATIENT ID LISTS (PLAIN TEXT â€“ IMPORTANT)
# ======================================================
pd.Series(train_patients).to_csv(
    "train_patients.txt", index=False, header=False
)
pd.Series(val_patients).to_csv(
    "val_patients.txt", index=False, header=False
)
pd.Series(test_patients).to_csv(
    "test_patients.txt", index=False, header=False
)

print("\nPatient ID files saved:")
print(" - train_patients.txt")
print(" - val_patients.txt")
print(" - test_patients.txt")
import os
import re
import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt
import albumentations as A

# ======================================================
# PATHS
# ======================================================
AUG_IMG_DIR   = "/kaggle/input/sample/AUGMENTED/DATASET_FINAL/JPEGImages"
AUG_MASK_DIR  = "/kaggle/input/sample/AUGMENTED/DATASET_FINAL/Annotations"

NOAUG_IMG_DIR  = "/kaggle/input/sample/NOT-AUGMENTED/DATASET_FINAL/JPEGImages"
NOAUG_MASK_DIR = "/kaggle/input/sample/NOT-AUGMENTED/DATASET_FINAL/Annotations"

# ======================================================
# HELPERS
# ======================================================
def get_slice_key(fname):
    # slice_case_00010_17_aug2.jpg â†’ slice_case_00010_17
    m = re.match(r"(slice_case_\d+_\d+)", fname)
    return m.group(1) if m else None

def build_df(img_dir, mask_dir):
    imgs  = [f for f in os.listdir(img_dir)
             if f.lower().endswith((".png",".jpg",".jpeg"))]
    masks = [f for f in os.listdir(mask_dir)
             if f.lower().endswith((".png",".jpg",".jpeg"))]

    img_map = {}
    for f in imgs:
        key = get_slice_key(f)
        if key:
            img_map.setdefault(key, []).append(f)

    mask_map = {}
    for f in masks:
        key = get_slice_key(f)
        if key:
            mask_map[key] = f

    rows = []
    for key, files in img_map.items():
        if key in mask_map:
            for img in files:
                rows.append({
                    "img_path": os.path.join(img_dir, img),
                    "mask_path": os.path.join(mask_dir, mask_map[key])
                })

    return pd.DataFrame(rows)

# ======================================================
# 1) TRAINING DATA â†’ AUGMENTED ONLY
# ======================================================
train_df = build_df(AUG_IMG_DIR, AUG_MASK_DIR)
print("Training (augmented) slices:", len(train_df))

# ======================================================
# 2) EVALUATION DATA â†’ NON-AUGMENTED ONLY
# ======================================================
eval_df = build_df(NOAUG_IMG_DIR, NOAUG_MASK_DIR)
print("Evaluation (non-augmented) slices:", len(eval_df))

# ======================================================
# DISPLAY ORIGINAL TRAINING SAMPLES
# ======================================================
def display_samples(df, num_samples=5, title_prefix=""):
    num_samples = min(num_samples, len(df))
    indices = np.random.choice(df.index, size=num_samples, replace=False)

    fig, axes = plt.subplots(num_samples, 2, figsize=(10, num_samples * 3))
    for i, idx in enumerate(indices):
        img = cv2.imread(df.loc[idx, "img_path"])
        mask = cv2.imread(df.loc[idx, "mask_path"], cv2.IMREAD_GRAYSCALE)

        axes[i, 0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        axes[i, 0].set_title(f"{title_prefix} Image")
        axes[i, 0].axis("off")

        axes[i, 1].imshow(mask, cmap="gray")
        axes[i, 1].set_title(f"{title_prefix} Mask")
        axes[i, 1].axis("off")

    plt.tight_layout()
    plt.show()

display_samples(train_df, num_samples=5, title_prefix="Train (Aug)")

# ======================================================
# AUGMENTATION PIPELINE (TRAINING ONLY)
# ======================================================
augmentation = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.5),
    A.Rotate(limit=15, p=0.5),
    A.RandomBrightnessContrast(p=0.3),
    A.ElasticTransform(alpha=1, sigma=40, alpha_affine=30, p=0.2),
])

def augment_image(image_path, mask_path):
    image = cv2.imread(image_path)
    mask  = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    aug = augmentation(image=image, mask=mask)
    return aug["image"], aug["mask"]

# ======================================================
# DISPLAY AUGMENTED TRAINING SAMPLES
# ======================================================
def display_augmented_samples(df, num_samples=5):
    num_samples = min(num_samples, len(df))
    indices = np.random.choice(df.index, size=num_samples, replace=False)

    fig, axes = plt.subplots(num_samples, 4, figsize=(16, num_samples * 3))
    for i, idx in enumerate(indices):
        img = cv2.imread(df.loc[idx, "img_path"])
        mask = cv2.imread(df.loc[idx, "mask_path"], cv2.IMREAD_GRAYSCALE)
        aug_img, aug_mask = augment_image(
            df.loc[idx, "img_path"],
            df.loc[idx, "mask_path"]
        )

        axes[i, 0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        axes[i, 0].set_title("Original Image")
        axes[i, 0].axis("off")

        axes[i, 1].imshow(mask, cmap="gray")
        axes[i, 1].set_title("Original Mask")
        axes[i, 1].axis("off")

        axes[i, 2].imshow(cv2.cvtColor(aug_img, cv2.COLOR_BGR2RGB))
        axes[i, 2].set_title("Augmented Image")
        axes[i, 2].axis("off")

        axes[i, 3].imshow(aug_mask, cmap="gray")
        axes[i, 3].set_title("Augmented Mask")
        axes[i, 3].axis("off")

    plt.tight_layout()
    plt.show()

display_augmented_samples(train_df, num_samples=5)

# ======================================================
# DISPLAY NON-AUGMENTED EVALUATION SAMPLES (NO AUG)
# ======================================================
display_samples(eval_df, num_samples=5, title_prefix="Eval (Non-Aug)")

import os
import re
import numpy as np
import cv2
import matplotlib.pyplot as plt
import albumentations as A
from sklearn.manifold import TSNE
import umap
from sklearn.decomposition import PCA
import random

# ======================================================
# PATHS
# ======================================================
AUG_IMG_DIR   = "/kaggle/input/sample/AUGMENTED/DATASET_FINAL/JPEGImages"
NOAUG_IMG_DIR = "/kaggle/input/sample/NOT-AUGMENTED/DATASET_FINAL/JPEGImages"

# ======================================================
# HELPERS
# ======================================================
def get_slice_key(fname):
    m = re.match(r"(slice_case_\d+_\d+)", fname)
    return m.group(1) if m else None

def load_images(img_dir, max_samples=None):
    files = [f for f in os.listdir(img_dir)
             if f.lower().endswith((".png",".jpg",".jpeg"))]
    if max_samples:
        files = random.sample(files, min(max_samples, len(files)))

    images = []
    for f in files:
        img = cv2.imread(os.path.join(img_dir, f))
        if img is not None:
            images.append(img)
    return images

# ======================================================
# STEP 1: PREPROCESSING FUNCTIONS
# ======================================================
def apply_clahe(image):
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l = clahe.apply(l)
    lab = cv2.merge((l, a, b))
    return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)

def apply_histogram_equalization(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    eq = cv2.equalizeHist(gray)
    return cv2.cvtColor(eq, cv2.COLOR_GRAY2BGR)

# ======================================================
# STEP 2: AUGMENTATION (TRAINING ONLY)
# ======================================================
augmentation = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.5),
    A.Rotate(limit=20, p=0.5),
    A.RandomBrightnessContrast(p=0.3),
    A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.3),
    A.OneOf([
        A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.5),
        A.Equalize(p=0.5)
    ], p=0.5)
])

def augment_image(image):
    return augmentation(image=image)["image"]

# ======================================================
# STEP 3: DISPLAY PREPROCESSING (TRAINING ONLY)
# ======================================================
def display_preprocessing_stages(image1, image2):
    fig, axes = plt.subplots(2, 4, figsize=(20, 10))

    for i, img in enumerate([image1, image2]):
        clahe_img = apply_clahe(img)
        hist_img  = apply_histogram_equalization(img)
        aug_img   = augment_image(img)

        images = [img, clahe_img, hist_img, aug_img]
        titles = ["Original", "CLAHE", "Histogram Eq.", "Augmented"]

        for j, ax in enumerate(axes[i]):
            ax.imshow(cv2.cvtColor(images[j], cv2.COLOR_BGR2RGB))
            ax.set_title(f"Train Image {i+1} â€“ {titles[j]}")
            ax.axis("off")

    plt.tight_layout()
    plt.show()

# ======================================================
# STEP 4: t-SNE / UMAP VISUALIZATION
# ======================================================
def visualize_distribution(images, title, method="tsne"):
    images = np.array(images)
    images = images.reshape(images.shape[0], -1)

    images_pca = PCA(n_components=min(50, images.shape[1])).fit_transform(images)

    if method == "tsne":
        reducer = TSNE(n_components=2, perplexity=min(30, len(images)-1), random_state=42)
    else:
        reducer = umap.UMAP(n_components=2, random_state=42)

    reduced = reducer.fit_transform(images_pca)

    plt.figure(figsize=(7, 6))
    plt.scatter(reduced[:, 0], reduced[:, 1], alpha=0.7)
    plt.title(f"{method.upper()} â€“ {title}")
    plt.xlabel("Component 1")
    plt.ylabel("Component 2")
    plt.show()

# ======================================================
# STEP 5: TRAINING DATA (AUGMENTED)
# ======================================================
train_images = load_images(AUG_IMG_DIR, max_samples=50)

if len(train_images) < 2:
    raise ValueError("Not enough training images.")

# Display preprocessing on training samples
display_preprocessing_stages(train_images[0], train_images[1])

# Prepare training images for embedding
train_vis = [cv2.resize(img, (64, 64)) / 255.0 for img in train_images]

visualize_distribution(train_vis, "Training (Augmented)", method="tsne")
visualize_distribution(train_vis, "Training (Augmented)", method="umap")

# ======================================================
# STEP 6: EVALUATION DATA (NON-AUGMENTED â€“ NO AUG)
# ======================================================
eval_images = load_images(NOAUG_IMG_DIR, max_samples=50)

eval_vis = [cv2.resize(img, (64, 64)) / 255.0 for img in eval_images]

visualize_distribution(eval_vis, "Evaluation (Non-Augmented)", method="tsne")
visualize_distribution(eval_vis, "Evaluation (Non-Augmented)", method="umap")
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np

def create_image_generator(data_frame,
                           batch_size=4,
                           image_color_mode="rgb",
                           mask_color_mode="grayscale",
                           target_size=(256, 256),
                           augment=False,
                           seed=42):

    # --------------------------
    # Normalization
    # --------------------------
    def normalize(img, mask):
        img = img.astype("float32") / 255.0
        mask = mask.astype("float32") / 255.0
        mask = (mask > 0.5).astype("float32")
        return img, mask

    # --------------------------
    # Data generators
    # --------------------------
    if augment:
        img_datagen = ImageDataGenerator(
            rotation_range=15,
            horizontal_flip=True,
            vertical_flip=True,
            zoom_range=0.1
        )
        mask_datagen = ImageDataGenerator(
            rotation_range=15,
            horizontal_flip=True,
            vertical_flip=True,
            zoom_range=0.1
        )
    else:
        img_datagen = ImageDataGenerator()
        mask_datagen = ImageDataGenerator()

    # --------------------------
    # Flow from dataframe
    # --------------------------
    img_gen = img_datagen.flow_from_dataframe(
        dataframe=data_frame,
        x_col="img_path",
        class_mode=None,
        color_mode=image_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        shuffle=True,
        seed=seed
    )

    mask_gen = mask_datagen.flow_from_dataframe(
        dataframe=data_frame,
        x_col="mask_path",
        class_mode=None,
        color_mode=mask_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        shuffle=True,
        seed=seed
    )

    # --------------------------
    # Yield paired batches
    # --------------------------
    while True:
        img = next(img_gen)
        mask = next(mask_gen)
        yield normalize(img, mask)
batch_size = 4  # you can increase safely now

train_generator = create_image_generator(
    train_df,
    batch_size=batch_size,
    augment=True
)

val_generator = create_image_generator(
    val_df,
    batch_size=batch_size,
    augment=False
)

test_generator = create_image_generator(
    test_df,
    batch_size=batch_size,
    augment=False
)

# Test one batch
x_batch, y_batch = next(train_generator)
print("Image batch shape:", x_batch.shape)
print("Mask batch shape :", y_batch.shape)

EPOCHS = 35        # keep very low, only for checking pipeline
BATCH_SIZE = 32    # MUST be 1 because dataset has only one sample
learning_rate = 1e-4
w, h = 256, 256   # keep same size as generator target_sizeEPOCHS = 35        # keep very low, only for checking pipelineimport tensorflow as tf
from tensorflow.keras import layers, Model, backend as K
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Input, SeparableConv2D, MaxPooling2D, Conv2DTranspose, Concatenate, GroupNormalization
import os
from sklearn.model_selection import train_test_split

# -----------------------------
# GPU / Optimization
# -----------------------------
tf.keras.mixed_precision.set_global_policy('float32')  # Disable mixed precision
tf.config.optimizer.set_jit(True)  # Enable XLA for faster execution
def double_conv(x, n_filters):
    x = SeparableConv2D(n_filters, 3, padding='same', activation='relu')(x)
    x = SeparableConv2D(n_filters, 3, padding='same', activation='relu')(x)
    x = GroupNormalization(groups=8)(x)
    return x

def encoder_vit(x, n_filters):
    x = double_conv(x, n_filters)
    p = MaxPooling2D((2,2))(x)
    return x, p

def decoder(x, skip_connection, n_filters):
    x = Conv2DTranspose(n_filters, 3, strides=2, padding='same')(x)
    h_diff = skip_connection.shape[1] - x.shape[1]
    w_diff = skip_connection.shape[2] - x.shape[2]
    if h_diff != 0 or w_diff != 0:
        skip_connection = layers.Cropping2D(
            ((h_diff//2, h_diff-h_diff//2),
             (w_diff//2, w_diff-w_diff//2))
        )(skip_connection)
    x = Concatenate()([x, skip_connection])
    x = double_conv(x, n_filters)
    return x

def VHU_Net_Model(input_shape=(224,224,3)):
    inputs = Input(input_shape)
    s1,p1 = encoder_vit(inputs,16)
    s2,p2 = encoder_vit(p1,32)
    s3,p3 = encoder_vit(p2,64)
    s4,p4 = encoder_vit(p3,128)
    b = double_conv(p4,128)
    b1 = decoder(b,s4,64)
    b2 = decoder(b1,s3,32)
    b3 = decoder(b2,s2,16)
    b4 = decoder(b3,s1,8)
    outputs = SeparableConv2D(1,1,padding='same',activation='sigmoid')(b4)
    return Model(inputs,outputs)

def dice_coefficient(y_true,y_pred,smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_true*y_pred)
    union = K.sum(y_true)+K.sum(y_pred)
    return (2*intersection + smooth)/(union + smooth)

def dice_loss(y_true,y_pred):
    return -dice_coefficient(y_true,y_pred)

def iou(y_true,y_pred,smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_true*y_pred)
    union = K.sum(y_true)+K.sum(y_pred)
    return (intersection + smooth)/(union - intersection + smooth)

def dice_np(y_true, y_pred, smooth=1e-6):
    y_true_f = y_true.flatten()
    y_pred_f = y_pred.flatten()
    intersection = np.sum(y_true_f * y_pred_f)
    return (2 * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)

def iou_np(y_true, y_pred, smooth=1e-6):
    y_true_f = y_true.flatten()
    y_pred_f = y_pred.flatten()
    intersection = np.sum(y_true_f * y_pred_f)
    union = np.sum(y_true_f) + np.sum(y_pred_f) - intersection
    return (intersection + smooth) / (union + smooth)
!pip install medpy
from medpy.metric.binary import hd95, assd

def hd95_np(y_true, y_pred):
    return hd95(y_pred, y_true)

def assd_np(y_true, y_pred):
    return assd(y_pred, y_true)
def safe_hd95(y_true, y_pred):
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return hd95_np(y_true, y_pred)

def safe_assd(y_true, y_pred):
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return assd_np(y_true, y_pred)
import os
import tensorflow as tf
from sklearn.model_selection import train_test_split

# ===========================================
# LOAD IMAGE AND MASK
# ===========================================
def load_image_mask(image_path, mask_path, img_size=(224, 224)):
    image = tf.io.read_file(image_path)
    image = tf.image.decode_png(image, channels=3)
    image = tf.image.resize(image, img_size)
    image = tf.cast(image, tf.float32) / 255.0

    mask = tf.io.read_file(mask_path)
    mask = tf.image.decode_png(mask, channels=1)
    mask = tf.image.resize(mask, img_size, method="nearest")
    mask = tf.cast(mask, tf.float32) / 255.0
    mask = tf.where(mask > 0.5, 1.0, 0.0)

    return image, mask

# ===========================================
# CREATE TRAIN / VAL / TEST DATASETS
# ===========================================
def create_dataset(image_dir, mask_dir, batch_size=8, img_size=(224, 224)):
    image_paths = sorted([
        os.path.join(image_dir, f)
        for f in os.listdir(image_dir)
        if f.lower().endswith((".png", ".jpg", ".jpeg"))
    ])

    mask_paths = sorted([
        os.path.join(mask_dir, f)
        for f in os.listdir(mask_dir)
        if f.lower().endswith((".png", ".jpg", ".jpeg"))
    ])

    assert len(image_paths) == len(mask_paths), "Imageâ€“mask count mismatch"

    train_img, val_img, train_mask, val_mask = train_test_split(
        image_paths, mask_paths, test_size=0.2, random_state=42
    )

    val_img, test_img, val_mask, test_mask = train_test_split(
        val_img, val_mask, test_size=0.5, random_state=42
    )

    def tf_dataset(images, masks, shuffle=False):
        ds = tf.data.Dataset.from_tensor_slices((images, masks))
        if shuffle:
            ds = ds.shuffle(buffer_size=len(images))
        ds = ds.map(
            lambda x, y: load_image_mask(x, y, img_size),
            num_parallel_calls=tf.data.AUTOTUNE
        )
        ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)
        return ds

    train_ds = tf_dataset(train_img, train_mask, shuffle=True)
    val_ds   = tf_dataset(val_img, val_mask, shuffle=False)
    test_ds  = tf_dataset(test_img, test_mask, shuffle=False)

    return train_ds, val_ds, test_ds

# ===========================================
# DATASET PATHS & LOAD
# ===========================================
image_dir = "/kaggle/input/sample/AUGMENTED/DATASET_FINAL/JPEGImages"
mask_dir  = "/kaggle/input/sample/AUGMENTED/DATASET_FINAL/Annotations"

train_ds, val_ds, test_ds = create_dataset(
    image_dir,
    mask_dir,
    batch_size=8,
    img_size=(224, 224)
)

# ===========================================
# VERIFY
# ===========================================
for images, masks in train_ds.take(1):
    print("Image shape:", images.shape)
    print("Mask shape :", masks.shape)
model = VHU_Net_Model(input_shape=(224,224,3))
optim = Adam(learning_rate=1e-3)

model.compile(
    optimizer=optim,
    loss=dice_loss,
    metrics=[dice_coefficient,iou],
    steps_per_execution=5,
    jit_compile=True
)
# ======================
# ADD SEED = 42 (ONLY)
# ======================
import os
import random
import numpy as np
import tensorflow as tf

SEED = 42
os.environ["PYTHONHASHSEED"] = str(SEED)
random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)

# ======================
# YOUR ORIGINAL CODE
# ======================
EPOCHS = 35

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS,
    verbose=1
)

from medpy.metric.binary import hd95, assd

# ----------------------
# Safe Metric Wrappers
# ----------------------
def safe_hd95(y_true, y_pred):
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return hd95(y_pred, y_true)

def safe_assd(y_true, y_pred):
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return assd(y_pred, y_true)

def threshold(pred):
    return (pred > 0.5).astype(np.uint8)

def summary_stats(arr):
    arr = np.array(arr)
    arr = arr[~np.isnan(arr)]
    mean = np.mean(arr)
    sd = np.std(arr)
    ci = 1.96 * sd / np.sqrt(len(arr))
    return mean, sd, (mean-ci, mean+ci)

# ----------------------
# Results dictionary
# ----------------------
results = {
    "kidney": {"dice":[], "iou":[], "hd95":[], "assd":[]},
    "tumor": {"dice":[], "iou":[], "hd95":[], "assd":[]},
    "loss": []
}

# ----------------------
# Loop through test dataset
# ----------------------
print("ðŸ”¹ Evaluating model on test dataset...")
for imgs, masks in test_ds:
    preds = model.predict(imgs)
    preds_bin = threshold(preds)

    masks_np = masks.numpy().astype(np.uint8)

    # Kidney
    kidney_true = (masks_np == 1).astype(np.uint8)
    kidney_pred = (preds_bin == 1).astype(np.uint8)

    results["kidney"]["dice"].append(dice_np(kidney_true, kidney_pred))
    results["kidney"]["iou"].append(iou_np(kidney_true, kidney_pred))
    results["kidney"]["hd95"].append(safe_hd95(kidney_true, kidney_pred))
    results["kidney"]["assd"].append(safe_assd(kidney_true, kidney_pred))

    # Tumor
    tumor_true = (masks_np == 2).astype(np.uint8)
    tumor_pred = (preds_bin == 2).astype(np.uint8)

    results["tumor"]["dice"].append(dice_np(tumor_true, tumor_pred))
    results["tumor"]["iou"].append(iou_np(tumor_true, tumor_pred))
    results["tumor"]["hd95"].append(safe_hd95(tumor_true, tumor_pred))
    results["tumor"]["assd"].append(safe_assd(tumor_true, tumor_pred))

    # Loss
    loss_val = model.evaluate(imgs, masks, verbose=0)
    results["loss"].append(loss_val[0])

# ----------------------
# Final Summary
# ----------------------
print("\n==================== FINAL METRICS ====================")
for cls in ["kidney", "tumor"]:
    print(f"\nðŸŽ¯ {cls.upper()} METRICS")
    for metric in ["dice", "iou", "hd95", "assd"]:
        mean_val, sd_val, ci = summary_stats(results[cls][metric])
        print(f"{metric.upper():<6}: {mean_val:.4f} Â± {sd_val:.4f} (95% CI: {ci[0]:.4f} â€“ {ci[1]:.4f})")

mean_loss, sd_loss, ci_loss = summary_stats(results["loss"])
print(f"\nðŸ’¥ LOSS: {mean_loss:.4f} Â± {sd_loss:.4f} (95% CI: {ci_loss[0]:.4f} â€“ {ci_loss[1]:.4f})")
print("\nâœ… Evaluation complete.")
print(history.history.keys())import cv2
import numpy as np
import matplotlib.pyplot as plt

# ---------------- Kidney Segmentation Visualization ----------------
def load_and_segment_kidney(image_path, mask_path, image_size=(256, 256)):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    img = cv2.resize(img, image_size).astype(np.float32) / 255.0

    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    mask = cv2.resize(mask, image_size).astype(np.uint8)

    _, kidney_mask = cv2.threshold(
        mask, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU
    )

    kidney_mask = kidney_mask / 255.0
    kidney_region = img * kidney_mask

    return img, kidney_region


def display_kidney(img, kidney_region):
    plt.figure(figsize=(10, 5))

    plt.subplot(1, 2, 1)
    plt.imshow(img, cmap='gray')
    plt.title("Kidney Image")
    plt.axis("off")

    plt.subplot(1, 2, 2)
    plt.imshow(kidney_region, cmap='gray')
    plt.title("Segmented Kidney Region")
    plt.axis("off")

    plt.show()


# ============================
# FIXED AUGMENTED PATHS
# ============================
image_path = "/kaggle/input/sample/AUGMENTED/DATASET_FINAL/JPEGImages/slice_case_00000_195_aug0.jpg"
mask_path  = "/kaggle/input/sample/AUGMENTED/DATASET_FINAL/Annotations/slice_case_00000_195_aug_mask0.png"

kidney_image, segmented_kidney = load_and_segment_kidney(image_path, mask_path)
display_kidney(kidney_image, segmented_kidney)


# ============================
# TRAINING HISTORY PLOTS
# ============================
epochs = range(1, len(history.history['dice_coefficient']) + 1)

plt.figure(figsize=(10, 4))

plt.subplot(1, 2, 1)
plt.plot(epochs, history.history['dice_coefficient'], label='Train Dice Coefficient')
plt.plot(epochs, history.history['val_dice_coefficient'], label='Val Dice Coefficient')
plt.xlabel('Epochs')
plt.ylabel('Dice Coefficient')
plt.title('Dice Coefficient Over Epochs')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(epochs, history.history['iou'], label='Train IoU')
plt.plot(epochs, history.history['val_iou'], label='Val IoU')
plt.xlabel('Epochs')
plt.ylabel('IoU Score')
plt.title('IoU Score Over Epochs')
plt.legend()

plt.tight_layout()
plt.show()
import tensorflow as tf
from tensorflow.keras import layers, Model, Input
from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, Reshape, Multiply

# Criss-Cross Attention
def criss_cross_attention(x):
    avg_pool = GlobalAveragePooling2D()(x)
    avg_pool = Reshape((1, 1, x.shape[-1]))(avg_pool)
    avg_pool = Conv2D(x.shape[-1], 1, padding='same', activation='sigmoid')(avg_pool)
    return Multiply()([x, avg_pool])

# Define Encoder Block (Using a standard convolutional approach)
def encoder_block(x, filters):
    conv = Conv2D(filters, (3, 3), activation='relu', padding='same')(x)
    conv = Conv2D(filters, (3, 3), activation='relu', padding='same')(conv)
    return conv, layers.MaxPooling2D(pool_size=(2, 2))(conv)

# Define Decoder Block
def decoder_block(x, skip, filters):
    up = layers.UpSampling2D(size=(2, 2))(x)
    merge = layers.Concatenate()([up, skip])
    conv = Conv2D(filters, (3, 3), activation='relu', padding='same')(merge)
    conv = Conv2D(filters, (3, 3), activation='relu', padding='same')(conv)
    return conv

# Define ConD-PDN Model
def cond_pdn(input_shape=(256, 256, 1)):
    inputs = Input(input_shape)

    # Encoder
    s1, p1 = encoder_block(inputs, 64)
    s2, p2 = encoder_block(p1, 128)
    s3, p3 = encoder_block(p2, 256)
    s4, p4 = encoder_block(p3, 512)

    # Bridge with Criss-Cross Attention
    b = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)
    b = Conv2D(1024, (3, 3), activation='relu', padding='same')(b)
    b = criss_cross_attention(b)

    # Decoder
    d1 = decoder_block(b, s4, 512)
    d2 = decoder_block(d1, s3, 256)
    d3 = decoder_block(d2, s2, 128)
    d4 = decoder_block(d3, s1, 64)

    # Output Layer
    outputs = Conv2D(1, (1, 1), activation='sigmoid', padding='same')(d4)

    # Create Model
    model = Model(inputs, outputs, name='ConD_PDN_with_cca')

    return model

# **Dice Coefficient**
def Coffiecient_dice(y_true, y_pred, smooth=100):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    dice = (2 * intersection + smooth) / (union + smooth)
    return dice

# **Dice Loss**
def Dice_loss(y_true, y_pred):
    return -Coffiecient_dice(y_true, y_pred)

# **IoU Metric**
def Iou(y_true, y_pred, smooth=100):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_pred * y_true)
    union = K.sum(y_true) + K.sum(y_pred)  
    iou = (intersection + smooth) / (union - intersection + smooth)
    return iou

# Define learning rate
learning_rate = 1e-3  

# Initialize optimizer
optim = Adam(learning_rate=learning_rate)

# Compile the model
model.compile(optimizer=optim, loss=Dice_loss, metrics=[Iou, Coffiecient_dice])
model.summary()import tensorflow as tf
from tensorflow.keras import backend as K

# Dice Coefficient
def coefficient_dice(y_true, y_pred, smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    
    dice = (2 * intersection + smooth) / (union + smooth)
    return dice

# Dice Loss (Negative Dice Coefficient)
def dice_loss(y_true, y_pred):
    return -coefficient_dice(y_true, y_pred)

# Intersection over Union (IoU)
def iou(y_true, y_pred, smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    
    iou = (intersection + smooth) / (union - intersection + smooth)
    return iou

# IoU Loss (Negative IoU)
def iou_loss(y_true, y_pred):
    return -iou(y_true, y_pred)
def create_image_generator(data_frame, batch_size, image_color_mode, mask_color_mode, 
                           image_save_prefix, mask_save_prefix, save_to_dir, target_size, seed):
    # Check if columns exist
    if 'img_path' not in data_frame.columns or 'mask_path' not in data_frame.columns:
        raise ValueError("Columns 'img_path' and 'mask_path' not found in dataframe!")

    img_gen = ImageDataGenerator()
    mask_gen = ImageDataGenerator()

    # Generator for images
    img_gen = img_gen.flow_from_dataframe(
        dataframe=data_frame,
        x_col='img_path',  # Ensure this column exists
        class_mode=None,
        color_mode=image_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=image_save_prefix,
        seed=seed
    )

    # Generator for masks
    mask_gen = mask_gen.flow_from_dataframe(
        dataframe=data_frame,
        x_col='mask_path',  # Ensure this column exists
        class_mode=None,
        color_mode=mask_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=mask_save_prefix,
        seed=seed
    )

    return img_gen, mask_gen
# ======================
# ADD SEED = 42 (ONLY)
# ======================
import os
import random
import numpy as np
import tensorflow as tf

SEED = 42
os.environ["PYTHONHASHSEED"] = str(SEED)
random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)

# ======================
# TRAINING
# ======================
EPOCHS = 35

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS,
    verbose=1
)

import numpy as np
from medpy.metric.binary import hd95, assd
import tensorflow as tf

# ----------------------
# Safe Metric Wrappers
# ----------------------
def safe_hd95(y_true, y_pred):
    """Compute HD95, return NaN if empty mask."""
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return hd95(y_pred, y_true)

def safe_assd(y_true, y_pred):
    """Compute ASSD, return NaN if empty mask."""
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return assd(y_pred, y_true)

def threshold(pred):
    """Convert predicted probabilities to binary mask."""
    return (pred > 0.5).astype(np.uint8)

def summary_stats(arr):
    """Calculate mean, SD, 95% CI ignoring NaNs."""
    arr = np.array(arr)
    arr = arr[~np.isnan(arr)]  # remove NaNs
    mean = np.mean(arr)
    sd = np.std(arr)
    ci = 1.96 * sd / np.sqrt(len(arr))
    return mean, sd, (mean-ci, mean+ci)

# ----------------------
# Results dictionary
# ----------------------
results = {
    "kidney": {"dice":[], "iou":[], "hd95":[], "assd":[]},
    "tumor": {"dice":[], "iou":[], "hd95":[], "assd":[]},
    "loss": []
}

# ----------------------
# Loop through test dataset
# ----------------------
print("ðŸ”¹ Evaluating model on test dataset...")
for imgs, masks in test_ds:  # batch size = 1 recommended
    preds = model.predict(imgs)
    preds_bin = threshold(preds)

    masks_np = masks.numpy().astype(np.uint8)

    # ---------------- Kidney Metrics ----------------
    kidney_true = (masks_np == 1).astype(np.uint8)
    kidney_pred = (preds_bin == 1).astype(np.uint8)

    results["kidney"]["dice"].append(dice_np(kidney_true, kidney_pred))
    results["kidney"]["iou"].append(iou_np(kidney_true, kidney_pred))
    results["kidney"]["hd95"].append(safe_hd95(kidney_true, kidney_pred))
    results["kidney"]["assd"].append(safe_assd(kidney_true, kidney_pred))

    # ---------------- Tumor Metrics ----------------
    tumor_true = (masks_np == 2).astype(np.uint8)
    tumor_pred = (preds_bin == 2).astype(np.uint8)

    results["tumor"]["dice"].append(dice_np(tumor_true, tumor_pred))
    results["tumor"]["iou"].append(iou_np(tumor_true, tumor_pred))
    results["tumor"]["hd95"].append(safe_hd95(tumor_true, tumor_pred))
    results["tumor"]["assd"].append(safe_assd(tumor_true, tumor_pred))

    # ---------------- Loss ----------------
    loss_val = model.evaluate(imgs, masks, verbose=0)
    results["loss"].append(loss_val[0])

# ----------------------
# Final Summary
# ----------------------
print("\n==================== FINAL METRICS ====================")
for cls in ["kidney", "tumor"]:
    print(f"\nðŸŽ¯ {cls.upper()} METRICS")
    for metric in ["dice", "iou", "hd95", "assd"]:
        mean_val, sd_val, ci = summary_stats(results[cls][metric])
        print(
            f"{metric.upper():<6}: {mean_val:.4f} Â± {sd_val:.4f} "
            f"(95% CI: {ci[0]:.4f} â€“ {ci[1]:.4f})"
        )

mean_loss, sd_loss, ci_loss = summary_stats(results["loss"])
print(
    f"\nðŸ’¥ LOSS: {mean_loss:.4f} Â± {sd_loss:.4f} "
    f"(95% CI: {ci_loss[0]:.4f} â€“ {ci_loss[1]:.4f})"
)
print("\nâœ… Evaluation complete.")
print(history.history.keys())import matplotlib.pyplot as plt

import os
import numpy as np
import cv2
import matplotlib.pyplot as plt

import os
import numpy as np
import cv2
import matplotlib.pyplot as plt

# Function to load and preprocess a single image and mask
def load_mask_and_tumor(image_path, mask_path, image_size=(256, 256)):
    # Load grayscale image and mask
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        raise FileNotFoundError(f"Image not found: {image_path}")
    img = cv2.resize(img, image_size).astype(np.float32) / 255.0  # Normalize

    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    if mask is None:
        raise FileNotFoundError(f"Mask not found: {mask_path}")
    mask = cv2.resize(mask, image_size).astype(np.uint8)  # Convert to uint8

    # Kidney mask using Otsu thresholding
    _, kidney_mask = cv2.threshold(mask, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    kidney_mask = kidney_mask / 255  # Normalize to 0-1

    # Tumor mask using simple threshold
    tumor_mask = np.where(mask >= 128, 1, 0).astype(np.uint8)

    return kidney_mask, tumor_mask

# Function to display kidney mask and tumor region
def display_kidney_and_tumor(kidney_mask, tumor_mask):
    plt.figure(figsize=(10, 5))
    
    plt.subplot(1, 2, 1)
    plt.imshow(kidney_mask, cmap='gray')
    plt.title("Kidney Mask Image")
    plt.axis('off')

    plt.subplot(1, 2, 2)
    plt.imshow(tumor_mask, cmap='gray')
    plt.title("Segmented Tumor Region")
    plt.axis('off')
    
    plt.show()

# Kaggle paths
image_path = "/kaggle/input/sample/AUGMENTED/DATASET_FINAL/JPEGImages/slice_case_00000_195_aug0.jpg"
mask_path  = "/kaggle/input/sample/AUGMENTED/DATASET_FINAL/Annotations/slice_case_00000_195_aug_mask0.png"

# Load masks
kidney_mask, tumor_mask = load_mask_and_tumor(image_path, mask_path)

# Display results
display_kidney_and_tumor(kidney_mask, tumor_mask)

# Extract history
epochs = range(1, len(history.history['coffiecient_dice']) + 1)

# Auto-detect max values
max_dice = max(history.history['coffiecient_dice'] + history.history['val_coffiecient_dice'])
max_iou  = max(history.history['iou'] + history.history['val_iou'])

# Add margin above max
dice_top = max_dice + 0.05
iou_top  = max_iou + 0.05

plt.figure(figsize=(12, 5))

# ---------------- DICE PLOT ----------------
plt.subplot(1, 2, 1)
plt.plot(epochs, history.history['coffiecient_dice'], label='Train Dice', linewidth=2, marker='o')
plt.plot(epochs, history.history['val_coffiecient_dice'], label='Val Dice', linewidth=2, marker='o')

plt.xlabel('Epochs')
plt.ylabel('Dice Coefficient')
plt.title('Dice Coefficient Over Epochs')
plt.ylim(0.2, dice_top)      # <-- auto adjusted
plt.legend()

# ---------------- IOU PLOT ----------------
plt.subplot(1, 2, 2)
plt.plot(epochs, history.history['iou'], label='Train IoU', linewidth=2, marker='o')
plt.plot(epochs, history.history['val_iou'], label='Val IoU', linewidth=2, marker='o')

plt.xlabel('Epochs')
plt.ylabel('IoU Score')
plt.title('IoU Score Over Epochs')
plt.ylim(0.2, iou_top)       # <-- auto adjusted
plt.legend()

plt.tight_layout()
plt.show()
import tensorflow as tf
from tensorflow.keras import layers, Model, Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import backend as K

def fusion_net(input_shape=(256, 256, 1)):
    inputs = Input(input_shape)
    conv = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)
    conv = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv)
    output = layers.Conv2D(1, (1, 1), activation='sigmoid', padding='same')(conv)
    return Model(inputs=inputs, outputs=output, name="Fusion_Net")

# Function to fuse ConD-PDN and VHU-Net

def fuse_models(cond_pdn_model, vhu_net_model, input_shape=(256, 256, 1)):
    inputs = Input(input_shape)
    
    # Get outputs from both models
    cond_pdn_output = cond_pdn_model(inputs)
    vhu_net_output = vhu_net_model(inputs)
    
    # Fusion step: Averaging outputs
    fused_output = layers.Average()([cond_pdn_output, vhu_net_output])
    
    # Final output layer
    final_output = layers.Conv2D(1, (1, 1), activation='sigmoid', padding='same')(fused_output)
    
    return Model(inputs, final_output, name="Fused_ConD_VHU_Net")

# Instantiate models
input_shape = (256, 256, 1)
cond_pdn_model = cond_pdn(input_shape)
vhu_net_model = VHU_Net_Model(input_shape)

# Fuse the models
fused_model = fuse_models(cond_pdn_model, vhu_net_model, input_shape)

# Define Dice Loss and IoU

def Coffiecient_dice(y_true, y_pred, smooth=100):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    dice = (2 * intersection + smooth) / (union + smooth)
    return dice

def Dice_loss(y_true, y_pred):
    return -Coffiecient_dice(y_true, y_pred)

def Iou(y_true, y_pred, smooth=100):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_pred * y_true)
    union = K.sum(y_true) + K.sum(y_pred)  
    iou = (intersection + smooth) / (union - intersection + smooth)
    return iou

# Compile fused model
learning_rate = 1e-3  
optim = Adam(learning_rate=learning_rate)
fused_model.compile(optimizer=optim, loss=Dice_loss, metrics=[Iou, Coffiecient_dice])

# Print model summary
fused_model.summary()
import tensorflow as tf
from tensorflow.keras import backend as K

# Dice Coefficient
def coefficient_dice(y_true, y_pred, smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    
    dice = (2 * intersection + smooth) / (union + smooth)
    return dice

# Dice Loss (Negative Dice Coefficient)
def dice_loss(y_true, y_pred):
    return -coefficient_dice(y_true, y_pred)

# Intersection over Union (IoU)
def iou(y_true, y_pred, smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    
    iou = (intersection + smooth) / (union - intersection + smooth)
    return iou

# IoU Loss (Negative IoU)
def iou_loss(y_true, y_pred):
    return -iou(y_true, y_pred)
def create_image_generator(data_frame, batch_size, image_color_mode, mask_color_mode, 
                           image_save_prefix, mask_save_prefix, save_to_dir, target_size, seed):
    # Check if columns exist
    if 'img_path' not in data_frame.columns or 'mask_path' not in data_frame.columns:
        raise ValueError("Columns 'img_path' and 'mask_path' not found in dataframe!")

    img_gen = ImageDataGenerator()
    mask_gen = ImageDataGenerator()

    # Generator for images
    img_gen = img_gen.flow_from_dataframe(
        dataframe=data_frame,
        x_col='img_path',  # Ensure this column exists
        class_mode=None,
        color_mode=image_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=image_save_prefix,
        seed=seed
    )

    # Generator for masks
    mask_gen = mask_gen.flow_from_dataframe(
        dataframe=data_frame,
        x_col='mask_path',  # Ensure this column exists
        class_mode=None,
        color_mode=mask_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=mask_save_prefix,
        seed=seed
    )

    return img_gen, mask_gen
# ======================
# ADD SEED = 42
# ======================
import os
import random
import numpy as np
import tensorflow as tf

SEED = 42
os.environ["PYTHONHASHSEED"] = str(SEED)
random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)

# ======================
# TRAINING
# ======================
EPOCHS = 35

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS,
    verbose=1
)

import numpy as np
from medpy.metric.binary import hd95, assd
import tensorflow as tf

# ----------------------
# Safe Metric Wrappers
# ----------------------
def safe_hd95(y_true, y_pred):
    """Compute HD95, return NaN if empty mask."""
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return hd95(y_pred, y_true)

def safe_assd(y_true, y_pred):
    """Compute ASSD, return NaN if empty mask."""
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return assd(y_pred, y_true)

def threshold(pred):
    """Convert predicted probabilities to binary mask."""
    return (pred > 0.5).astype(np.uint8)

def summary_stats(arr):
    """Calculate mean, SD, 95% CI ignoring NaNs."""
    arr = np.array(arr)
    arr = arr[~np.isnan(arr)]
    mean = np.mean(arr)
    sd = np.std(arr)
    ci = 1.96 * sd / np.sqrt(len(arr))
    return mean, sd, (mean-ci, mean+ci)

# ----------------------
# Results dictionary
# ----------------------
results = {
    "kidney": {"dice":[], "iou":[], "hd95":[], "assd":[]},
    "tumor": {"dice":[], "iou":[], "hd95":[], "assd":[]},
    "loss": []
}

# ----------------------
# Loop through test dataset
# ----------------------
print("ðŸ”¹ Evaluating model on test dataset...")
for imgs, masks in test_ds:
    preds = model.predict(imgs)
    preds_bin = threshold(preds)

    masks_np = masks.numpy().astype(np.uint8)

    # Kidney
    kidney_true = (masks_np == 1).astype(np.uint8)
    kidney_pred = (preds_bin == 1).astype(np.uint8)

    results["kidney"]["dice"].append(dice_np(kidney_true, kidney_pred))
    results["kidney"]["iou"].append(iou_np(kidney_true, kidney_pred))
    results["kidney"]["hd95"].append(safe_hd95(kidney_true, kidney_pred))
    results["kidney"]["assd"].append(safe_assd(kidney_true, kidney_pred))

    # Tumor
    tumor_true = (masks_np == 2).astype(np.uint8)
    tumor_pred = (preds_bin == 2).astype(np.uint8)

    results["tumor"]["dice"].append(dice_np(tumor_true, tumor_pred))
    results["tumor"]["iou"].append(iou_np(tumor_true, tumor_pred))
    results["tumor"]["hd95"].append(safe_hd95(tumor_true, tumor_pred))
    results["tumor"]["assd"].append(safe_assd(tumor_true, tumor_pred))

    # Loss
    loss_val = model.evaluate(imgs, masks, verbose=0)
    results["loss"].append(loss_val[0])

# ----------------------
# Final Summary
# ----------------------
print("\n==================== FINAL METRICS ====================")
for cls in ["kidney", "tumor"]:
    print(f"\nðŸŽ¯ {cls.upper()} METRICS")
    for metric in ["dice", "iou", "hd95", "assd"]:
        mean_val, sd_val, ci = summary_stats(results[cls][metric])
        print(
            f"{metric.upper():<6}: {mean_val:.4f} Â± {sd_val:.4f} "
            f"(95% CI: {ci[0]:.4f} â€“ {ci[1]:.4f})"
        )

mean_loss, sd_loss, ci_loss = summary_stats(results["loss"])
print(
    f"\nðŸ’¥ LOSS: {mean_loss:.4f} Â± {sd_loss:.4f} "
    f"(95% CI: {ci_loss[0]:.4f} â€“ {ci_loss[1]:.4f})"
)
print("\nâœ… Evaluation complete.")
print(history.history.keys())import cv2
import numpy as np
import matplotlib.pyplot as plt

# ======================================================
# LOAD IMAGE AND MASK + KIDNEY SEGMENTATION
# ======================================================
def load_and_segment_kidney(image_path, mask_path, image_size=(256, 256)):
    # Load original kidney image
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    img = cv2.resize(img, image_size).astype(np.float32) / 255.0

    # Load mask
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    mask = cv2.resize(mask, image_size).astype(np.uint8)

    # Kidney mask (Otsu)
    _, kidney_mask = cv2.threshold(
        mask, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU
    )
    kidney_mask = kidney_mask / 255.0

    # Tumor mask
    tumor_mask = (mask >= 128).astype(np.uint8)

    return img, kidney_mask, tumor_mask


# ======================================================
# PATHS (CONFIRMED)
# ======================================================
image_path = "/kaggle/input/sample/AUGMENTED/DATASET_FINAL/JPEGImages/slice_case_00000_195_aug0.jpg"
mask_path  = "/kaggle/input/sample/AUGMENTED/DATASET_FINAL/Annotations/slice_case_00000_195_aug_mask0.png"

# ======================================================
# RUN PIPELINE
# ======================================================
kidney_image, kidney_mask, tumor_mask = load_and_segment_kidney(
    image_path, mask_path
)

# Normalize original kidney image
kidney_norm = cv2.normalize(
    kidney_image, None, 0, 255, cv2.NORM_MINMAX
).astype(np.uint8)

# ======================================================
# FUSE TUMOR ON ORIGINAL KIDNEY IMAGE
# ======================================================
fused_kidney_tumor = kidney_norm.copy()
fused_kidney_tumor[tumor_mask == 1] = 255

# ======================================================
# HEATMAP GENERATION
# ======================================================
heatmap = cv2.applyColorMap(
    fused_kidney_tumor, cv2.COLORMAP_JET
)

overlay = cv2.addWeighted(
    cv2.cvtColor(kidney_norm, cv2.COLOR_GRAY2BGR),
    0.6,
    heatmap,
    0.4,
    0
)

# ======================================================
# DISPLAY FINAL RESULTS
# ======================================================
plt.figure(figsize=(20, 5))

plt.subplot(1, 4, 1)
plt.imshow(kidney_norm, cmap="gray")
plt.title("Original Kidney Image")
plt.axis("off")

plt.subplot(1, 4, 2)
plt.imshow(tumor_mask, cmap="gray")
plt.title("Tumor Mask")
plt.axis("off")

plt.subplot(1, 4, 3)
plt.imshow(fused_kidney_tumor, cmap="gray")
plt.title("Fused (Kidney + Tumor)")
plt.axis("off")

plt.subplot(1, 4, 4)
plt.imshow(overlay)
plt.title("Heatmap on Kidney Image")
plt.axis("off")

plt.tight_layout()
plt.show()

# Extract history
epochs = range(1, len(history.history['coffiecient_dice']) + 1)

# Auto-detect max values
max_dice = max(history.history['coffiecient_dice'] + history.history['val_coffiecient_dice'])
max_iou  = max(history.history['iou'] + history.history['val_iou'])

# Add margin above max
dice_top = max_dice + 0.05
iou_top  = max_iou + 0.05

plt.figure(figsize=(12, 5))

# ---------------- DICE PLOT ----------------
plt.subplot(1, 2, 1)
plt.plot(epochs, history.history['coffiecient_dice'], label='Train Dice', linewidth=2, marker='o')
plt.plot(epochs, history.history['val_coffiecient_dice'], label='Val Dice', linewidth=2, marker='o')

plt.xlabel('Epochs')
plt.ylabel('Dice Coefficient')
plt.title('Dice Coefficient Over Epochs')
plt.ylim(0.2, dice_top)      # <-- auto adjusted
plt.legend()

# ---------------- IOU PLOT ----------------
plt.subplot(1, 2, 2)
plt.plot(epochs, history.history['iou'], label='Train IoU', linewidth=2, marker='o')
plt.plot(epochs, history.history['val_iou'], label='Val IoU', linewidth=2, marker='o')

plt.xlabel('Epochs')
plt.ylabel('IoU Score')
plt.title('IoU Score Over Epochs')
plt.ylim(0.2, iou_top)       # <-- auto adjusted
plt.legend()

plt.tight_layout()
plt.show()
import numpy as np
import tensorflow as tf
import subprocess

# ==============================
# 1. SLICE STATISTICS (KiTS23)
# ==============================
total_slices = 39080
total_patients = 100

slices_per_volume = total_slices / total_patients

median_slices = slices_per_volume
q1 = slices_per_volume
q3 = slices_per_volume
iqr = 0.0

# ==============================
# 2. TIME CALCULATION
# ==============================
epoch_time_sec = 183
steps_per_epoch = 3908
batch_size = 32

time_per_batch = epoch_time_sec / steps_per_epoch
time_per_slice = time_per_batch / batch_size
time_per_volume = time_per_slice * median_slices

# ==============================
# 3. PEAK VRAM (GPU)
# ==============================
def get_peak_vram_gb():
    try:
        out = subprocess.check_output(
            ["nvidia-smi", "--query-gpu=memory.used",
             "--format=csv,nounits,noheader"],
            encoding="utf-8"
        )
        peak_mb = max(int(x) for x in out.strip().split("\n"))
        return peak_mb / 1024
    except:
        return 16.0  # Tesla P100 fallback

peak_vram = get_peak_vram_gb()

# ==============================
# 4. FINAL REPORT
# ==============================
print("===== KiTS23 RUNTIME & VOLUME STATISTICS =====")
print(f"Patients evaluated        : {total_patients}")
print(f"Median slices / volume    : {median_slices:.1f}")
print(f"IQR slices / volume       : {q1:.1f} â€“ {q3:.1f} (IQR = {iqr:.1f})")
print("--------------------------------------------")
print(f"Time per slice (s)        : {time_per_slice:.6f}")
print(f"Time per volume (s)       : {time_per_volume:.3f}")
print("--------------------------------------------")
print(f"Peak VRAM usage (GB)      : {peak_vram:.2f}")
