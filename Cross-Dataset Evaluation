#................HAM10000 and Blood Cell it contain Table 9 result...........#

#...........Blood cell dataset..................#
import os
os.listdir("/kaggle/input")
#........................['bccd-dataset-with-mask']...................#

import os
from glob import glob

# Base BCCD dataset path
dataset_base = '/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/'

# Paths to images and masks
images_path = os.path.join(dataset_base, 'original')
masks_path = os.path.join(dataset_base, 'mask')

# Get all files
image_files = glob(os.path.join(images_path, '*'))
mask_files = glob(os.path.join(masks_path, '*'))

# Print counts
print("Total images:", len(image_files))
print("Total masks:", len(mask_files))

# If you want them in a tuple
counts = (len(image_files), len(mask_files))
print("Counts (images, masks):", counts)

import os
import pandas as pd
from sklearn.model_selection import train_test_split

# ==============================
# Dataset directories (BCCD)
# ==============================
base_dir = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train"

image_dir = os.path.join(base_dir, "original")   # images
mask_dir  = os.path.join(base_dir, "mask")       # masks

# ==============================
# Gather files and match images to masks
# ==============================
image_files = sorted([
    os.path.join(image_dir, f)
    for f in os.listdir(image_dir)
    if f.lower().endswith(('.png', '.jpg', '.jpeg'))
])

mask_files = sorted([
    os.path.join(mask_dir, f)
    for f in os.listdir(mask_dir)
    if f.lower().endswith(('.png', '.jpg', '.jpeg'))
])

if len(image_files) != len(mask_files):
    print(f"Warning: {len(image_files)} images vs {len(mask_files)} masks")

# Create dataframe
df = pd.DataFrame({
    'img_path': image_files,
    'mask_path': mask_files
})

# ==============================
# Split dataset: 8:1:1
# ==============================
train_df, temp_df = train_test_split(
    df, test_size=0.2, random_state=42, shuffle=True
)

val_df, test_df = train_test_split(
    temp_df, test_size=0.5, random_state=42, shuffle=True
)

# Reset indices
train_df = train_df.reset_index(drop=True)
val_df   = val_df.reset_index(drop=True)
test_df  = test_df.reset_index(drop=True)

# ==============================
# Summary
# ==============================
print(f"Total samples: {len(df)}")
print(f"Training samples: {len(train_df)}")
print(f"Validation samples: {len(val_df)}")
print(f"Test samples: {len(test_df)}")

# Optional: show first 5 rows
train_df.head()


import os
import pandas as pd

def create_df(image_dir, mask_dir):
    img_paths = []
    mask_paths = []
    
    # Ensure directories exist
    if not os.path.exists(image_dir) or not os.path.exists(mask_dir):
        raise ValueError("The specified directories do not exist.")
    
    # Get sorted lists of images and masks
    image_files = sorted(os.listdir(image_dir))
    mask_files = sorted(os.listdir(mask_dir))

    # Ensure matching images and masks
    for img_file, mask_file in zip(image_files, mask_files):
        img_paths.append(os.path.join(image_dir, img_file))
        mask_paths.append(os.path.join(mask_dir, mask_file))

    # Create DataFrame
    df = pd.DataFrame({'img_path': img_paths, 'mask_path': mask_paths})
    return df

# ==============================
# BCCD dataset directories
# ==============================
image_dir = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/original"
mask_dir  = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/mask"

# Create dataset DataFrame
df = create_df(image_dir, mask_dir)

# Display sample dataset
print(df.head())

# Optional: check lengths
print("Total images:", len(df))
print("Total masks:", len(df))


import numpy as np
import cv2

def display_image_shapes(df, num_samples=10):
    num_samples = min(num_samples, len(df))  # Ensure valid range

    # Random sampling
    random_indices = np.random.choice(df.index, size=num_samples, replace=False)
    random_images = df.iloc[random_indices]['img_path'].values
    random_masks = df.iloc[random_indices]['mask_path'].values

    for i in range(num_samples):
        # Load BCCD images + masks
        image = cv2.imread(random_images[i])
        mask = cv2.imread(random_masks[i], cv2.IMREAD_GRAYSCALE)

        if image is None or mask is None:
            print(f"Warning: Unable to load image or mask at index {random_indices[i]}")
            continue

        print(f"Sample {i+1}: Image Shape = {image.shape}, Mask Shape = {mask.shape}")

# Run for BCCD dataframe
display_image_shapes(df)
import os
import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt
import albumentations as A

# ============================================
# STEP 1 â€” Create DataFrame for BCCD images/masks
# ============================================
def create_df(image_dir, mask_dir):
    img_paths = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir)])
    mask_paths = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir)])
    return pd.DataFrame({'img_path': img_paths, 'mask_path': mask_paths})

# BCCD dataset paths
image_dir = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/original"
mask_dir  = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/mask"

df = create_df(image_dir, mask_dir)
print("Total images:", len(df))

# ============================================
# STEP 2 â€” Visualize random imageâ€“mask pairs
# ============================================
def display_samples(df, num_samples=5):
    random_indices = np.random.choice(df.index, size=num_samples, replace=False)
    fig, axes = plt.subplots(num_samples, 2, figsize=(10, num_samples * 3))

    for i, idx in enumerate(random_indices):
        img = cv2.imread(df.iloc[idx]['img_path'])
        mask = cv2.imread(df.iloc[idx]['mask_path'], cv2.IMREAD_GRAYSCALE)

        axes[i, 0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        axes[i, 0].set_title("Original Image")
        axes[i, 0].axis("off")

        axes[i, 1].imshow(mask, cmap="gray")
        axes[i, 1].set_title("Mask")
        axes[i, 1].axis("off")

    plt.tight_layout()
    plt.show()

display_samples(df, num_samples=5)

# ============================================
# STEP 3 â€” Albumentations augmentation pipeline
# ============================================
augmentation = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.5),
    A.Rotate(limit=20, p=0.5),
    A.RandomBrightnessContrast(p=0.3),
    A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.3),
])

def augment_image(image_path, mask_path):
    image = cv2.imread(image_path)
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    augmented = augmentation(image=image, mask=mask)
    return augmented['image'], augmented['mask']

# ============================================
# STEP 4 â€” Display augmented samples
# ============================================
def display_augmented_samples(df, num_samples=5):
    random_indices = np.random.choice(df.index, size=num_samples, replace=False)
    fig, axes = plt.subplots(num_samples, 4, figsize=(15, num_samples * 3))

    for i, idx in enumerate(random_indices):
        img = cv2.imread(df.iloc[idx]['img_path'])
        mask = cv2.imread(df.iloc[idx]['mask_path'], cv2.IMREAD_GRAYSCALE)
        aug_img, aug_mask = augment_image(df.iloc[idx]['img_path'], df.iloc[idx]['mask_path'])

        axes[i, 0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        axes[i, 0].set_title("Original Image")
        axes[i, 0].axis("off")

        axes[i, 1].imshow(mask, cmap="gray")
        axes[i, 1].set_title("Original Mask")
        axes[i, 1].axis("off")

        axes[i, 2].imshow(cv2.cvtColor(aug_img, cv2.COLOR_BGR2RGB))
        axes[i, 2].set_title("Augmented Image")
        axes[i, 2].axis("off")

        axes[i, 3].imshow(aug_mask, cmap="gray")
        axes[i, 3].set_title("Augmented Mask")
        axes[i, 3].axis("off")

    plt.tight_layout()
    plt.show()

display_augmented_samples(df, num_samples=5)

import os
import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt
import seaborn as sns
import albumentations as A
from sklearn.manifold import TSNE
import umap
from sklearn.decomposition import PCA
import random

# ===============================
# STEP 1 â€” Preprocessing functions
# ===============================

def apply_clahe(image):
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l = clahe.apply(l)
    lab = cv2.merge((l, a, b))
    return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)

def apply_histogram_equalization(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    equalized = cv2.equalizeHist(gray)
    return cv2.cvtColor(equalized, cv2.COLOR_GRAY2BGR)

# ===============================
# STEP 2 â€” Augmentation pipeline
# ===============================

augmentation = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.5),
    A.Rotate(limit=20, p=0.5),
    A.RandomBrightnessContrast(p=0.3),
    A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.3),
    A.OneOf([
        A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.5),
        A.Equalize(p=0.5)
    ], p=0.5)
])

def augment_image(image):
    return augmentation(image=image)['image']

# ===============================
# STEP 3 â€” Display preprocessing stages
# ===============================

def display_preprocessing_stages(image1, image2):
    fig, axes = plt.subplots(2, 4, figsize=(20, 10))
    for i, img in enumerate([image1, image2]):
        clahe_image = apply_clahe(img)
        hist_eq_image = apply_histogram_equalization(img)
        augmented_image = augment_image(img)

        titles = ["Original", "CLAHE", "Histogram Equalization", "Augmented"]
        images = [img, clahe_image, hist_eq_image, augmented_image]

        for ax, img_, title in zip(axes[i], images, titles):
            ax.imshow(cv2.cvtColor(img_, cv2.COLOR_BGR2RGB))
            ax.set_title(f"Image {i+1} - {title}")
            ax.axis("off")

    plt.show()

# ===============================
# STEP 4 â€” t-SNE and UMAP visualization
# ===============================

def visualize_image_distribution(df, method='tsne'):
    images = np.stack(df['image_pixels'].values)
    images_flat = images.reshape(images.shape[0], -1)

    images_pca = PCA(n_components=min(50, images_flat.shape[1])).fit_transform(images_flat)

    if method == 'tsne':
        perplexity_value = min(30, images_pca.shape[0] - 1)
        reducer = TSNE(n_components=2, perplexity=perplexity_value, random_state=42)
    else:
        reducer = umap.UMAP(n_components=2, random_state=42)

    images_reduced = reducer.fit_transform(images_pca)

    plt.figure(figsize=(8, 6))
    plt.scatter(images_reduced[:, 0], images_reduced[:, 1], alpha=0.7, cmap='coolwarm')
    plt.title(f'{method.upper()} Visualization of Image Dataset')
    plt.xlabel('Component 1')
    plt.ylabel('Component 2')
    plt.show()

# ===============================
# STEP 5 â€” Select two random images from BCCD dataset
# ===============================

image_dir = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/original"

image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

if len(image_files) < 2:
    raise ValueError("Not enough images found in the BCCD dataset.")

# Randomly sample 2 images
random_images = random.sample(image_files, 2)

image1 = cv2.imread(os.path.join(image_dir, random_images[0]))
image2 = cv2.imread(os.path.join(image_dir, random_images[1]))

if image1 is None or image2 is None:
    raise ValueError("Failed to load one or both images from BCCD dataset.")

# Display preprocessing stages
display_preprocessing_stages(image1, image2)

# ===============================
# STEP 6 â€” Synthetic sample DataFrame for t-SNE / UMAP
# ===============================

df = pd.DataFrame({
    'image_pixels': [np.random.rand(32, 32, 3) for _ in range(50)]
})

visualize_image_distribution(df, method='tsne')
visualize_image_distribution(df, method='umap')

import os
import pandas as pd
from sklearn.model_selection import train_test_split

# --- Step 1: Create DataFrame for BCCD dataset ---
image_dir = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/original"
mask_dir  = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/mask"

# Function to create df
def create_df(image_dir, mask_dir):
    img_paths = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir)])
    mask_paths = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir)])
    return pd.DataFrame({'img_path': img_paths, 'mask_path': mask_paths})

df = create_df(image_dir, mask_dir)
print("Total dataset size:", len(df))

# --- Step 2: Split dataset into train, validation, and test sets ---
train_df, test_df = train_test_split(df, test_size=0.1, random_state=42)     # 10% test
train_df, val_df  = train_test_split(train_df, test_size=0.1, random_state=42)  # 10% of remaining â†’ validation

# --- Step 3: Check split sizes ---
print("Training set size:", len(train_df))
print("Validation set size:", len(val_df))
print("Test set size:", len(test_df))
#.................Total dataset size: 1169
Training set size: 946
Validation set size: 106
Test set size: 117................#

from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np

def create_image_generator(data_frame,
                           batch_size,
                           image_color_mode="rgb",
                           mask_color_mode="grayscale",
                           image_save_prefix="image",
                           mask_save_prefix="mask",
                           save_to_dir=None,
                           target_size=(256, 256),
                           seed=1):

    def normalize(img, mask):
        img = img / 255.0
        mask = mask / 255.0
        mask[mask > 0.5] = 1
        mask[mask <= 0.5] = 0
        return img, mask

    img_datagen = ImageDataGenerator()
    mask_datagen = ImageDataGenerator()

    # Image generator
    img_gen = img_datagen.flow_from_dataframe(
        dataframe=data_frame,
        x_col="img_path",
        class_mode=None,
        color_mode=image_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        shuffle=True,
        seed=seed
    )

    # Mask generator
    mask_gen = mask_datagen.flow_from_dataframe(
        dataframe=data_frame,
        x_col="mask_path",
        class_mode=None,
        color_mode=mask_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        shuffle=True,
        seed=seed
    )

    # Combine generators
    while True:
        img = next(img_gen)
        mask = next(mask_gen)
        yield normalize(img, mask)


# -------------------- BCCD Usage ----------------------

batch_size = 1    # suitable for BCCD small dataset

train_generator = create_image_generator(train_df, batch_size=batch_size)
val_generator   = create_image_generator(val_df, batch_size=batch_size)
test_generator  = create_image_generator(test_df, batch_size=batch_size)

# Fetch one batch
x_batch, y_batch = next(train_generator)
print("Image batch shape:", x_batch.shape)
print("Mask batch shape:", y_batch.shape)

EPOCHS = 35        # keep very low, only for checking pipeline
BATCH_SIZE = 32    # MUST be 1 because dataset has only one sample
learning_rate = 1e-4
w, h = 256, 256   # keep same size as generator target_sizeEPOCHS = 35  
import tensorflow as tf
from tensorflow.keras import layers, Model, backend as K
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Input, SeparableConv2D, MaxPooling2D, Conv2DTranspose, Concatenate, GroupNormalization
import os
from sklearn.model_selection import train_test_split

# -----------------------------
# GPU / Optimization
# -----------------------------
tf.keras.mixed_precision.set_global_policy('float32')  # Disable mixed precision
tf.config.optimizer.set_jit(True)  # Enable XLA for faster execution

def double_conv(x, n_filters):
    x = SeparableConv2D(n_filters, 3, padding='same', activation='relu')(x)
    x = SeparableConv2D(n_filters, 3, padding='same', activation='relu')(x)
    x = GroupNormalization(groups=8)(x)
    return x

def encoder_vit(x, n_filters):
    x = double_conv(x, n_filters)
    p = MaxPooling2D((2,2))(x)
    return x, p

def decoder(x, skip_connection, n_filters):
    x = Conv2DTranspose(n_filters, 3, strides=2, padding='same')(x)
    h_diff = skip_connection.shape[1] - x.shape[1]
    w_diff = skip_connection.shape[2] - x.shape[2]
    if h_diff != 0 or w_diff != 0:
        skip_connection = layers.Cropping2D(
            ((h_diff//2, h_diff-h_diff//2),
             (w_diff//2, w_diff-w_diff//2))
        )(skip_connection)
    x = Concatenate()([x, skip_connection])
    x = double_conv(x, n_filters)
    return x

def VHU_Net_Model(input_shape=(224,224,3)):
    inputs = Input(input_shape)
    s1,p1 = encoder_vit(inputs,16)
    s2,p2 = encoder_vit(p1,32)
    s3,p3 = encoder_vit(p2,64)
    s4,p4 = encoder_vit(p3,128)
    b = double_conv(p4,128)
    b1 = decoder(b,s4,64)
    b2 = decoder(b1,s3,32)
    b3 = decoder(b2,s2,16)
    b4 = decoder(b3,s1,8)
    outputs = SeparableConv2D(1,1,padding='same',activation='sigmoid')(b4)
    return Model(inputs,outputs)
def dice_coefficient(y_true,y_pred,smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_true*y_pred)
    union = K.sum(y_true)+K.sum(y_pred)
    return (2*intersection + smooth)/(union + smooth)

def dice_loss(y_true,y_pred):
    return -dice_coefficient(y_true,y_pred)

def iou(y_true,y_pred,smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_true*y_pred)
    union = K.sum(y_true)+K.sum(y_pred)
    return (intersection + smooth)/(union - intersection + smooth)
def dice_np(y_true, y_pred, smooth=1e-6):
    y_true_f = y_true.flatten()
    y_pred_f = y_pred.flatten()
    intersection = np.sum(y_true_f * y_pred_f)
    return (2 * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)

def iou_np(y_true, y_pred, smooth=1e-6):
    y_true_f = y_true.flatten()
    y_pred_f = y_pred.flatten()
    intersection = np.sum(y_true_f * y_pred_f)
    union = np.sum(y_true_f) + np.sum(y_pred_f) - intersection
    return (intersection + smooth) / (union + smooth)
!pip install medpy
from medpy.metric.binary import hd95, assd

def hd95_np(y_true, y_pred):
    return hd95(y_pred, y_true)

def assd_np(y_true, y_pred):
    return assd(y_pred, y_true)
def safe_hd95(y_true, y_pred):
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return hd95_np(y_true, y_pred)

def safe_assd(y_true, y_pred):
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return assd_np(y_true, y_pred)
import os
import tensorflow as tf
from sklearn.model_selection import train_test_split

def load_image_mask(image_path, mask_path, img_size=(224,224)):
    # Load image
    image = tf.io.read_file(image_path)
    image = tf.image.decode_png(image, channels=3)
    image = tf.image.resize(image, img_size)
    image = tf.cast(image, tf.float32) / 255.0

    # Load mask
    mask = tf.io.read_file(mask_path)
    mask = tf.image.decode_png(mask, channels=1)
    mask = tf.image.resize(mask, img_size)
    mask = tf.cast(mask, tf.float32) / 255.0

    # Convert to binary (BCCD masks are typically binary)
    mask = tf.where(mask > 0.5, 1.0, 0.0)

    return image, mask


def create_dataset(image_dir, mask_dir, batch_size=8, img_size=(224,224)):
    image_paths = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir)])
    mask_paths  = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir)])

    # Split into train / val / test
    train_img, val_img, train_mask, val_mask = train_test_split(
        image_paths, mask_paths, test_size=0.2, random_state=42)

    val_img, test_img, val_mask, test_mask = train_test_split(
        val_img, val_mask, test_size=0.5, random_state=42)

    def tf_dataset(images, masks):
        ds = tf.data.Dataset.from_tensor_slices((images, masks))
        ds = ds.map(lambda x, y: load_image_mask(x, y, img_size),
                    num_parallel_calls=tf.data.AUTOTUNE)
        ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)
        return ds

    return (
        tf_dataset(train_img, train_mask),
        tf_dataset(val_img, val_mask),
        tf_dataset(test_img, test_mask)
    )


# ===============================
# Set BCCD paths and load datasets
# ===============================

image_dir = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/original"
mask_dir  = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/mask"

train_ds, val_ds, test_ds = create_dataset(image_dir, mask_dir, batch_size=8)
model = VHU_Net_Model(input_shape=(224,224,3))
optim = Adam(learning_rate=1e-3)

model.compile(
    optimizer=optim,
    loss=dice_loss,
    metrics=[dice_coefficient,iou],
    steps_per_execution=5,
    jit_compile=True
)
EPOCHS = 35

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS,
    verbose=1
)
import numpy as np
from medpy.metric.binary import hd95, assd
import tensorflow as tf

# ----------------------
# Safe Metric Wrappers
# ----------------------
def safe_hd95(y_true, y_pred):
    """Compute HD95, return NaN if empty mask."""
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return hd95(y_pred, y_true)

def safe_assd(y_true, y_pred):
    """Compute ASSD, return NaN if empty mask."""
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return assd(y_pred, y_true)

def threshold(pred):
    """Convert predicted probabilities to binary mask."""
    return (pred > 0.5).astype(np.uint8)

def summary_stats(arr):
    """Calculate mean, SD, 95% CI ignoring NaNs."""
    arr = np.array(arr)
    arr = arr[~np.isnan(arr)]  # remove NaNs
    mean = np.mean(arr)
    sd = np.std(arr)
    ci = 1.96 * sd / np.sqrt(len(arr))
    return mean, sd, (mean-ci, mean+ci)

# ----------------------
# Results dictionary
# ----------------------
results = {
    "kidney": {"dice":[], "iou":[], "hd95":[], "assd":[]},
    "tumor": {"dice":[], "iou":[], "hd95":[], "assd":[]},
    "loss": []  # store per-sample loss if needed
}

# ----------------------
# Loop through test dataset
# ----------------------
print("ðŸ”¹ Evaluating model on test dataset...")
for imgs, masks in test_ds:  # batch size = 1 recommended
    preds = model.predict(imgs)
    preds_bin = threshold(preds)

    masks_np = masks.numpy().astype(np.uint8)

    # ---------------- Kidney Metrics ----------------
    kidney_true = (masks_np == 1).astype(np.uint8)
    kidney_pred = (preds_bin == 1).astype(np.uint8)

    results["kidney"]["dice"].append(dice_np(kidney_true, kidney_pred))
    results["kidney"]["iou"].append(iou_np(kidney_true, kidney_pred))
    results["kidney"]["hd95"].append(safe_hd95(kidney_true, kidney_pred))
    results["kidney"]["assd"].append(safe_assd(kidney_true, kidney_pred))

    # ---------------- Tumor Metrics ----------------
    tumor_true = (masks_np == 2).astype(np.uint8)
    tumor_pred = (preds_bin == 2).astype(np.uint8)

    results["tumor"]["dice"].append(dice_np(tumor_true, tumor_pred))
    results["tumor"]["iou"].append(iou_np(tumor_true, tumor_pred))
    results["tumor"]["hd95"].append(safe_hd95(tumor_true, tumor_pred))
    results["tumor"]["assd"].append(safe_assd(tumor_true, tumor_pred))

    # ---------------- Loss ----------------
    loss_val = model.evaluate(imgs, masks, verbose=0)
    results["loss"].append(loss_val[0])  # only store loss

# ----------------------
# Final Summary
# ----------------------
print("\n==================== FINAL METRICS ====================")
for cls in ["kidney", "tumor"]:
    print(f"\nðŸŽ¯ {cls.upper()} METRICS")
    for metric in ["dice", "iou", "hd95", "assd"]:
        mean_val, sd_val, ci = summary_stats(results[cls][metric])
        print(f"{metric.upper():<6}: {mean_val:.4f} Â± {sd_val:.4f} (95% CI: {ci[0]:.4f} â€“ {ci[1]:.4f})")

# Overall loss
mean_loss, sd_loss, ci_loss = summary_stats(results["loss"])
print(f"\nðŸ’¥ LOSS: {mean_loss:.4f} Â± {sd_loss:.4f} (95% CI: {ci_loss[0]:.4f} â€“ {ci_loss[1]:.4f})")
print("\nâœ… Evaluation complete.")
print(history.history.keys())
import cv2
import numpy as np
import matplotlib.pyplot as plt

# ----------------------------------------------
# 1ï¸âƒ£ Load Original Blood Cell Image
# ----------------------------------------------
def load_blood_cell_image(image_path, image_size=(256, 256)):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        raise ValueError(f"Image not found: {image_path}")
    img = cv2.resize(img, image_size)
    img = img.astype(np.float32) / 255.0  # Normalize
    return img

# ----------------------------------------------
# 2ï¸âƒ£ Segment Blood Cell Region
# ----------------------------------------------
def segment_blood_cell(mask_path, base_image, image_size=(256, 256)):
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    if mask is None:
        raise ValueError(f"Mask not found: {mask_path}")

    mask = cv2.resize(mask, image_size).astype(np.uint8)

    # Convert to binary mask (0 or 1)
    _, binary_mask = cv2.threshold(mask, 128, 255, cv2.THRESH_BINARY)
    binary_mask = binary_mask / 255.0

    # Extract segmented blood cell region
    segmented_region = base_image * binary_mask
    return mask, binary_mask, segmented_region

# ----------------------------------------------
# 3ï¸âƒ£ Display Results
# ----------------------------------------------
def display_blood_cell_results(original_img, segmented_img):
    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1)
    plt.imshow(original_img, cmap='gray')
    plt.title("Original Blood Cell Image")
    plt.axis("off")

    plt.subplot(1, 2, 2)
    plt.imshow(segmented_img, cmap='gray')
    plt.title("Segmented Blood Cell Region")
    plt.axis("off")

    plt.show()

# ----------------------------------------------
# 4ï¸âƒ£ Use BCCD Paths
# ----------------------------------------------
image_path = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/original/002f20ad-2ace-499c-9335-c9080bc3e6b5.png"
mask_path  = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/mask/002f20ad-2ace-499c-9335-c9080bc3e6b5.png"

# Load + segment
original_img = load_blood_cell_image(image_path)
mask, mask_binary, segmented_region = segment_blood_cell(mask_path, original_img)

# Display output
display_blood_cell_results(original_img, segmented_region)

# ----------------------------------------------
# 5ï¸âƒ£ Plot Dice & IoU Training Curves
# ----------------------------------------------
epochs = range(1, len(history.history['dice_coefficient']) + 1)

plt.figure(figsize=(10, 4))

# Dice Coefficient
plt.subplot(1, 2, 1)
plt.plot(epochs, history.history['dice_coefficient'], label='Train Dice')
plt.plot(epochs, history.history['val_dice_coefficient'], label='Val Dice')
plt.xlabel('Epochs')
plt.ylabel('Dice Coefficient')
plt.title('Dice Coefficient Over Epochs')
plt.legend()

# IoU
plt.subplot(1, 2, 2)
plt.plot(epochs, history.history['iou'], label='Train IoU')
plt.plot(epochs, history.history['val_iou'], label='Val IoU')
plt.xlabel('Epochs')
plt.ylabel('IoU Score')
plt.title('IoU Score Over Epochs')
plt.legend()

plt.tight_layout()
plt.show()

# Show available keys for clarity
print(history.history.keys())

import tensorflow as tf
from tensorflow.keras import layers, Model, Input
from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, Reshape, Multiply

# Criss-Cross Attention
def criss_cross_attention(x):
    avg_pool = GlobalAveragePooling2D()(x)
    avg_pool = Reshape((1, 1, x.shape[-1]))(avg_pool)
    avg_pool = Conv2D(x.shape[-1], 1, padding='same', activation='sigmoid')(avg_pool)
    return Multiply()([x, avg_pool])

# Define Encoder Block (Using a standard convolutional approach)
def encoder_block(x, filters):
    conv = Conv2D(filters, (3, 3), activation='relu', padding='same')(x)
    conv = Conv2D(filters, (3, 3), activation='relu', padding='same')(conv)
    return conv, layers.MaxPooling2D(pool_size=(2, 2))(conv)

# Define Decoder Block
def decoder_block(x, skip, filters):
    up = layers.UpSampling2D(size=(2, 2))(x)
    merge = layers.Concatenate()([up, skip])
    conv = Conv2D(filters, (3, 3), activation='relu', padding='same')(merge)
    conv = Conv2D(filters, (3, 3), activation='relu', padding='same')(conv)
    return conv

# Define ConD-PDN Model
def cond_pdn(input_shape=(256, 256, 1)):
    inputs = Input(input_shape)

    # Encoder
    s1, p1 = encoder_block(inputs, 64)
    s2, p2 = encoder_block(p1, 128)
    s3, p3 = encoder_block(p2, 256)
    s4, p4 = encoder_block(p3, 512)

    # Bridge with Criss-Cross Attention
    b = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)
    b = Conv2D(1024, (3, 3), activation='relu', padding='same')(b)
    b = criss_cross_attention(b)

    # Decoder
    d1 = decoder_block(b, s4, 512)
    d2 = decoder_block(d1, s3, 256)
    d3 = decoder_block(d2, s2, 128)
    d4 = decoder_block(d3, s1, 64)

    # Output Layer
    outputs = Conv2D(1, (1, 1), activation='sigmoid', padding='same')(d4)

    # Create Model
    model = Model(inputs, outputs, name='ConD_PDN_with_cca')

    return model

# **Dice Coefficient**
def Coffiecient_dice(y_true, y_pred, smooth=100):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    dice = (2 * intersection + smooth) / (union + smooth)
    return dice

# **Dice Loss**
def Dice_loss(y_true, y_pred):
    return -Coffiecient_dice(y_true, y_pred)

# **IoU Metric**
def Iou(y_true, y_pred, smooth=100):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_pred * y_true)
    union = K.sum(y_true) + K.sum(y_pred)  
    iou = (intersection + smooth) / (union - intersection + smooth)
    return iou

# Define learning rate
learning_rate = 1e-3  

# Initialize optimizer
optim = Adam(learning_rate=learning_rate)

# Compile the model
model.compile(optimizer=optim, loss=Dice_loss, metrics=[Iou, Coffiecient_dice])
model.summary()

import tensorflow as tf
from tensorflow.keras import backend as K

# Dice Coefficient
def coefficient_dice(y_true, y_pred, smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    
    dice = (2 * intersection + smooth) / (union + smooth)
    return dice

# Dice Loss (Negative Dice Coefficient)
def dice_loss(y_true, y_pred):
    return -coefficient_dice(y_true, y_pred)

# Intersection over Union (IoU)
def iou(y_true, y_pred, smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    
    iou = (intersection + smooth) / (union - intersection + smooth)
    return iou

# IoU Loss (Negative IoU)
def iou_loss(y_true, y_pred):
    return -iou(y_true, y_pred)
def create_image_generator(data_frame, batch_size, image_color_mode, mask_color_mode, 
                           image_save_prefix, mask_save_prefix, save_to_dir, target_size, seed):
    # Check if columns exist
    if 'img_path' not in data_frame.columns or 'mask_path' not in data_frame.columns:
        raise ValueError("Columns 'img_path' and 'mask_path' not found in dataframe!")

    img_gen = ImageDataGenerator()
    mask_gen = ImageDataGenerator()

    # Generator for images
    img_gen = img_gen.flow_from_dataframe(
        dataframe=data_frame,
        x_col='img_path',  # Ensure this column exists
        class_mode=None,
        color_mode=image_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=image_save_prefix,
        seed=seed
    )

    # Generator for masks
    mask_gen = mask_gen.flow_from_dataframe(
        dataframe=data_frame,
        x_col='mask_path',  # Ensure this column exists
        class_mode=None,
        color_mode=mask_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=mask_save_prefix,
        seed=seed
    )

    return img_gen, mask_gen

EPOCHS = 35

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS,
    verbose=1
)
import numpy as np
from medpy.metric.binary import hd95, assd
import tensorflow as tf

# ----------------------
# Safe Metric Wrappers
# ----------------------
def safe_hd95(y_true, y_pred):
    """Compute HD95, return NaN if empty mask."""
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return hd95(y_pred, y_true)

def safe_assd(y_true, y_pred):
    """Compute ASSD, return NaN if empty mask."""
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return assd(y_pred, y_true)

def threshold(pred):
    """Convert predicted probabilities to binary mask."""
    return (pred > 0.5).astype(np.uint8)

def summary_stats(arr):
    """Calculate mean, SD, 95% CI ignoring NaNs."""
    arr = np.array(arr)
    arr = arr[~np.isnan(arr)]  # remove NaNs
    mean = np.mean(arr)
    sd = np.std(arr)
    ci = 1.96 * sd / np.sqrt(len(arr))
    return mean, sd, (mean-ci, mean+ci)

# ----------------------
# Results dictionary
# ----------------------
results = {
    "kidney": {"dice":[], "iou":[], "hd95":[], "assd":[]},
    "tumor": {"dice":[], "iou":[], "hd95":[], "assd":[]},
    "loss": []  # store per-sample loss if needed
}

# ----------------------
# Loop through test dataset
# ----------------------
print("ðŸ”¹ Evaluating model on test dataset...")
for imgs, masks in test_ds:  # batch size = 1 recommended
    preds = model.predict(imgs)
    preds_bin = threshold(preds)

    masks_np = masks.numpy().astype(np.uint8)

    # ---------------- Kidney Metrics ----------------
    kidney_true = (masks_np == 1).astype(np.uint8)
    kidney_pred = (preds_bin == 1).astype(np.uint8)

    results["kidney"]["dice"].append(dice_np(kidney_true, kidney_pred))
    results["kidney"]["iou"].append(iou_np(kidney_true, kidney_pred))
    results["kidney"]["hd95"].append(safe_hd95(kidney_true, kidney_pred))
    results["kidney"]["assd"].append(safe_assd(kidney_true, kidney_pred))

    # ---------------- Tumor Metrics ----------------
    tumor_true = (masks_np == 2).astype(np.uint8)
    tumor_pred = (preds_bin == 2).astype(np.uint8)

    results["tumor"]["dice"].append(dice_np(tumor_true, tumor_pred))
    results["tumor"]["iou"].append(iou_np(tumor_true, tumor_pred))
    results["tumor"]["hd95"].append(safe_hd95(tumor_true, tumor_pred))
    results["tumor"]["assd"].append(safe_assd(tumor_true, tumor_pred))

    # ---------------- Loss ----------------
    loss_val = model.evaluate(imgs, masks, verbose=0)
    results["loss"].append(loss_val[0])  # only store loss

# ----------------------
# Final Summary
# ----------------------
print("\n==================== FINAL METRICS ====================")
for cls in ["kidney", "tumor"]:
    print(f"\nðŸŽ¯ {cls.upper()} METRICS")
    for metric in ["dice", "iou", "hd95", "assd"]:
        mean_val, sd_val, ci = summary_stats(results[cls][metric])
        print(f"{metric.upper():<6}: {mean_val:.4f} Â± {sd_val:.4f} (95% CI: {ci[0]:.4f} â€“ {ci[1]:.4f})")

# Overall loss
mean_loss, sd_loss, ci_loss = summary_stats(results["loss"])
print(f"\nðŸ’¥ LOSS: {mean_loss:.4f} Â± {sd_loss:.4f} (95% CI: {ci_loss[0]:.4f} â€“ {ci_loss[1]:.4f})")
print("\nâœ… Evaluation complete.")

print(history.history.keys())

import cv2
import numpy as np
import matplotlib.pyplot as plt

# ---------------------------------------------------------
# 1ï¸âƒ£ Load Blood Cell Mask Image
# ---------------------------------------------------------
def load_blood_cell_mask(mask_path, image_size=(256, 256)):
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    if mask is None:
        raise ValueError(f"Mask not found: {mask_path}")
    mask = cv2.resize(mask, image_size).astype(np.uint8)
    return mask

# ---------------------------------------------------------
# 2ï¸âƒ£ Create Segmented Mask Region (Binary Mask)
# ---------------------------------------------------------
def create_mask_region(mask):
    _, binary_mask = cv2.threshold(mask, 128, 255, cv2.THRESH_BINARY)
    binary_mask = binary_mask.astype(np.float32) / 255.0
    return binary_mask

# ---------------------------------------------------------
# 3ï¸âƒ£ Display Mask + Segmented Region
# ---------------------------------------------------------
def display_mask_results(mask, mask_region):
    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1)
    plt.imshow(mask, cmap='gray')
    plt.title("Blood Cell Mask Image")
    plt.axis("off")

    plt.subplot(1, 2, 2)
    plt.imshow(mask_region, cmap='gray')
    plt.title("Segmented Mask Region (Binary)")
    plt.axis("off")

    plt.show()

# ---------------------------------------------------------
# 4ï¸âƒ£ USE BCCD KAGGLE PATHS
# ---------------------------------------------------------
image_path = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/original/002f20ad-2ace-499c-9335-c9080bc3e6b5.png"
mask_path  = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/mask/002f20ad-2ace-499c-9335-c9080bc3e6b5.png"

mask = load_blood_cell_mask(mask_path)
mask_region = create_mask_region(mask)

display_mask_results(mask, mask_region)

# ---------------------------------------------------------
# 5ï¸âƒ£ FIXED â€” Plot Dice & IoU Training Curves
# ---------------------------------------------------------
epochs = range(1, len(history.history['coffiecient_dice']) + 1)

plt.figure(figsize=(10, 4))

# Dice (Correct Key)
plt.subplot(1, 2, 1)
plt.plot(epochs, history.history['coffiecient_dice'], label='Train Dice')
plt.plot(epochs, history.history['val_coffiecient_dice'], label='Val Dice')
plt.xlabel('Epochs')
plt.ylabel('Dice Coefficient')
plt.title('Dice Coefficient Over Epochs')
plt.legend()

# IoU (Correct Key)
plt.subplot(1, 2, 2)
plt.plot(epochs, history.history['iou'], label='Train IoU')
plt.plot(epochs, history.history['val_iou'], label='Val IoU')
plt.xlabel('Epochs')
plt.ylabel('IoU Score')
plt.title('IoU Score Over Epochs')
plt.legend()

plt.tight_layout()
plt.show()

print(history.history.keys())

import tensorflow as tf
from tensorflow.keras import layers, Model, Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import backend as K

def fusion_net(input_shape=(256, 256, 1)):
    inputs = Input(input_shape)
    conv = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)
    conv = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv)
    output = layers.Conv2D(1, (1, 1), activation='sigmoid', padding='same')(conv)
    return Model(inputs=inputs, outputs=output, name="Fusion_Net")

# Function to fuse ConD-PDN and VHU-Net

def fuse_models(cond_pdn_model, vhu_net_model, input_shape=(256, 256, 1)):
    inputs = Input(input_shape)
    
    # Get outputs from both models
    cond_pdn_output = cond_pdn_model(inputs)
    vhu_net_output = vhu_net_model(inputs)
    
    # Fusion step: Averaging outputs
    fused_output = layers.Average()([cond_pdn_output, vhu_net_output])
    
    # Final output layer
    final_output = layers.Conv2D(1, (1, 1), activation='sigmoid', padding='same')(fused_output)
    
    return Model(inputs, final_output, name="Fused_ConD_VHU_Net")

# Instantiate models
input_shape = (256, 256, 1)
cond_pdn_model = cond_pdn(input_shape)
vhu_net_model = VHU_Net_Model(input_shape)

# Fuse the models
fused_model = fuse_models(cond_pdn_model, vhu_net_model, input_shape)

# Define Dice Loss and IoU

def Coffiecient_dice(y_true, y_pred, smooth=100):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    dice = (2 * intersection + smooth) / (union + smooth)
    return dice

def Dice_loss(y_true, y_pred):
    return -Coffiecient_dice(y_true, y_pred)

def Iou(y_true, y_pred, smooth=100):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_pred * y_true)
    union = K.sum(y_true) + K.sum(y_pred)  
    iou = (intersection + smooth) / (union - intersection + smooth)
    return iou

# Compile fused model
learning_rate = 1e-3  
optim = Adam(learning_rate=learning_rate)
fused_model.compile(optimizer=optim, loss=Dice_loss, metrics=[Iou, Coffiecient_dice])

# Print model summary
fused_model.summary()

import tensorflow as tf
from tensorflow.keras import backend as K

# Dice Coefficient
def coefficient_dice(y_true, y_pred, smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    
    dice = (2 * intersection + smooth) / (union + smooth)
    return dice

# Dice Loss (Negative Dice Coefficient)
def dice_loss(y_true, y_pred):
    return -coefficient_dice(y_true, y_pred)

# Intersection over Union (IoU)
def iou(y_true, y_pred, smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    
    iou = (intersection + smooth) / (union - intersection + smooth)
    return iou

# IoU Loss (Negative IoU)
def iou_loss(y_true, y_pred):
    return -iou(y_true, y_pred)
def create_image_generator(data_frame, batch_size, image_color_mode, mask_color_mode, 
                           image_save_prefix, mask_save_prefix, save_to_dir, target_size, seed):
    # Check if columns exist
    if 'img_path' not in data_frame.columns or 'mask_path' not in data_frame.columns:
        raise ValueError("Columns 'img_path' and 'mask_path' not found in dataframe!")

    img_gen = ImageDataGenerator()
    mask_gen = ImageDataGenerator()

    # Generator for images
    img_gen = img_gen.flow_from_dataframe(
        dataframe=data_frame,
        x_col='img_path',  # Ensure this column exists
        class_mode=None,
        color_mode=image_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=image_save_prefix,
        seed=seed
    )

    # Generator for masks
    mask_gen = mask_gen.flow_from_dataframe(
        dataframe=data_frame,
        x_col='mask_path',  # Ensure this column exists
        class_mode=None,
        color_mode=mask_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=mask_save_prefix,
        seed=seed
    )

    return img_gen, mask_gen

EPOCHS = 35

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS,
    verbose=1
)
import numpy as np
from medpy.metric.binary import hd95, assd
import tensorflow as tf

# ----------------------
# Safe Metric Wrappers
# ----------------------
def safe_hd95(y_true, y_pred):
    """Compute HD95, return NaN if empty mask."""
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return hd95(y_pred, y_true)

def safe_assd(y_true, y_pred):
    """Compute ASSD, return NaN if empty mask."""
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return assd(y_pred, y_true)

def threshold(pred):
    """Convert predicted probabilities to binary mask."""
    return (pred > 0.5).astype(np.uint8)

def summary_stats(arr):
    """Calculate mean, SD, 95% CI ignoring NaNs."""
    arr = np.array(arr)
    arr = arr[~np.isnan(arr)]  # remove NaNs
    mean = np.mean(arr)
    sd = np.std(arr)
    ci = 1.96 * sd / np.sqrt(len(arr))
    return mean, sd, (mean-ci, mean+ci)

# ----------------------
# Results dictionary
# ----------------------
results = {
    "kidney": {"dice":[], "iou":[], "hd95":[], "assd":[]},
    "tumor": {"dice":[], "iou":[], "hd95":[], "assd":[]},
    "loss": []  # store per-sample loss if needed
}

# ----------------------
# Loop through test dataset
# ----------------------
print("ðŸ”¹ Evaluating model on test dataset...")
for imgs, masks in test_ds:  # batch size = 1 recommended
    preds = model.predict(imgs)
    preds_bin = threshold(preds)

    masks_np = masks.numpy().astype(np.uint8)

    # ---------------- Kidney Metrics ----------------
    kidney_true = (masks_np == 1).astype(np.uint8)
    kidney_pred = (preds_bin == 1).astype(np.uint8)

    results["kidney"]["dice"].append(dice_np(kidney_true, kidney_pred))
    results["kidney"]["iou"].append(iou_np(kidney_true, kidney_pred))
    results["kidney"]["hd95"].append(safe_hd95(kidney_true, kidney_pred))
    results["kidney"]["assd"].append(safe_assd(kidney_true, kidney_pred))

    # ---------------- Tumor Metrics ----------------
    tumor_true = (masks_np == 2).astype(np.uint8)
    tumor_pred = (preds_bin == 2).astype(np.uint8)

    results["tumor"]["dice"].append(dice_np(tumor_true, tumor_pred))
    results["tumor"]["iou"].append(iou_np(tumor_true, tumor_pred))
    results["tumor"]["hd95"].append(safe_hd95(tumor_true, tumor_pred))
    results["tumor"]["assd"].append(safe_assd(tumor_true, tumor_pred))

    # ---------------- Loss ----------------
    loss_val = model.evaluate(imgs, masks, verbose=0)
    results["loss"].append(loss_val[0])  # only store loss

# ----------------------
# Final Summary
# ----------------------
print("\n==================== FINAL METRICS ====================")
for cls in ["kidney", "tumor"]:
    print(f"\nðŸŽ¯ {cls.upper()} METRICS")
    for metric in ["dice", "iou", "hd95", "assd"]:
        mean_val, sd_val, ci = summary_stats(results[cls][metric])
        print(f"{metric.upper():<6}: {mean_val:.4f} Â± {sd_val:.4f} (95% CI: {ci[0]:.4f} â€“ {ci[1]:.4f})")

# Overall loss
mean_loss, sd_loss, ci_loss = summary_stats(results["loss"])
print(f"\nðŸ’¥ LOSS: {mean_loss:.4f} Â± {sd_loss:.4f} (95% CI: {ci_loss[0]:.4f} â€“ {ci_loss[1]:.4f})")
print("\nâœ… Evaluation complete.")
print(history.history.keys())
import cv2
import numpy as np
import matplotlib.pyplot as plt

# ---------------------------------------------------------
# Create ONLY the FUSED IMAGE
# ---------------------------------------------------------
def create_fused_image(image_path, mask_path, image_size=(256, 256)):
    # Load grayscale blood cell image
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        raise ValueError(f"Image not found: {image_path}")
    img = cv2.resize(img, image_size).astype(np.float32) / 255.0

    # Load segmentation mask
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    if mask is None:
        raise ValueError(f"Mask not found: {mask_path}")
    mask = cv2.resize(mask, image_size).astype(np.uint8)

    # Convert mask â†’ binary
    _, binary_mask = cv2.threshold(mask, 128, 255, cv2.THRESH_BINARY)
    binary_mask = binary_mask.astype(np.float32) / 255.0

    # Fused image: mask = 1 â†’ highlight, background uses segmented image
    fused_image = np.where(binary_mask == 1, 1.0, img * binary_mask)

    return fused_image

# ---------------------------------------------------------
# DISPLAY FUSED IMAGE ONLY
# ---------------------------------------------------------
def display_fused_image(fused_img):
    plt.figure(figsize=(6, 6))
    plt.imshow(fused_img, cmap="gray")
    plt.title("Fused Blood Cell Image")
    plt.axis("off")
    plt.show()

# ---------------------------------------------------------
# USE BCCD KAGGLE PATHS
# ---------------------------------------------------------
image_path = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/original/002f20ad-2ace-499c-9335-c9080bc3e6b5.png"
mask_path  = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/mask/002f20ad-2ace-499c-9335-c9080bc3e6b5.png"

# Generate fused image
fused_img = create_fused_image(image_path, mask_path)

# Display result
display_fused_image(fused_img)
# Extract history
epochs = range(1, len(history.history['coffiecient_dice']) + 1)

# Auto-detect max values
max_dice = max(history.history['coffiecient_dice'] + history.history['val_coffiecient_dice'])
max_iou  = max(history.history['iou'] + history.history['val_iou'])

# Add margin above max
dice_top = max_dice + 0.05
iou_top  = max_iou + 0.05

plt.figure(figsize=(12, 5))

# ---------------- DICE PLOT ----------------
plt.subplot(1, 2, 1)
plt.plot(epochs, history.history['coffiecient_dice'], label='Train Dice', linewidth=2, marker='o')
plt.plot(epochs, history.history['val_coffiecient_dice'], label='Val Dice', linewidth=2, marker='o')

plt.xlabel('Epochs')
plt.ylabel('Dice Coefficient')
plt.title('Dice Coefficient Over Epochs')
plt.ylim(0.2, dice_top)      # <-- auto adjusted
plt.legend()

# ---------------- IOU PLOT ----------------
plt.subplot(1, 2, 2)
plt.plot(epochs, history.history['iou'], label='Train IoU', linewidth=2, marker='o')
plt.plot(epochs, history.history['val_iou'], label='Val IoU', linewidth=2, marker='o')

plt.xlabel('Epochs')
plt.ylabel('IoU Score')
plt.title('IoU Score Over Epochs')
plt.ylim(0.2, iou_top)       # <-- auto adjusted
plt.legend()

plt.tight_layout()
plt.show()

#..................HAM10000 dataset...............................#
#......Dataset 3.....#
import os
os.listdir("/kaggle/input")
['skin-cancer-mnist-ham10000', 'ham10000-lesion-segmentations']

import os
from glob import glob

# ==============================
# Base paths (HAM10000)
# ==============================

# Images (HAM10000 â€“ Part 1 & Part 2)
images_paths = [
    "/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1",
    "/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2",
]

# Masks (HAM10000 Lesion Segmentations)
masks_path = "/kaggle/input/ham10000-lesion-segmentations/HAM10000_segmentations_lesion_tschandl"

# ==============================
# Collect image and mask files
# ==============================

image_files = []
for p in images_paths:
    image_files.extend(glob(os.path.join(p, "*.jpg")))

mask_files = glob(os.path.join(masks_path, "*.png"))

# ==============================
# Print counts
# ==============================

print("Total images:", len(image_files))
print("Total masks :", len(mask_files))

# Tuple output
counts = (len(image_files), len(mask_files))
print("Counts (images, masks):", counts)

import os
from glob import glob

# ==============================
# Paths
# ==============================
images_paths = [
    "/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1",
    "/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2",
]
masks_path = "/kaggle/input/ham10000-lesion-segmentations/HAM10000_segmentations_lesion_tschandl"

# ==============================
# Collect files
# ==============================
image_files = []
for p in images_paths:
    image_files.extend(glob(os.path.join(p, "*.jpg")))

mask_files = glob(os.path.join(masks_path, "*.png"))

# ==============================
# Extract comparable IDs
# ==============================
image_ids = set(os.path.splitext(os.path.basename(f))[0] for f in image_files)
mask_ids  = set(
    os.path.splitext(os.path.basename(f))[0].replace("_segmentation", "")
    for f in mask_files
)

# ==============================
# Pairing
# ==============================
paired_ids      = image_ids & mask_ids
unpaired_images = image_ids - mask_ids
unpaired_masks  = mask_ids - image_ids

# ==============================
# Results
# ==============================
print("Total images :", len(image_ids))
print("Total masks  :", len(mask_ids))
print("Paired image-mask :", len(paired_ids))
print("Unpaired images  :", len(unpaired_images))
print("Unpaired masks   :", len(unpaired_masks))

import os
import pandas as pd
from glob import glob
from sklearn.model_selection import train_test_split

# ==============================
# Dataset paths (HAM10000)
# ==============================

images_paths = [
    "/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1",
    "/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2",
]

masks_path = "/kaggle/input/ham10000-lesion-segmentations/HAM10000_segmentations_lesion_tschandl"

# ==============================
# Collect image files (part 1 + part 2)
# ==============================

image_files = []
for p in images_paths:
    image_files.extend(glob(os.path.join(p, "*.jpg")))

# Collect mask files
mask_files = glob(os.path.join(masks_path, "*.png"))

# ==============================
# Build ID â†’ path mappings
# ==============================

image_dict = {
    os.path.splitext(os.path.basename(f))[0]: f
    for f in image_files
}

mask_dict = {
    os.path.splitext(os.path.basename(f))[0].replace("_segmentation", ""): f
    for f in mask_files
}

# ==============================
# Match imageâ€“mask pairs
# ==============================

common_ids = sorted(image_dict.keys() & mask_dict.keys())

print("Total images:", len(image_dict))
print("Total masks :", len(mask_dict))
print("Paired image-mask:", len(common_ids))

# Create dataframe
df = pd.DataFrame({
    "img_path": [image_dict[i] for i in common_ids],
    "mask_path": [mask_dict[i] for i in common_ids]
})

# ==============================
# Split dataset: 8 : 1 : 1
# ==============================

train_df, temp_df = train_test_split(
    df, test_size=0.2, random_state=42, shuffle=True
)

val_df, test_df = train_test_split(
    temp_df, test_size=0.5, random_state=42, shuffle=True
)

# Reset indices
train_df = train_df.reset_index(drop=True)
val_df   = val_df.reset_index(drop=True)
test_df  = test_df.reset_index(drop=True)

# ==============================
# Summary
# ==============================

print(f"Total samples     : {len(df)}")
print(f"Training samples  : {len(train_df)}")
print(f"Validation samples: {len(val_df)}")
print(f"Test samples      : {len(test_df)}")

# Preview
train_df.head()

import os
import pandas as pd
from glob import glob

def create_df_ham10000(images_dirs, mask_dir):
    img_paths = []
    mask_paths = []

    # Check directories
    for d in images_dirs:
        if not os.path.exists(d):
            raise ValueError(f"Image directory does not exist: {d}")
    if not os.path.exists(mask_dir):
        raise ValueError("Mask directory does not exist.")

    # Collect image files from part 1 & part 2
    image_files = []
    for d in images_dirs:
        image_files.extend(glob(os.path.join(d, "*.jpg")))

    # Collect mask files
    mask_files = glob(os.path.join(mask_dir, "*.png"))

    # Build ID â†’ path mappings
    image_dict = {
        os.path.splitext(os.path.basename(f))[0]: f
        for f in image_files
    }

    mask_dict = {
        os.path.splitext(os.path.basename(f))[0].replace("_segmentation", ""): f
        for f in mask_files
    }

    # Match image-mask pairs
    common_ids = sorted(image_dict.keys() & mask_dict.keys())

    for cid in common_ids:
        img_paths.append(image_dict[cid])
        mask_paths.append(mask_dict[cid])

    # Create DataFrame
    df = pd.DataFrame({
        "img_path": img_paths,
        "mask_path": mask_paths
    })

    return df


# ==============================
# HAM10000 dataset directories
# ==============================

images_dirs = [
    "/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1",
    "/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2",
]

mask_dir = "/kaggle/input/ham10000-lesion-segmentations/HAM10000_segmentations_lesion_tschandl"

# Create dataset DataFrame
df = create_df_ham10000(images_dirs, mask_dir)

# Display sample dataset
print(df.head())

# Counts
print("Total paired samples:", len(df))
print("Total images used :", df["img_path"].nunique())
print("Total masks used  :", df["mask_path"].nunique())

import numpy as np
import cv2

def display_image_shapes_ham10000(df, num_samples=10):
    num_samples = min(num_samples, len(df))  # safety

    # Random sampling
    random_indices = np.random.choice(df.index, size=num_samples, replace=False)
    random_images = df.loc[random_indices, "img_path"].values
    random_masks  = df.loc[random_indices, "mask_path"].values

    for i in range(num_samples):
        # Load HAM10000 image and mask
        image = cv2.imread(random_images[i])  # RGB image
        mask  = cv2.imread(random_masks[i], cv2.IMREAD_GRAYSCALE)  # binary/gray mask

        if image is None or mask is None:
            print(f"Warning: Unable to load image or mask at index {random_indices[i]}")
            continue

        print(
            f"Sample {i+1}: "
            f"Image Shape = {image.shape}, "
            f"Mask Shape = {mask.shape}"
        )

# Run for HAM10000 dataframe
display_image_shapes_ham10000(df)

import os
import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt
import albumentations as A
from glob import glob

# ============================================
# STEP 1 â€” Create DataFrame for HAM10000 images/masks
# ============================================
def create_df_ham10000(images_dirs, mask_dir):
    # Collect images from part 1 + part 2
    image_files = []
    for d in images_dirs:
        image_files.extend(glob(os.path.join(d, "*.jpg")))

    # Collect masks
    mask_files = glob(os.path.join(mask_dir, "*.png"))

    # Build ID â†’ path maps
    image_dict = {
        os.path.splitext(os.path.basename(f))[0]: f
        for f in image_files
    }

    mask_dict = {
        os.path.splitext(os.path.basename(f))[0].replace("_segmentation", ""): f
        for f in mask_files
    }

    # Match pairs using ISIC IDs
    common_ids = sorted(image_dict.keys() & mask_dict.keys())

    df = pd.DataFrame({
        "img_path": [image_dict[i] for i in common_ids],
        "mask_path": [mask_dict[i] for i in common_ids]
    })

    return df


# HAM10000 dataset paths
images_dirs = [
    "/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1",
    "/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2",
]
mask_dir = "/kaggle/input/ham10000-lesion-segmentations/HAM10000_segmentations_lesion_tschandl"

df = create_df_ham10000(images_dirs, mask_dir)
print("Total paired samples:", len(df))

# ============================================
# STEP 2 â€” Visualize random imageâ€“mask pairs
# ============================================
def display_samples(df, num_samples=5):
    num_samples = min(num_samples, len(df))
    random_indices = np.random.choice(df.index, size=num_samples, replace=False)

    fig, axes = plt.subplots(num_samples, 2, figsize=(10, num_samples * 3))

    for i, idx in enumerate(random_indices):
        img = cv2.imread(df.iloc[idx]["img_path"])
        mask = cv2.imread(df.iloc[idx]["mask_path"], cv2.IMREAD_GRAYSCALE)

        axes[i, 0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        axes[i, 0].set_title("Original Image")
        axes[i, 0].axis("off")

        axes[i, 1].imshow(mask, cmap="gray")
        axes[i, 1].set_title("Mask")
        axes[i, 1].axis("off")

    plt.tight_layout()
    plt.show()


display_samples(df, num_samples=5)

# ============================================
# STEP 3 â€” Albumentations augmentation pipeline
# ============================================
augmentation = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.5),
    A.Rotate(limit=20, p=0.5),
    A.RandomBrightnessContrast(p=0.3),
    A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.3),
])

def augment_image(image_path, mask_path):
    image = cv2.imread(image_path)
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

    augmented = augmentation(image=image, mask=mask)
    return augmented["image"], augmented["mask"]

# ============================================
# STEP 4 â€” Display augmented samples
# ============================================
def display_augmented_samples(df, num_samples=5):
    num_samples = min(num_samples, len(df))
    random_indices = np.random.choice(df.index, size=num_samples, replace=False)

    fig, axes = plt.subplots(num_samples, 4, figsize=(15, num_samples * 3))

    for i, idx in enumerate(random_indices):
        img = cv2.imread(df.iloc[idx]["img_path"])
        mask = cv2.imread(df.iloc[idx]["mask_path"], cv2.IMREAD_GRAYSCALE)
        aug_img, aug_mask = augment_image(
            df.iloc[idx]["img_path"],
            df.iloc[idx]["mask_path"]
        )

        axes[i, 0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        axes[i, 0].set_title("Original Image")
        axes[i, 0].axis("off")

        axes[i, 1].imshow(mask, cmap="gray")
        axes[i, 1].set_title("Original Mask")
        axes[i, 1].axis("off")

        axes[i, 2].imshow(cv2.cvtColor(aug_img, cv2.COLOR_BGR2RGB))
        axes[i, 2].set_title("Augmented Image")
        axes[i, 2].axis("off")

        axes[i, 3].imshow(aug_mask, cmap="gray")
        axes[i, 3].set_title("Augmented Mask")
        axes[i, 3].axis("off")

    plt.tight_layout()
    plt.show()


display_augmented_samples(df, num_samples=5)

import os
import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt
import albumentations as A
from sklearn.manifold import TSNE
import umap
from sklearn.decomposition import PCA
import random
from glob import glob

# ===============================
# STEP 1 â€” Preprocessing functions
# ===============================

def apply_clahe(image):
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l = clahe.apply(l)
    lab = cv2.merge((l, a, b))
    return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)

def apply_histogram_equalization(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    equalized = cv2.equalizeHist(gray)
    return cv2.cvtColor(equalized, cv2.COLOR_GRAY2BGR)

# ===============================
# STEP 2 â€” Augmentation pipeline
# ===============================

augmentation = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.5),
    A.Rotate(limit=20, p=0.5),
    A.RandomBrightnessContrast(p=0.3),
    A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.3),
    A.OneOf([
        A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.5),
        A.Equalize(p=0.5)
    ], p=0.5)
])

def augment_image(image):
    return augmentation(image=image)["image"]

# ===============================
# STEP 3 â€” Display preprocessing stages
# ===============================

def display_preprocessing_stages(image1, image2):
    fig, axes = plt.subplots(2, 4, figsize=(20, 10))

    for i, img in enumerate([image1, image2]):
        clahe_img = apply_clahe(img)
        hist_img  = apply_histogram_equalization(img)
        aug_img   = augment_image(img)

        titles = ["Original", "CLAHE", "Histogram Equalization", "Augmented"]
        images = [img, clahe_img, hist_img, aug_img]

        for ax, im, title in zip(axes[i], images, titles):
            ax.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))
            ax.set_title(f"Image {i+1} - {title}")
            ax.axis("off")

    plt.tight_layout()
    plt.show()

# ===============================
# STEP 4 â€” t-SNE / UMAP visualization
# ===============================

def visualize_image_distribution(df, method="tsne"):
    images = np.stack(df["image_pixels"].values)
    images_flat = images.reshape(images.shape[0], -1)

    images_pca = PCA(
        n_components=min(50, images_flat.shape[1])
    ).fit_transform(images_flat)

    if method == "tsne":
        perplexity = min(30, images_pca.shape[0] - 1)
        reducer = TSNE(n_components=2, perplexity=perplexity, random_state=42)
    else:
        reducer = umap.UMAP(n_components=2, random_state=42)

    reduced = reducer.fit_transform(images_pca)

    plt.figure(figsize=(8, 6))
    plt.scatter(reduced[:, 0], reduced[:, 1], alpha=0.7)
    plt.title(f"{method.upper()} Visualization of HAM10000 Images")
    plt.xlabel("Component 1")
    plt.ylabel("Component 2")
    plt.show()

# ===============================
# STEP 5 â€” Select two random HAM10000 images
# ===============================

images_dirs = [
    "/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1",
    "/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2",
]

image_files = []
for d in images_dirs:
    image_files.extend(glob(os.path.join(d, "*.jpg")))

if len(image_files) < 2:
    raise ValueError("Not enough HAM10000 images found.")

# Randomly sample two images
img_paths = random.sample(image_files, 2)
image1 = cv2.imread(img_paths[0])
image2 = cv2.imread(img_paths[1])

if image1 is None or image2 is None:
    raise ValueError("Failed to load HAM10000 images.")

display_preprocessing_stages(image1, image2)

# ===============================
# STEP 6 â€” Prepare HAM10000 data for t-SNE / UMAP
# ===============================

def load_images_for_embedding(image_paths, size=(32, 32), max_samples=50):
    sampled = random.sample(image_paths, min(max_samples, len(image_paths)))
    images = []

    for p in sampled:
        img = cv2.imread(p)
        img = cv2.resize(img, size)
        img = img.astype(np.float32) / 255.0
        images.append(img)

    return images

df = pd.DataFrame({
    "image_pixels": load_images_for_embedding(image_files)
})

visualize_image_distribution(df, method="tsne")
visualize_image_distribution(df, method="umap")

EPOCHS = 35        # keep very low, only for checking pipeline
BATCH_SIZE = 32    # MUST be 1 because dataset has only one sample
learning_rate = 1e-4
w, h = 256, 256   # keep same size as generator target_sizeEPOCHS = 35  

import tensorflow as tf
from tensorflow.keras import layers, Model, backend as K
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Input, SeparableConv2D, MaxPooling2D, Conv2DTranspose, Concatenate, GroupNormalization
import os
from sklearn.model_selection import train_test_split

# -----------------------------
# GPU / Optimization
# -----------------------------
tf.keras.mixed_precision.set_global_policy('float32')  # Disable mixed precision
tf.config.optimizer.set_jit(True)  # Enable XLA for faster execution

def double_conv(x, n_filters):
    x = SeparableConv2D(n_filters, 3, padding='same', activation='relu')(x)
    x = SeparableConv2D(n_filters, 3, padding='same', activation='relu')(x)
    x = GroupNormalization(groups=8)(x)
    return x

def encoder_vit(x, n_filters):
    x = double_conv(x, n_filters)
    p = MaxPooling2D((2,2))(x)
    return x, p

def decoder(x, skip_connection, n_filters):
    x = Conv2DTranspose(n_filters, 3, strides=2, padding='same')(x)
    h_diff = skip_connection.shape[1] - x.shape[1]
    w_diff = skip_connection.shape[2] - x.shape[2]
    if h_diff != 0 or w_diff != 0:
        skip_connection = layers.Cropping2D(
            ((h_diff//2, h_diff-h_diff//2),
             (w_diff//2, w_diff-w_diff//2))
        )(skip_connection)
    x = Concatenate()([x, skip_connection])
    x = double_conv(x, n_filters)
    return x

def VHU_Net_Model(input_shape=(224,224,3)):
    inputs = Input(input_shape)
    s1,p1 = encoder_vit(inputs,16)
    s2,p2 = encoder_vit(p1,32)
    s3,p3 = encoder_vit(p2,64)
    s4,p4 = encoder_vit(p3,128)
    b = double_conv(p4,128)
    b1 = decoder(b,s4,64)
    b2 = decoder(b1,s3,32)
    b3 = decoder(b2,s2,16)
    b4 = decoder(b3,s1,8)
    outputs = SeparableConv2D(1,1,padding='same',activation='sigmoid')(b4)
    return Model(inputs,outputs)

def dice_coefficient(y_true,y_pred,smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_true*y_pred)
    union = K.sum(y_true)+K.sum(y_pred)
    return (2*intersection + smooth)/(union + smooth)

def dice_loss(y_true,y_pred):
    return -dice_coefficient(y_true,y_pred)

def iou(y_true,y_pred,smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_true*y_pred)
    union = K.sum(y_true)+K.sum(y_pred)
    return (intersection + smooth)/(union - intersection + smooth)

def dice_np(y_true, y_pred, smooth=1e-6):
    y_true_f = y_true.flatten()
    y_pred_f = y_pred.flatten()
    intersection = np.sum(y_true_f * y_pred_f)
    return (2 * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)

def iou_np(y_true, y_pred, smooth=1e-6):
    y_true_f = y_true.flatten()
    y_pred_f = y_pred.flatten()
    intersection = np.sum(y_true_f * y_pred_f)
    union = np.sum(y_true_f) + np.sum(y_pred_f) - intersection
    return (intersection + smooth) / (union + smooth)

!pip install medpy
from medpy.metric.binary import hd95, assd

def hd95_np(y_true, y_pred):
    return hd95(y_pred, y_true)

def assd_np(y_true, y_pred):
    return assd(y_pred, y_true)
def safe_hd95(y_true, y_pred):
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return hd95_np(y_true, y_pred)

def safe_assd(y_true, y_pred):
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return assd_np(y_true, y_pred)

import os
import tensorflow as tf
from glob import glob
from sklearn.model_selection import train_test_split

# ============================================
# Imageâ€“mask loader
# ============================================

def load_image_mask(image_path, mask_path, img_size=(224, 224)):
    # Load image
    image = tf.io.read_file(image_path)
    image = tf.image.decode_jpeg(image, channels=3)
    image = tf.image.resize(image, img_size)
    image = tf.cast(image, tf.float32) / 255.0

    # Load mask
    mask = tf.io.read_file(mask_path)
    mask = tf.image.decode_png(mask, channels=1)
    mask = tf.image.resize(mask, img_size, method="nearest")
    mask = tf.cast(mask, tf.float32)

    # Binary mask
    mask = tf.where(mask > 0.5, 1.0, 0.0)

    return image, mask


# ============================================
# Create HAM10000 tf.data datasets
# ============================================

def create_dataset_ham10000(images_dirs, mask_dir, batch_size=8, img_size=(224, 224)):
    # Collect images from part 1 + part 2
    image_files = []
    for d in images_dirs:
        image_files.extend(glob(os.path.join(d, "*.jpg")))

    # Collect masks
    mask_files = glob(os.path.join(mask_dir, "*.png"))

    # Build ID â†’ path maps
    image_dict = {
        os.path.splitext(os.path.basename(f))[0]: f
        for f in image_files
    }

    mask_dict = {
        os.path.splitext(os.path.basename(f))[0].replace("_segmentation", ""): f
        for f in mask_files
    }

    # Match pairs using ISIC IDs
    common_ids = sorted(image_dict.keys() & mask_dict.keys())

    image_paths = [image_dict[i] for i in common_ids]
    mask_paths  = [mask_dict[i] for i in common_ids]

    # ==============================
    # 8 : 1 : 1 split
    # ==============================
    train_img, temp_img, train_mask, temp_mask = train_test_split(
        image_paths, mask_paths, test_size=0.2, random_state=42, shuffle=True
    )

    val_img, test_img, val_mask, test_mask = train_test_split(
        temp_img, temp_mask, test_size=0.5, random_state=42, shuffle=True
    )

    def tf_dataset(images, masks):
        ds = tf.data.Dataset.from_tensor_slices((images, masks))
        ds = ds.map(
            lambda x, y: load_image_mask(x, y, img_size),
            num_parallel_calls=tf.data.AUTOTUNE
        )
        ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)
        return ds

    return (
        tf_dataset(train_img, train_mask),
        tf_dataset(val_img, val_mask),
        tf_dataset(test_img, test_mask),
        len(train_img), len(val_img), len(test_img)
    )


# ============================================
# HAM10000 paths
# ============================================

images_dirs = [
    "/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1",
    "/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2",
]

mask_dir = "/kaggle/input/ham10000-lesion-segmentations/HAM10000_segmentations_lesion_tschandl"

train_ds, val_ds, test_ds, n_train, n_val, n_test = create_dataset_ham10000(
    images_dirs,
    mask_dir,
    batch_size=8,
    img_size=(224, 224)
)

print("Training samples  :", n_train)
print("Validation samples:", n_val)
print("Test samples      :", n_test)

model = VHU_Net_Model(input_shape=(224,224,3))
optim = Adam(learning_rate=1e-3)

model.compile(
    optimizer=optim,
    loss=dice_loss,
    metrics=[dice_coefficient,iou],
    steps_per_execution=5,
    jit_compile=True
)

EPOCHS = 35

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS,
    verbose=1
)
import numpy as np
from medpy.metric.binary import hd95, assd
import tensorflow as tf

# ----------------------
# Safe Metric Wrappers
# ----------------------
def safe_hd95(y_true, y_pred):
    """Compute HD95, return NaN if empty mask."""
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return hd95(y_pred, y_true)

def safe_assd(y_true, y_pred):
    """Compute ASSD, return NaN if empty mask."""
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return assd(y_pred, y_true)

def threshold(pred):
    """Convert predicted probabilities to binary mask."""
    return (pred > 0.5).astype(np.uint8)

def summary_stats(arr):
    """Calculate mean, SD, 95% CI ignoring NaNs."""
    arr = np.array(arr)
    arr = arr[~np.isnan(arr)]  # remove NaNs
    mean = np.mean(arr)
    sd = np.std(arr)
    ci = 1.96 * sd / np.sqrt(len(arr))
    return mean, sd, (mean-ci, mean+ci)

# ----------------------
# Results dictionary
# ----------------------
results = {
    "kidney": {"dice":[], "iou":[], "hd95":[], "assd":[]},
    "tumor": {"dice":[], "iou":[], "hd95":[], "assd":[]},
    "loss": []  # store per-sample loss if needed
}

# ----------------------
# Loop through test dataset
# ----------------------
print("ðŸ”¹ Evaluating model on test dataset...")
for imgs, masks in test_ds:  # batch size = 1 recommended
    preds = model.predict(imgs)
    preds_bin = threshold(preds)

    masks_np = masks.numpy().astype(np.uint8)

    # ---------------- Kidney Metrics ----------------
    kidney_true = (masks_np == 1).astype(np.uint8)
    kidney_pred = (preds_bin == 1).astype(np.uint8)

    results["kidney"]["dice"].append(dice_np(kidney_true, kidney_pred))
    results["kidney"]["iou"].append(iou_np(kidney_true, kidney_pred))
    results["kidney"]["hd95"].append(safe_hd95(kidney_true, kidney_pred))
    results["kidney"]["assd"].append(safe_assd(kidney_true, kidney_pred))

    # ---------------- Tumor Metrics ----------------
    tumor_true = (masks_np == 2).astype(np.uint8)
    tumor_pred = (preds_bin == 2).astype(np.uint8)

    results["tumor"]["dice"].append(dice_np(tumor_true, tumor_pred))
    results["tumor"]["iou"].append(iou_np(tumor_true, tumor_pred))
    results["tumor"]["hd95"].append(safe_hd95(tumor_true, tumor_pred))
    results["tumor"]["assd"].append(safe_assd(tumor_true, tumor_pred))

    # ---------------- Loss ----------------
    loss_val = model.evaluate(imgs, masks, verbose=0)
    results["loss"].append(loss_val[0])  # only store loss

# ----------------------
# Final Summary
# ----------------------
print("\n==================== FINAL METRICS ====================")
for cls in ["kidney", "tumor"]:
    print(f"\nðŸŽ¯ {cls.upper()} METRICS")
    for metric in ["dice", "iou", "hd95", "assd"]:
        mean_val, sd_val, ci = summary_stats(results[cls][metric])
        print(f"{metric.upper():<6}: {mean_val:.4f} Â± {sd_val:.4f} (95% CI: {ci[0]:.4f} â€“ {ci[1]:.4f})")

# Overall loss
mean_loss, sd_loss, ci_loss = summary_stats(results["loss"])
print(f"\nðŸ’¥ LOSS: {mean_loss:.4f} Â± {sd_loss:.4f} (95% CI: {ci_loss[0]:.4f} â€“ {ci_loss[1]:.4f})")
print("\nâœ… Evaluation complete.")


print(history.history.keys())
import cv2
import numpy as np
import matplotlib.pyplot as plt

# ----------------------------------------------
# 1ï¸âƒ£ Load Original HAM10000 Image
# ----------------------------------------------
def load_skin_lesion_image(image_path, image_size=(256, 256)):
    img = cv2.imread(image_path)  # RGB image
    if img is None:
        raise ValueError(f"Image not found: {image_path}")
    img = cv2.resize(img, image_size)
    img = img.astype(np.float32) / 255.0
    return img

# ----------------------------------------------
# 2ï¸âƒ£ Segment Lesion Region using Mask
# ----------------------------------------------
def segment_skin_lesion(mask_path, base_image, image_size=(256, 256)):
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    if mask is None:
        raise ValueError(f"Mask not found: {mask_path}")

    mask = cv2.resize(mask, image_size)

    # Binary mask
    _, binary_mask = cv2.threshold(mask, 128, 255, cv2.THRESH_BINARY)
    binary_mask = binary_mask.astype(np.float32) / 255.0

    # Expand dims to match RGB image
    binary_mask_3c = np.expand_dims(binary_mask, axis=-1)

    # Extract lesion region
    segmented_region = base_image * binary_mask_3c

    return mask, binary_mask, segmented_region

# ----------------------------------------------
# 3ï¸âƒ£ Display Results
# ----------------------------------------------
def display_skin_lesion_results(original_img, mask, segmented_img):
    plt.figure(figsize=(15, 5))

    plt.subplot(1, 3, 1)
    plt.imshow(original_img)
    plt.title("Original Skin Lesion Image")
    plt.axis("off")

    plt.subplot(1, 3, 2)
    plt.imshow(mask, cmap="gray")
    plt.title("Lesion Mask")
    plt.axis("off")

    plt.subplot(1, 3, 3)
    plt.imshow(segmented_img)
    plt.title("Segmented Lesion Region")
    plt.axis("off")

    plt.tight_layout()
    plt.show()

# ----------------------------------------------
# 4ï¸âƒ£ HAM10000 Paths (your exact example)
# ----------------------------------------------
image_path = "/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1/ISIC_0024306.jpg"
mask_path  = "/kaggle/input/ham10000-lesion-segmentations/HAM10000_segmentations_lesion_tschandl/ISIC_0024306_segmentation.png"

# Load + segment
original_img = load_skin_lesion_image(image_path)
mask, mask_binary, segmented_region = segment_skin_lesion(mask_path, original_img)

# Display output
display_skin_lesion_results(original_img, mask, segmented_region)

# ----------------------------------------------
# 5ï¸âƒ£ Plot Dice & IoU Training Curves
# ----------------------------------------------
# (Assumes `history` from model.fit exists)

epochs = range(1, len(history.history["dice_coefficient"]) + 1)

plt.figure(figsize=(12, 4))

# Dice Coefficient
plt.subplot(1, 2, 1)
plt.plot(epochs, history.history["dice_coefficient"], label="Train Dice")
plt.plot(epochs, history.history["val_dice_coefficient"], label="Val Dice")
plt.xlabel("Epochs")
plt.ylabel("Dice Coefficient")
plt.title("Dice Coefficient Over Epochs")
plt.legend()

# IoU
plt.subplot(1, 2, 2)
plt.plot(epochs, history.history["iou"], label="Train IoU")
plt.plot(epochs, history.history["val_iou"], label="Val IoU")
plt.xlabel("Epochs")
plt.ylabel("IoU Score")
plt.title("IoU Score Over Epochs")
plt.legend()

plt.tight_layout()
plt.show()

# Show available metrics
print(history.history.keys())

import tensorflow as tf
from tensorflow.keras import layers, Model, Input
from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, Reshape, Multiply

# Criss-Cross Attention
def criss_cross_attention(x):
    avg_pool = GlobalAveragePooling2D()(x)
    avg_pool = Reshape((1, 1, x.shape[-1]))(avg_pool)
    avg_pool = Conv2D(x.shape[-1], 1, padding='same', activation='sigmoid')(avg_pool)
    return Multiply()([x, avg_pool])

# Define Encoder Block (Using a standard convolutional approach)
def encoder_block(x, filters):
    conv = Conv2D(filters, (3, 3), activation='relu', padding='same')(x)
    conv = Conv2D(filters, (3, 3), activation='relu', padding='same')(conv)
    return conv, layers.MaxPooling2D(pool_size=(2, 2))(conv)

# Define Decoder Block
def decoder_block(x, skip, filters):
    up = layers.UpSampling2D(size=(2, 2))(x)
    merge = layers.Concatenate()([up, skip])
    conv = Conv2D(filters, (3, 3), activation='relu', padding='same')(merge)
    conv = Conv2D(filters, (3, 3), activation='relu', padding='same')(conv)
    return conv

# Define ConD-PDN Model
def cond_pdn(input_shape=(256, 256, 1)):
    inputs = Input(input_shape)

    # Encoder
    s1, p1 = encoder_block(inputs, 64)
    s2, p2 = encoder_block(p1, 128)
    s3, p3 = encoder_block(p2, 256)
    s4, p4 = encoder_block(p3, 512)

    # Bridge with Criss-Cross Attention
    b = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)
    b = Conv2D(1024, (3, 3), activation='relu', padding='same')(b)
    b = criss_cross_attention(b)

    # Decoder
    d1 = decoder_block(b, s4, 512)
    d2 = decoder_block(d1, s3, 256)
    d3 = decoder_block(d2, s2, 128)
    d4 = decoder_block(d3, s1, 64)

    # Output Layer
    outputs = Conv2D(1, (1, 1), activation='sigmoid', padding='same')(d4)

    # Create Model
    model = Model(inputs, outputs, name='ConD_PDN_with_cca')

    return model

# **Dice Coefficient**
def Coffiecient_dice(y_true, y_pred, smooth=100):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    dice = (2 * intersection + smooth) / (union + smooth)
    return dice

# **Dice Loss**
def Dice_loss(y_true, y_pred):
    return -Coffiecient_dice(y_true, y_pred)

# **IoU Metric**
def Iou(y_true, y_pred, smooth=100):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_pred * y_true)
    union = K.sum(y_true) + K.sum(y_pred)  
    iou = (intersection + smooth) / (union - intersection + smooth)
    return iou

# Define learning rate
learning_rate = 1e-3  

# Initialize optimizer
optim = Adam(learning_rate=learning_rate)

# Compile the model
model.compile(optimizer=optim, loss=Dice_loss, metrics=[Iou, Coffiecient_dice])
model.summary()
import tensorflow as tf
from tensorflow.keras import backend as K

# Dice Coefficient
def coefficient_dice(y_true, y_pred, smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    
    dice = (2 * intersection + smooth) / (union + smooth)
    return dice

# Dice Loss (Negative Dice Coefficient)
def dice_loss(y_true, y_pred):
    return -coefficient_dice(y_true, y_pred)

# Intersection over Union (IoU)
def iou(y_true, y_pred, smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    
    iou = (intersection + smooth) / (union - intersection + smooth)
    return iou

# IoU Loss (Negative IoU)
def iou_loss(y_true, y_pred):
    return -iou(y_true, y_pred)

def create_image_generator(data_frame, batch_size, image_color_mode, mask_color_mode, 
                           image_save_prefix, mask_save_prefix, save_to_dir, target_size, seed):
    # Check if columns exist
    if 'img_path' not in data_frame.columns or 'mask_path' not in data_frame.columns:
        raise ValueError("Columns 'img_path' and 'mask_path' not found in dataframe!")

    img_gen = ImageDataGenerator()
    mask_gen = ImageDataGenerator()

    # Generator for images
    img_gen = img_gen.flow_from_dataframe(
        dataframe=data_frame,
        x_col='img_path',  # Ensure this column exists
        class_mode=None,
        color_mode=image_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=image_save_prefix,
        seed=seed
    )

    # Generator for masks
    mask_gen = mask_gen.flow_from_dataframe(
        dataframe=data_frame,
        x_col='mask_path',  # Ensure this column exists
        class_mode=None,
        color_mode=mask_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=mask_save_prefix,
        seed=seed
    )

    return img_gen, mask_gen

EPOCHS = 35

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS,
    verbose=1
)
import numpy as np
from medpy.metric.binary import hd95, assd
import tensorflow as tf

# ----------------------
# Safe Metric Wrappers
# ----------------------
def safe_hd95(y_true, y_pred):
    """Compute HD95, return NaN if empty mask."""
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return hd95(y_pred, y_true)

def safe_assd(y_true, y_pred):
    """Compute ASSD, return NaN if empty mask."""
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return assd(y_pred, y_true)

def threshold(pred):
    """Convert predicted probabilities to binary mask."""
    return (pred > 0.5).astype(np.uint8)

def summary_stats(arr):
    """Calculate mean, SD, 95% CI ignoring NaNs."""
    arr = np.array(arr)
    arr = arr[~np.isnan(arr)]  # remove NaNs
    mean = np.mean(arr)
    sd = np.std(arr)
    ci = 1.96 * sd / np.sqrt(len(arr))
    return mean, sd, (mean-ci, mean+ci)

# ----------------------
# Results dictionary
# ----------------------
results = {
    "kidney": {"dice":[], "iou":[], "hd95":[], "assd":[]},
    "tumor": {"dice":[], "iou":[], "hd95":[], "assd":[]},
    "loss": []  # store per-sample loss if needed
}

# ----------------------
# Loop through test dataset
# ----------------------
print("ðŸ”¹ Evaluating model on test dataset...")
for imgs, masks in test_ds:  # batch size = 1 recommended
    preds = model.predict(imgs)
    preds_bin = threshold(preds)

    masks_np = masks.numpy().astype(np.uint8)

    # ---------------- Kidney Metrics ----------------
    kidney_true = (masks_np == 1).astype(np.uint8)
    kidney_pred = (preds_bin == 1).astype(np.uint8)

    results["kidney"]["dice"].append(dice_np(kidney_true, kidney_pred))
    results["kidney"]["iou"].append(iou_np(kidney_true, kidney_pred))
    results["kidney"]["hd95"].append(safe_hd95(kidney_true, kidney_pred))
    results["kidney"]["assd"].append(safe_assd(kidney_true, kidney_pred))

    # ---------------- Tumor Metrics ----------------
    tumor_true = (masks_np == 2).astype(np.uint8)
    tumor_pred = (preds_bin == 2).astype(np.uint8)

    results["tumor"]["dice"].append(dice_np(tumor_true, tumor_pred))
    results["tumor"]["iou"].append(iou_np(tumor_true, tumor_pred))
    results["tumor"]["hd95"].append(safe_hd95(tumor_true, tumor_pred))
    results["tumor"]["assd"].append(safe_assd(tumor_true, tumor_pred))

    # ---------------- Loss ----------------
    loss_val = model.evaluate(imgs, masks, verbose=0)
    results["loss"].append(loss_val[0])  # only store loss

# ----------------------
# Final Summary
# ----------------------
print("\n==================== FINAL METRICS ====================")
for cls in ["kidney", "tumor"]:
    print(f"\nðŸŽ¯ {cls.upper()} METRICS")
    for metric in ["dice", "iou", "hd95", "assd"]:
        mean_val, sd_val, ci = summary_stats(results[cls][metric])
        print(f"{metric.upper():<6}: {mean_val:.4f} Â± {sd_val:.4f} (95% CI: {ci[0]:.4f} â€“ {ci[1]:.4f})")

# Overall loss
mean_loss, sd_loss, ci_loss = summary_stats(results["loss"])
print(f"\nðŸ’¥ LOSS: {mean_loss:.4f} Â± {sd_loss:.4f} (95% CI: {ci_loss[0]:.4f} â€“ {ci_loss[1]:.4f})")
print("\nâœ… Evaluation complete.")

print(history.history.keys())
import cv2
import numpy as np
import matplotlib.pyplot as plt

# ---------------------------------------------------------
# 1ï¸âƒ£ Load HAM10000 Lesion Mask Image
# ---------------------------------------------------------
def load_lesion_mask(mask_path, image_size=(256, 256)):
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    if mask is None:
        raise ValueError(f"Mask not found: {mask_path}")
    mask = cv2.resize(mask, image_size).astype(np.uint8)
    return mask

# ---------------------------------------------------------
# 2ï¸âƒ£ Create Segmented Mask Region (Binary Mask)
# ---------------------------------------------------------
def create_mask_region(mask):
    _, binary_mask = cv2.threshold(mask, 128, 255, cv2.THRESH_BINARY)
    binary_mask = binary_mask.astype(np.float32) / 255.0
    return binary_mask

# ---------------------------------------------------------
# 3ï¸âƒ£ Display Mask + Binary Mask
# ---------------------------------------------------------
def display_mask_results(mask, mask_region):
    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1)
    plt.imshow(mask, cmap="gray")
    plt.title("Lesion Mask Image")
    plt.axis("off")

    plt.subplot(1, 2, 2)
    plt.imshow(mask_region, cmap="gray")
    plt.title("Binary Lesion Mask")
    plt.axis("off")

    plt.tight_layout()
    plt.show()

# ---------------------------------------------------------
# 4ï¸âƒ£ HAM10000 Paths (your example)
# ---------------------------------------------------------
mask_path = (
    "/kaggle/input/ham10000-lesion-segmentations/"
    "HAM10000_segmentations_lesion_tschandl/"
    "ISIC_0024306_segmentation.png"
)

mask = load_lesion_mask(mask_path)
mask_region = create_mask_region(mask)

display_mask_results(mask, mask_region)

# ---------------------------------------------------------
# 5ï¸âƒ£ Plot Dice & IoU Training Curves
# ---------------------------------------------------------
# (Assumes `history` from model.fit exists)

epochs = range(1, len(history.history["coffiecient_dice"]) + 1)

plt.figure(figsize=(10, 4))

# Dice
plt.subplot(1, 2, 1)
plt.plot(epochs, history.history["coffiecient_dice"], label="Train Dice")
plt.plot(epochs, history.history["val_coffiecient_dice"], label="Val Dice")
plt.xlabel("Epochs")
plt.ylabel("Dice Coefficient")
plt.title("Dice Coefficient Over Epochs")
plt.legend()

# IoU
plt.subplot(1, 2, 2)
plt.plot(epochs, history.history["iou"], label="Train IoU")
plt.plot(epochs, history.history["val_iou"], label="Val IoU")
plt.xlabel("Epochs")
plt.ylabel("IoU Score")
plt.title("IoU Score Over Epochs")
plt.legend()

plt.tight_layout()
plt.show()

print(history.history.keys())

import tensorflow as tf
from tensorflow.keras import layers, Model, Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import backend as K

def fusion_net(input_shape=(256, 256, 1)):
    inputs = Input(input_shape)
    conv = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)
    conv = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv)
    output = layers.Conv2D(1, (1, 1), activation='sigmoid', padding='same')(conv)
    return Model(inputs=inputs, outputs=output, name="Fusion_Net")

# Function to fuse ConD-PDN and VHU-Net

def fuse_models(cond_pdn_model, vhu_net_model, input_shape=(256, 256, 1)):
    inputs = Input(input_shape)
    
    # Get outputs from both models
    cond_pdn_output = cond_pdn_model(inputs)
    vhu_net_output = vhu_net_model(inputs)
    
    # Fusion step: Averaging outputs
    fused_output = layers.Average()([cond_pdn_output, vhu_net_output])
    
    # Final output layer
    final_output = layers.Conv2D(1, (1, 1), activation='sigmoid', padding='same')(fused_output)
    
    return Model(inputs, final_output, name="Fused_ConD_VHU_Net")

# Instantiate models
input_shape = (256, 256, 1)
cond_pdn_model = cond_pdn(input_shape)
vhu_net_model = VHU_Net_Model(input_shape)

# Fuse the models
fused_model = fuse_models(cond_pdn_model, vhu_net_model, input_shape)

# Define Dice Loss and IoU

def Coffiecient_dice(y_true, y_pred, smooth=100):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    dice = (2 * intersection + smooth) / (union + smooth)
    return dice

def Dice_loss(y_true, y_pred):
    return -Coffiecient_dice(y_true, y_pred)

def Iou(y_true, y_pred, smooth=100):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_pred * y_true)
    union = K.sum(y_true) + K.sum(y_pred)  
    iou = (intersection + smooth) / (union - intersection + smooth)
    return iou

# Compile fused model
learning_rate = 1e-3  
optim = Adam(learning_rate=learning_rate)
fused_model.compile(optimizer=optim, loss=Dice_loss, metrics=[Iou, Coffiecient_dice])

# Print model summary
fused_model.summary()

import tensorflow as tf
from tensorflow.keras import backend as K

# Dice Coefficient
def coefficient_dice(y_true, y_pred, smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    
    dice = (2 * intersection + smooth) / (union + smooth)
    return dice

# Dice Loss (Negative Dice Coefficient)
def dice_loss(y_true, y_pred):
    return -coefficient_dice(y_true, y_pred)

# Intersection over Union (IoU)
def iou(y_true, y_pred, smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    
    iou = (intersection + smooth) / (union - intersection + smooth)
    return iou

# IoU Loss (Negative IoU)
def iou_loss(y_true, y_pred):
    return -iou(y_true, y_pred)

def create_image_generator(data_frame, batch_size, image_color_mode, mask_color_mode, 
                           image_save_prefix, mask_save_prefix, save_to_dir, target_size, seed):
    # Check if columns exist
    if 'img_path' not in data_frame.columns or 'mask_path' not in data_frame.columns:
        raise ValueError("Columns 'img_path' and 'mask_path' not found in dataframe!")

    img_gen = ImageDataGenerator()
    mask_gen = ImageDataGenerator()

    # Generator for images
    img_gen = img_gen.flow_from_dataframe(
        dataframe=data_frame,
        x_col='img_path',  # Ensure this column exists
        class_mode=None,
        color_mode=image_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=image_save_prefix,
        seed=seed
    )

    # Generator for masks
    mask_gen = mask_gen.flow_from_dataframe(
        dataframe=data_frame,
        x_col='mask_path',  # Ensure this column exists
        class_mode=None,
        color_mode=mask_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=mask_save_prefix,
        seed=seed
    )

    return img_gen, mask_gen

EPOCHS = 35

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS,
    verbose=1
)
import numpy as np
from medpy.metric.binary import hd95, assd
import tensorflow as tf

# ----------------------
# Safe Metric Wrappers
# ----------------------
def safe_hd95(y_true, y_pred):
    """Compute HD95, return NaN if empty mask."""
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return hd95(y_pred, y_true)

def safe_assd(y_true, y_pred):
    """Compute ASSD, return NaN if empty mask."""
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return assd(y_pred, y_true)

def threshold(pred):
    """Convert predicted probabilities to binary mask."""
    return (pred > 0.5).astype(np.uint8)

def summary_stats(arr):
    """Calculate mean, SD, 95% CI ignoring NaNs."""
    arr = np.array(arr)
    arr = arr[~np.isnan(arr)]  # remove NaNs
    mean = np.mean(arr)
    sd = np.std(arr)
    ci = 1.96 * sd / np.sqrt(len(arr))
    return mean, sd, (mean-ci, mean+ci)

# ----------------------
# Results dictionary
# ----------------------
results = {
    "kidney": {"dice":[], "iou":[], "hd95":[], "assd":[]},
    "tumor": {"dice":[], "iou":[], "hd95":[], "assd":[]},
    "loss": []  # store per-sample loss if needed
}

# ----------------------
# Loop through test dataset
# ----------------------
print("ðŸ”¹ Evaluating model on test dataset...")
for imgs, masks in test_ds:  # batch size = 1 recommended
    preds = model.predict(imgs)
    preds_bin = threshold(preds)

    masks_np = masks.numpy().astype(np.uint8)

    # ---------------- Kidney Metrics ----------------
    kidney_true = (masks_np == 1).astype(np.uint8)
    kidney_pred = (preds_bin == 1).astype(np.uint8)

    results["kidney"]["dice"].append(dice_np(kidney_true, kidney_pred))
    results["kidney"]["iou"].append(iou_np(kidney_true, kidney_pred))
    results["kidney"]["hd95"].append(safe_hd95(kidney_true, kidney_pred))
    results["kidney"]["assd"].append(safe_assd(kidney_true, kidney_pred))

    # ---------------- Tumor Metrics ----------------
    tumor_true = (masks_np == 2).astype(np.uint8)
    tumor_pred = (preds_bin == 2).astype(np.uint8)

    results["tumor"]["dice"].append(dice_np(tumor_true, tumor_pred))
    results["tumor"]["iou"].append(iou_np(tumor_true, tumor_pred))
    results["tumor"]["hd95"].append(safe_hd95(tumor_true, tumor_pred))
    results["tumor"]["assd"].append(safe_assd(tumor_true, tumor_pred))

    # ---------------- Loss ----------------
    loss_val = model.evaluate(imgs, masks, verbose=0)
    results["loss"].append(loss_val[0])  # only store loss

# ----------------------
# Final Summary
# ----------------------
print("\n==================== FINAL METRICS ====================")
for cls in ["kidney", "tumor"]:
    print(f"\nðŸŽ¯ {cls.upper()} METRICS")
    for metric in ["dice", "iou", "hd95", "assd"]:
        mean_val, sd_val, ci = summary_stats(results[cls][metric])
        print(f"{metric.upper():<6}: {mean_val:.4f} Â± {sd_val:.4f} (95% CI: {ci[0]:.4f} â€“ {ci[1]:.4f})")

# Overall loss
mean_loss, sd_loss, ci_loss = summary_stats(results["loss"])
print(f"\nðŸ’¥ LOSS: {mean_loss:.4f} Â± {sd_loss:.4f} (95% CI: {ci_loss[0]:.4f} â€“ {ci_loss[1]:.4f})")
print("\nâœ… Evaluation complete.")
print(history.history.keys())

import cv2
import numpy as np
import matplotlib.pyplot as plt

# ----------------------------------------------
# 1ï¸âƒ£ Load HAM10000 Image
# ----------------------------------------------
def load_skin_image(image_path, image_size=(256, 256)):
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError(f"Image not found: {image_path}")
    img = cv2.resize(img, image_size)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # convert to grayscale
    img = img.astype(np.float32) / 255.0
    return img

# ----------------------------------------------
# 2ï¸âƒ£ Load & Binarize Lesion Mask
# ----------------------------------------------
def load_binary_lesion_mask(mask_path, image_size=(256, 256)):
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    if mask is None:
        raise ValueError(f"Mask not found: {mask_path}")
    mask = cv2.resize(mask, image_size)
    _, binary_mask = cv2.threshold(mask, 128, 1, cv2.THRESH_BINARY)
    return binary_mask.astype(np.float32)

# ----------------------------------------------
# 3ï¸âƒ£ Fuse Skin + Lesion
# ----------------------------------------------
def fuse_lesion_regions(skin_region, lesion_mask):
    """
    Lesion pixels â†’ white (1)
    Skin pixels   â†’ grayscale skin
    """
    fused = np.where(lesion_mask == 1, 1.0, skin_region)
    return fused

# ----------------------------------------------
# 4ï¸âƒ£ Display Fusion Results
# ----------------------------------------------
def display_fused_only(skin_region, lesion_mask, fused_image):
    plt.figure(figsize=(18, 5))

    plt.subplot(1, 3, 1)
    plt.imshow(skin_region, cmap="gray")
    plt.title("Skin Region (Grayscale)")
    plt.axis("off")

    plt.subplot(1, 3, 2)
    plt.imshow(lesion_mask, cmap="gray")
    plt.title("Lesion Mask (Binary)")
    plt.axis("off")

    plt.subplot(1, 3, 3)
    plt.imshow(fused_image, cmap="gray")
    plt.title("Fused Skin + Lesion")
    plt.axis("off")

    plt.tight_layout()
    plt.show()

# ----------------------------------------------
# 5ï¸âƒ£ HAM10000 SAMPLE PATHS
# ----------------------------------------------
image_path = "/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1/ISIC_0024306.jpg"
mask_path  = "/kaggle/input/ham10000-lesion-segmentations/HAM10000_segmentations_lesion_tschandl/ISIC_0024306_segmentation.png"

# ----------------------------------------------
# 6ï¸âƒ£ CREATE REQUIRED VARIABLES (FIX)
# ----------------------------------------------
skin_region = load_skin_image(image_path)
lesion_mask = load_binary_lesion_mask(mask_path)

# ----------------------------------------------
# 7ï¸âƒ£ FUSE & DISPLAY
# ----------------------------------------------
fused_output = fuse_lesion_regions(skin_region, lesion_mask)
display_fused_only(skin_region, lesion_mask, fused_output)

# Extract history
epochs = range(1, len(history.history['coffiecient_dice']) + 1)

# Auto-detect max values
max_dice = max(history.history['coffiecient_dice'] + history.history['val_coffiecient_dice'])
max_iou  = max(history.history['iou'] + history.history['val_iou'])

# Add margin above max
dice_top = max_dice + 0.05
iou_top  = max_iou + 0.05

plt.figure(figsize=(12, 5))

# ---------------- DICE PLOT ----------------
plt.subplot(1, 2, 1)
plt.plot(epochs, history.history['coffiecient_dice'], label='Train Dice', linewidth=2, marker='o')
plt.plot(epochs, history.history['val_coffiecient_dice'], label='Val Dice', linewidth=2, marker='o')

plt.xlabel('Epochs')
plt.ylabel('Dice Coefficient')
plt.title('Dice Coefficient Over Epochs')
plt.ylim(0.2, dice_top)      # <-- auto adjusted
plt.legend()

# ---------------- IOU PLOT ----------------
plt.subplot(1, 2, 2)
plt.plot(epochs, history.history['iou'], label='Train IoU', linewidth=2, marker='o')
plt.plot(epochs, history.history['val_iou'], label='Val IoU', linewidth=2, marker='o')

plt.xlabel('Epochs')
plt.ylabel('IoU Score')
plt.title('IoU Score Over Epochs')
plt.ylim(0.2, iou_top)       # <-- auto adjusted
plt.legend()

plt.tight_layout()
plt.show()
import cv2
import numpy as np
import matplotlib.pyplot as plt

# -------------------------------------
# 1ï¸âƒ£ LOAD FUSED HAM10000 IMAGE
# -------------------------------------
# Use the fused output saved or recomputed image
# (Example: ISIC_0024306 fused image)

image_path = (
    "/kaggle/input/skin-cancer-mnist-ham10000/"
    "HAM10000_images_part_1/ISIC_0024306.jpg"
)

mask_path = (
    "/kaggle/input/ham10000-lesion-segmentations/"
    "HAM10000_segmentations_lesion_tschandl/"
    "ISIC_0024306_segmentation.png"
)

# Load image (grayscale)
image = cv2.imread(image_path)
image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
image = cv2.resize(image, (256, 256)).astype(np.float32) / 255.0

# Load and binarize mask
mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
mask = cv2.resize(mask, (256, 256))
_, mask = cv2.threshold(mask, 128, 1, cv2.THRESH_BINARY)

# Create fused image (lesion = bright)
fused = np.where(mask == 1, 1.0, image)

# -------------------------------------
# 2ï¸âƒ£ NORMAL HEATMAP (NO MODEL)
# -------------------------------------
# Scale fused image to 0â€“255
norm_img = cv2.normalize(fused, None, 0, 255, cv2.NORM_MINMAX)
norm_img = norm_img.astype(np.uint8)

# Apply color map
heatmap = cv2.applyColorMap(norm_img, cv2.COLORMAP_JET)

# Overlay: 60% fused + 40% heatmap
overlay = cv2.addWeighted(
    cv2.cvtColor(norm_img, cv2.COLOR_GRAY2BGR),
    0.6,
    heatmap,
    0.4,
    0
)

# -------------------------------------
# 3ï¸âƒ£ DISPLAY RESULTS
# -------------------------------------
plt.figure(figsize=(12, 4))

plt.subplot(1, 3, 1)
plt.title("Fused Image (Skin + Lesion)")
plt.imshow(norm_img, cmap="gray")
plt.axis("off")

plt.subplot(1, 3, 2)
plt.title("Heatmap")
plt.imshow(heatmap)
plt.axis("off")

plt.subplot(1, 3, 3)
plt.title("Overlay (Fused + Heatmap)")
plt.imshow(overlay)
plt.axis("off")

plt.tight_layout()
plt.show()

!nvidia-smi
