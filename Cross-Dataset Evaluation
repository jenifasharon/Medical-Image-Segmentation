#................HAM10000 and Blood Cell it contain Table 9 result...........#

#...........Blood cell dataset..................#
import os
os.listdir("/kaggle/input")
#........................['bccd-dataset-with-mask']...................#

import os
from glob import glob

# Base BCCD dataset path
dataset_base = '/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/'

# Paths to images and masks
images_path = os.path.join(dataset_base, 'original')
masks_path = os.path.join(dataset_base, 'mask')

# Get all files
image_files = glob(os.path.join(images_path, '*'))
mask_files = glob(os.path.join(masks_path, '*'))

# Print counts
print("Total images:", len(image_files))
print("Total masks:", len(mask_files))

# If you want them in a tuple
counts = (len(image_files), len(mask_files))
print("Counts (images, masks):", counts)
#..............Total images: 1169
Total masks: 1169
Counts (images, masks): (1169, 1169).........................#

import os
import pandas as pd
from sklearn.model_selection import train_test_split

# ==============================
# Dataset directories (BCCD)
# ==============================
base_dir = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train"

image_dir = os.path.join(base_dir, "original")   # images
mask_dir  = os.path.join(base_dir, "mask")       # masks

# ==============================
# Gather files and match images to masks
# ==============================
image_files = sorted([
    os.path.join(image_dir, f)
    for f in os.listdir(image_dir)
    if f.lower().endswith(('.png', '.jpg', '.jpeg'))
])

mask_files = sorted([
    os.path.join(mask_dir, f)
    for f in os.listdir(mask_dir)
    if f.lower().endswith(('.png', '.jpg', '.jpeg'))
])

if len(image_files) != len(mask_files):
    print(f"Warning: {len(image_files)} images vs {len(mask_files)} masks")

# Create dataframe
df = pd.DataFrame({
    'img_path': image_files,
    'mask_path': mask_files
})

# ==============================
# Split dataset: 8:1:1
# ==============================
train_df, temp_df = train_test_split(
    df, test_size=0.2, random_state=42, shuffle=True
)

val_df, test_df = train_test_split(
    temp_df, test_size=0.5, random_state=42, shuffle=True
)

# Reset indices
train_df = train_df.reset_index(drop=True)
val_df   = val_df.reset_index(drop=True)
test_df  = test_df.reset_index(drop=True)

# ==============================
# Summary
# ==============================
print(f"Total samples: {len(df)}")
print(f"Training samples: {len(train_df)}")
print(f"Validation samples: {len(val_df)}")
print(f"Test samples: {len(test_df)}")

# Optional: show first 5 rows
train_df.head()


import os
import pandas as pd

def create_df(image_dir, mask_dir):
    img_paths = []
    mask_paths = []
    
    # Ensure directories exist
    if not os.path.exists(image_dir) or not os.path.exists(mask_dir):
        raise ValueError("The specified directories do not exist.")
    
    # Get sorted lists of images and masks
    image_files = sorted(os.listdir(image_dir))
    mask_files = sorted(os.listdir(mask_dir))

    # Ensure matching images and masks
    for img_file, mask_file in zip(image_files, mask_files):
        img_paths.append(os.path.join(image_dir, img_file))
        mask_paths.append(os.path.join(mask_dir, mask_file))

    # Create DataFrame
    df = pd.DataFrame({'img_path': img_paths, 'mask_path': mask_paths})
    return df

# ==============================
# BCCD dataset directories
# ==============================
image_dir = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/original"
mask_dir  = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/mask"

# Create dataset DataFrame
df = create_df(image_dir, mask_dir)

# Display sample dataset
print(df.head())

# Optional: check lengths
print("Total images:", len(df))
print("Total masks:", len(df))


import numpy as np
import cv2

def display_image_shapes(df, num_samples=10):
    num_samples = min(num_samples, len(df))  # Ensure valid range

    # Random sampling
    random_indices = np.random.choice(df.index, size=num_samples, replace=False)
    random_images = df.iloc[random_indices]['img_path'].values
    random_masks = df.iloc[random_indices]['mask_path'].values

    for i in range(num_samples):
        # Load BCCD images + masks
        image = cv2.imread(random_images[i])
        mask = cv2.imread(random_masks[i], cv2.IMREAD_GRAYSCALE)

        if image is None or mask is None:
            print(f"Warning: Unable to load image or mask at index {random_indices[i]}")
            continue

        print(f"Sample {i+1}: Image Shape = {image.shape}, Mask Shape = {mask.shape}")

# Run for BCCD dataframe
display_image_shapes(df)
import os
import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt
import albumentations as A

# ============================================
# STEP 1 â€” Create DataFrame for BCCD images/masks
# ============================================
def create_df(image_dir, mask_dir):
    img_paths = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir)])
    mask_paths = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir)])
    return pd.DataFrame({'img_path': img_paths, 'mask_path': mask_paths})

# BCCD dataset paths
image_dir = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/original"
mask_dir  = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/mask"

df = create_df(image_dir, mask_dir)
print("Total images:", len(df))

# ============================================
# STEP 2 â€” Visualize random imageâ€“mask pairs
# ============================================
def display_samples(df, num_samples=5):
    random_indices = np.random.choice(df.index, size=num_samples, replace=False)
    fig, axes = plt.subplots(num_samples, 2, figsize=(10, num_samples * 3))

    for i, idx in enumerate(random_indices):
        img = cv2.imread(df.iloc[idx]['img_path'])
        mask = cv2.imread(df.iloc[idx]['mask_path'], cv2.IMREAD_GRAYSCALE)

        axes[i, 0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        axes[i, 0].set_title("Original Image")
        axes[i, 0].axis("off")

        axes[i, 1].imshow(mask, cmap="gray")
        axes[i, 1].set_title("Mask")
        axes[i, 1].axis("off")

    plt.tight_layout()
    plt.show()

display_samples(df, num_samples=5)

# ============================================
# STEP 3 â€” Albumentations augmentation pipeline
# ============================================
augmentation = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.5),
    A.Rotate(limit=20, p=0.5),
    A.RandomBrightnessContrast(p=0.3),
    A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.3),
])

def augment_image(image_path, mask_path):
    image = cv2.imread(image_path)
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    augmented = augmentation(image=image, mask=mask)
    return augmented['image'], augmented['mask']

# ============================================
# STEP 4 â€” Display augmented samples
# ============================================
def display_augmented_samples(df, num_samples=5):
    random_indices = np.random.choice(df.index, size=num_samples, replace=False)
    fig, axes = plt.subplots(num_samples, 4, figsize=(15, num_samples * 3))

    for i, idx in enumerate(random_indices):
        img = cv2.imread(df.iloc[idx]['img_path'])
        mask = cv2.imread(df.iloc[idx]['mask_path'], cv2.IMREAD_GRAYSCALE)
        aug_img, aug_mask = augment_image(df.iloc[idx]['img_path'], df.iloc[idx]['mask_path'])

        axes[i, 0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        axes[i, 0].set_title("Original Image")
        axes[i, 0].axis("off")

        axes[i, 1].imshow(mask, cmap="gray")
        axes[i, 1].set_title("Original Mask")
        axes[i, 1].axis("off")

        axes[i, 2].imshow(cv2.cvtColor(aug_img, cv2.COLOR_BGR2RGB))
        axes[i, 2].set_title("Augmented Image")
        axes[i, 2].axis("off")

        axes[i, 3].imshow(aug_mask, cmap="gray")
        axes[i, 3].set_title("Augmented Mask")
        axes[i, 3].axis("off")

    plt.tight_layout()
    plt.show()

display_augmented_samples(df, num_samples=5)

import os
import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt
import seaborn as sns
import albumentations as A
from sklearn.manifold import TSNE
import umap
from sklearn.decomposition import PCA
import random

# ===============================
# STEP 1 â€” Preprocessing functions
# ===============================

def apply_clahe(image):
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l = clahe.apply(l)
    lab = cv2.merge((l, a, b))
    return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)

def apply_histogram_equalization(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    equalized = cv2.equalizeHist(gray)
    return cv2.cvtColor(equalized, cv2.COLOR_GRAY2BGR)

# ===============================
# STEP 2 â€” Augmentation pipeline
# ===============================

augmentation = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.5),
    A.Rotate(limit=20, p=0.5),
    A.RandomBrightnessContrast(p=0.3),
    A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.3),
    A.OneOf([
        A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.5),
        A.Equalize(p=0.5)
    ], p=0.5)
])

def augment_image(image):
    return augmentation(image=image)['image']

# ===============================
# STEP 3 â€” Display preprocessing stages
# ===============================

def display_preprocessing_stages(image1, image2):
    fig, axes = plt.subplots(2, 4, figsize=(20, 10))
    for i, img in enumerate([image1, image2]):
        clahe_image = apply_clahe(img)
        hist_eq_image = apply_histogram_equalization(img)
        augmented_image = augment_image(img)

        titles = ["Original", "CLAHE", "Histogram Equalization", "Augmented"]
        images = [img, clahe_image, hist_eq_image, augmented_image]

        for ax, img_, title in zip(axes[i], images, titles):
            ax.imshow(cv2.cvtColor(img_, cv2.COLOR_BGR2RGB))
            ax.set_title(f"Image {i+1} - {title}")
            ax.axis("off")

    plt.show()

# ===============================
# STEP 4 â€” t-SNE and UMAP visualization
# ===============================

def visualize_image_distribution(df, method='tsne'):
    images = np.stack(df['image_pixels'].values)
    images_flat = images.reshape(images.shape[0], -1)

    images_pca = PCA(n_components=min(50, images_flat.shape[1])).fit_transform(images_flat)

    if method == 'tsne':
        perplexity_value = min(30, images_pca.shape[0] - 1)
        reducer = TSNE(n_components=2, perplexity=perplexity_value, random_state=42)
    else:
        reducer = umap.UMAP(n_components=2, random_state=42)

    images_reduced = reducer.fit_transform(images_pca)

    plt.figure(figsize=(8, 6))
    plt.scatter(images_reduced[:, 0], images_reduced[:, 1], alpha=0.7, cmap='coolwarm')
    plt.title(f'{method.upper()} Visualization of Image Dataset')
    plt.xlabel('Component 1')
    plt.ylabel('Component 2')
    plt.show()

# ===============================
# STEP 5 â€” Select two random images from BCCD dataset
# ===============================

image_dir = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/original"

image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

if len(image_files) < 2:
    raise ValueError("Not enough images found in the BCCD dataset.")

# Randomly sample 2 images
random_images = random.sample(image_files, 2)

image1 = cv2.imread(os.path.join(image_dir, random_images[0]))
image2 = cv2.imread(os.path.join(image_dir, random_images[1]))

if image1 is None or image2 is None:
    raise ValueError("Failed to load one or both images from BCCD dataset.")

# Display preprocessing stages
display_preprocessing_stages(image1, image2)

# ===============================
# STEP 6 â€” Synthetic sample DataFrame for t-SNE / UMAP
# ===============================

df = pd.DataFrame({
    'image_pixels': [np.random.rand(32, 32, 3) for _ in range(50)]
})

visualize_image_distribution(df, method='tsne')
visualize_image_distribution(df, method='umap')

import os
import pandas as pd
from sklearn.model_selection import train_test_split

# --- Step 1: Create DataFrame for BCCD dataset ---
image_dir = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/original"
mask_dir  = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/mask"

# Function to create df
def create_df(image_dir, mask_dir):
    img_paths = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir)])
    mask_paths = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir)])
    return pd.DataFrame({'img_path': img_paths, 'mask_path': mask_paths})

df = create_df(image_dir, mask_dir)
print("Total dataset size:", len(df))

# --- Step 2: Split dataset into train, validation, and test sets ---
train_df, test_df = train_test_split(df, test_size=0.1, random_state=42)     # 10% test
train_df, val_df  = train_test_split(train_df, test_size=0.1, random_state=42)  # 10% of remaining â†’ validation

# --- Step 3: Check split sizes ---
print("Training set size:", len(train_df))
print("Validation set size:", len(val_df))
print("Test set size:", len(test_df))
#.................Total dataset size: 1169
Training set size: 946
Validation set size: 106
Test set size: 117................#

from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np

def create_image_generator(data_frame,
                           batch_size,
                           image_color_mode="rgb",
                           mask_color_mode="grayscale",
                           image_save_prefix="image",
                           mask_save_prefix="mask",
                           save_to_dir=None,
                           target_size=(256, 256),
                           seed=1):

    def normalize(img, mask):
        img = img / 255.0
        mask = mask / 255.0
        mask[mask > 0.5] = 1
        mask[mask <= 0.5] = 0
        return img, mask

    img_datagen = ImageDataGenerator()
    mask_datagen = ImageDataGenerator()

    # Image generator
    img_gen = img_datagen.flow_from_dataframe(
        dataframe=data_frame,
        x_col="img_path",
        class_mode=None,
        color_mode=image_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        shuffle=True,
        seed=seed
    )

    # Mask generator
    mask_gen = mask_datagen.flow_from_dataframe(
        dataframe=data_frame,
        x_col="mask_path",
        class_mode=None,
        color_mode=mask_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        shuffle=True,
        seed=seed
    )

    # Combine generators
    while True:
        img = next(img_gen)
        mask = next(mask_gen)
        yield normalize(img, mask)


# -------------------- BCCD Usage ----------------------

batch_size = 1    # suitable for BCCD small dataset

train_generator = create_image_generator(train_df, batch_size=batch_size)
val_generator   = create_image_generator(val_df, batch_size=batch_size)
test_generator  = create_image_generator(test_df, batch_size=batch_size)

# Fetch one batch
x_batch, y_batch = next(train_generator)
print("Image batch shape:", x_batch.shape)
print("Mask batch shape:", y_batch.shape)

EPOCHS = 35        # keep very low, only for checking pipeline
BATCH_SIZE = 32    # MUST be 1 because dataset has only one sample
learning_rate = 1e-4
w, h = 256, 256   # keep same size as generator target_sizeEPOCHS = 35  
import tensorflow as tf
from tensorflow.keras import layers, Model, backend as K
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Input, SeparableConv2D, MaxPooling2D, Conv2DTranspose, Concatenate, GroupNormalization
import os
from sklearn.model_selection import train_test_split

# -----------------------------
# GPU / Optimization
# -----------------------------
tf.keras.mixed_precision.set_global_policy('float32')  # Disable mixed precision
tf.config.optimizer.set_jit(True)  # Enable XLA for faster execution

def double_conv(x, n_filters):
    x = SeparableConv2D(n_filters, 3, padding='same', activation='relu')(x)
    x = SeparableConv2D(n_filters, 3, padding='same', activation='relu')(x)
    x = GroupNormalization(groups=8)(x)
    return x

def encoder_vit(x, n_filters):
    x = double_conv(x, n_filters)
    p = MaxPooling2D((2,2))(x)
    return x, p

def decoder(x, skip_connection, n_filters):
    x = Conv2DTranspose(n_filters, 3, strides=2, padding='same')(x)
    h_diff = skip_connection.shape[1] - x.shape[1]
    w_diff = skip_connection.shape[2] - x.shape[2]
    if h_diff != 0 or w_diff != 0:
        skip_connection = layers.Cropping2D(
            ((h_diff//2, h_diff-h_diff//2),
             (w_diff//2, w_diff-w_diff//2))
        )(skip_connection)
    x = Concatenate()([x, skip_connection])
    x = double_conv(x, n_filters)
    return x

def VHU_Net_Model(input_shape=(224,224,3)):
    inputs = Input(input_shape)
    s1,p1 = encoder_vit(inputs,16)
    s2,p2 = encoder_vit(p1,32)
    s3,p3 = encoder_vit(p2,64)
    s4,p4 = encoder_vit(p3,128)
    b = double_conv(p4,128)
    b1 = decoder(b,s4,64)
    b2 = decoder(b1,s3,32)
    b3 = decoder(b2,s2,16)
    b4 = decoder(b3,s1,8)
    outputs = SeparableConv2D(1,1,padding='same',activation='sigmoid')(b4)
    return Model(inputs,outputs)
def dice_coefficient(y_true,y_pred,smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_true*y_pred)
    union = K.sum(y_true)+K.sum(y_pred)
    return (2*intersection + smooth)/(union + smooth)

def dice_loss(y_true,y_pred):
    return -dice_coefficient(y_true,y_pred)

def iou(y_true,y_pred,smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_true*y_pred)
    union = K.sum(y_true)+K.sum(y_pred)
    return (intersection + smooth)/(union - intersection + smooth)
def dice_np(y_true, y_pred, smooth=1e-6):
    y_true_f = y_true.flatten()
    y_pred_f = y_pred.flatten()
    intersection = np.sum(y_true_f * y_pred_f)
    return (2 * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)

def iou_np(y_true, y_pred, smooth=1e-6):
    y_true_f = y_true.flatten()
    y_pred_f = y_pred.flatten()
    intersection = np.sum(y_true_f * y_pred_f)
    union = np.sum(y_true_f) + np.sum(y_pred_f) - intersection
    return (intersection + smooth) / (union + smooth)
!pip install medpy
from medpy.metric.binary import hd95, assd

def hd95_np(y_true, y_pred):
    return hd95(y_pred, y_true)

def assd_np(y_true, y_pred):
    return assd(y_pred, y_true)
def safe_hd95(y_true, y_pred):
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return hd95_np(y_true, y_pred)

def safe_assd(y_true, y_pred):
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return assd_np(y_true, y_pred)
import os
import tensorflow as tf
from sklearn.model_selection import train_test_split

def load_image_mask(image_path, mask_path, img_size=(224,224)):
    # Load image
    image = tf.io.read_file(image_path)
    image = tf.image.decode_png(image, channels=3)
    image = tf.image.resize(image, img_size)
    image = tf.cast(image, tf.float32) / 255.0

    # Load mask
    mask = tf.io.read_file(mask_path)
    mask = tf.image.decode_png(mask, channels=1)
    mask = tf.image.resize(mask, img_size)
    mask = tf.cast(mask, tf.float32) / 255.0

    # Convert to binary (BCCD masks are typically binary)
    mask = tf.where(mask > 0.5, 1.0, 0.0)

    return image, mask


def create_dataset(image_dir, mask_dir, batch_size=8, img_size=(224,224)):
    image_paths = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir)])
    mask_paths  = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir)])

    # Split into train / val / test
    train_img, val_img, train_mask, val_mask = train_test_split(
        image_paths, mask_paths, test_size=0.2, random_state=42)

    val_img, test_img, val_mask, test_mask = train_test_split(
        val_img, val_mask, test_size=0.5, random_state=42)

    def tf_dataset(images, masks):
        ds = tf.data.Dataset.from_tensor_slices((images, masks))
        ds = ds.map(lambda x, y: load_image_mask(x, y, img_size),
                    num_parallel_calls=tf.data.AUTOTUNE)
        ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)
        return ds

    return (
        tf_dataset(train_img, train_mask),
        tf_dataset(val_img, val_mask),
        tf_dataset(test_img, test_mask)
    )


# ===============================
# Set BCCD paths and load datasets
# ===============================

image_dir = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/original"
mask_dir  = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/mask"

train_ds, val_ds, test_ds = create_dataset(image_dir, mask_dir, batch_size=8)
model = VHU_Net_Model(input_shape=(224,224,3))
optim = Adam(learning_rate=1e-3)

model.compile(
    optimizer=optim,
    loss=dice_loss,
    metrics=[dice_coefficient,iou],
    steps_per_execution=5,
    jit_compile=True
)
EPOCHS = 35

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS,
    verbose=1
)
import numpy as np
from medpy.metric.binary import hd95, assd
import tensorflow as tf

# ----------------------
# Safe Metric Wrappers
# ----------------------
def safe_hd95(y_true, y_pred):
    """Compute HD95, return NaN if empty mask."""
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return hd95(y_pred, y_true)

def safe_assd(y_true, y_pred):
    """Compute ASSD, return NaN if empty mask."""
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return assd(y_pred, y_true)

def threshold(pred):
    """Convert predicted probabilities to binary mask."""
    return (pred > 0.5).astype(np.uint8)

def summary_stats(arr):
    """Calculate mean, SD, 95% CI ignoring NaNs."""
    arr = np.array(arr)
    arr = arr[~np.isnan(arr)]  # remove NaNs
    mean = np.mean(arr)
    sd = np.std(arr)
    ci = 1.96 * sd / np.sqrt(len(arr))
    return mean, sd, (mean-ci, mean+ci)

# ----------------------
# Results dictionary
# ----------------------
results = {
    "kidney": {"dice":[], "iou":[], "hd95":[], "assd":[]},
    "tumor": {"dice":[], "iou":[], "hd95":[], "assd":[]},
    "loss": []  # store per-sample loss if needed
}

# ----------------------
# Loop through test dataset
# ----------------------
print("ðŸ”¹ Evaluating model on test dataset...")
for imgs, masks in test_ds:  # batch size = 1 recommended
    preds = model.predict(imgs)
    preds_bin = threshold(preds)

    masks_np = masks.numpy().astype(np.uint8)

    # ---------------- Kidney Metrics ----------------
    kidney_true = (masks_np == 1).astype(np.uint8)
    kidney_pred = (preds_bin == 1).astype(np.uint8)

    results["kidney"]["dice"].append(dice_np(kidney_true, kidney_pred))
    results["kidney"]["iou"].append(iou_np(kidney_true, kidney_pred))
    results["kidney"]["hd95"].append(safe_hd95(kidney_true, kidney_pred))
    results["kidney"]["assd"].append(safe_assd(kidney_true, kidney_pred))

    # ---------------- Tumor Metrics ----------------
    tumor_true = (masks_np == 2).astype(np.uint8)
    tumor_pred = (preds_bin == 2).astype(np.uint8)

    results["tumor"]["dice"].append(dice_np(tumor_true, tumor_pred))
    results["tumor"]["iou"].append(iou_np(tumor_true, tumor_pred))
    results["tumor"]["hd95"].append(safe_hd95(tumor_true, tumor_pred))
    results["tumor"]["assd"].append(safe_assd(tumor_true, tumor_pred))

    # ---------------- Loss ----------------
    loss_val = model.evaluate(imgs, masks, verbose=0)
    results["loss"].append(loss_val[0])  # only store loss

# ----------------------
# Final Summary
# ----------------------
print("\n==================== FINAL METRICS ====================")
for cls in ["kidney", "tumor"]:
    print(f"\nðŸŽ¯ {cls.upper()} METRICS")
    for metric in ["dice", "iou", "hd95", "assd"]:
        mean_val, sd_val, ci = summary_stats(results[cls][metric])
        print(f"{metric.upper():<6}: {mean_val:.4f} Â± {sd_val:.4f} (95% CI: {ci[0]:.4f} â€“ {ci[1]:.4f})")

# Overall loss
mean_loss, sd_loss, ci_loss = summary_stats(results["loss"])
print(f"\nðŸ’¥ LOSS: {mean_loss:.4f} Â± {sd_loss:.4f} (95% CI: {ci_loss[0]:.4f} â€“ {ci_loss[1]:.4f})")
print("\nâœ… Evaluation complete.")
print(history.history.keys())
import cv2
import numpy as np
import matplotlib.pyplot as plt

# ----------------------------------------------
# 1ï¸âƒ£ Load Original Blood Cell Image
# ----------------------------------------------
def load_blood_cell_image(image_path, image_size=(256, 256)):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        raise ValueError(f"Image not found: {image_path}")
    img = cv2.resize(img, image_size)
    img = img.astype(np.float32) / 255.0  # Normalize
    return img

# ----------------------------------------------
# 2ï¸âƒ£ Segment Blood Cell Region
# ----------------------------------------------
def segment_blood_cell(mask_path, base_image, image_size=(256, 256)):
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    if mask is None:
        raise ValueError(f"Mask not found: {mask_path}")

    mask = cv2.resize(mask, image_size).astype(np.uint8)

    # Convert to binary mask (0 or 1)
    _, binary_mask = cv2.threshold(mask, 128, 255, cv2.THRESH_BINARY)
    binary_mask = binary_mask / 255.0

    # Extract segmented blood cell region
    segmented_region = base_image * binary_mask
    return mask, binary_mask, segmented_region

# ----------------------------------------------
# 3ï¸âƒ£ Display Results
# ----------------------------------------------
def display_blood_cell_results(original_img, segmented_img):
    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1)
    plt.imshow(original_img, cmap='gray')
    plt.title("Original Blood Cell Image")
    plt.axis("off")

    plt.subplot(1, 2, 2)
    plt.imshow(segmented_img, cmap='gray')
    plt.title("Segmented Blood Cell Region")
    plt.axis("off")

    plt.show()

# ----------------------------------------------
# 4ï¸âƒ£ Use BCCD Paths
# ----------------------------------------------
image_path = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/original/002f20ad-2ace-499c-9335-c9080bc3e6b5.png"
mask_path  = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/mask/002f20ad-2ace-499c-9335-c9080bc3e6b5.png"

# Load + segment
original_img = load_blood_cell_image(image_path)
mask, mask_binary, segmented_region = segment_blood_cell(mask_path, original_img)

# Display output
display_blood_cell_results(original_img, segmented_region)

# ----------------------------------------------
# 5ï¸âƒ£ Plot Dice & IoU Training Curves
# ----------------------------------------------
epochs = range(1, len(history.history['dice_coefficient']) + 1)

plt.figure(figsize=(10, 4))

# Dice Coefficient
plt.subplot(1, 2, 1)
plt.plot(epochs, history.history['dice_coefficient'], label='Train Dice')
plt.plot(epochs, history.history['val_dice_coefficient'], label='Val Dice')
plt.xlabel('Epochs')
plt.ylabel('Dice Coefficient')
plt.title('Dice Coefficient Over Epochs')
plt.legend()

# IoU
plt.subplot(1, 2, 2)
plt.plot(epochs, history.history['iou'], label='Train IoU')
plt.plot(epochs, history.history['val_iou'], label='Val IoU')
plt.xlabel('Epochs')
plt.ylabel('IoU Score')
plt.title('IoU Score Over Epochs')
plt.legend()

plt.tight_layout()
plt.show()

# Show available keys for clarity
print(history.history.keys())

import tensorflow as tf
from tensorflow.keras import layers, Model, Input
from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, Reshape, Multiply

# Criss-Cross Attention
def criss_cross_attention(x):
    avg_pool = GlobalAveragePooling2D()(x)
    avg_pool = Reshape((1, 1, x.shape[-1]))(avg_pool)
    avg_pool = Conv2D(x.shape[-1], 1, padding='same', activation='sigmoid')(avg_pool)
    return Multiply()([x, avg_pool])

# Define Encoder Block (Using a standard convolutional approach)
def encoder_block(x, filters):
    conv = Conv2D(filters, (3, 3), activation='relu', padding='same')(x)
    conv = Conv2D(filters, (3, 3), activation='relu', padding='same')(conv)
    return conv, layers.MaxPooling2D(pool_size=(2, 2))(conv)

# Define Decoder Block
def decoder_block(x, skip, filters):
    up = layers.UpSampling2D(size=(2, 2))(x)
    merge = layers.Concatenate()([up, skip])
    conv = Conv2D(filters, (3, 3), activation='relu', padding='same')(merge)
    conv = Conv2D(filters, (3, 3), activation='relu', padding='same')(conv)
    return conv

# Define ConD-PDN Model
def cond_pdn(input_shape=(256, 256, 1)):
    inputs = Input(input_shape)

    # Encoder
    s1, p1 = encoder_block(inputs, 64)
    s2, p2 = encoder_block(p1, 128)
    s3, p3 = encoder_block(p2, 256)
    s4, p4 = encoder_block(p3, 512)

    # Bridge with Criss-Cross Attention
    b = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)
    b = Conv2D(1024, (3, 3), activation='relu', padding='same')(b)
    b = criss_cross_attention(b)

    # Decoder
    d1 = decoder_block(b, s4, 512)
    d2 = decoder_block(d1, s3, 256)
    d3 = decoder_block(d2, s2, 128)
    d4 = decoder_block(d3, s1, 64)

    # Output Layer
    outputs = Conv2D(1, (1, 1), activation='sigmoid', padding='same')(d4)

    # Create Model
    model = Model(inputs, outputs, name='ConD_PDN_with_cca')

    return model

# **Dice Coefficient**
def Coffiecient_dice(y_true, y_pred, smooth=100):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    dice = (2 * intersection + smooth) / (union + smooth)
    return dice

# **Dice Loss**
def Dice_loss(y_true, y_pred):
    return -Coffiecient_dice(y_true, y_pred)

# **IoU Metric**
def Iou(y_true, y_pred, smooth=100):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_pred * y_true)
    union = K.sum(y_true) + K.sum(y_pred)  
    iou = (intersection + smooth) / (union - intersection + smooth)
    return iou

# Define learning rate
learning_rate = 1e-3  

# Initialize optimizer
optim = Adam(learning_rate=learning_rate)

# Compile the model
model.compile(optimizer=optim, loss=Dice_loss, metrics=[Iou, Coffiecient_dice])
model.summary()

import tensorflow as tf
from tensorflow.keras import backend as K

# Dice Coefficient
def coefficient_dice(y_true, y_pred, smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    
    dice = (2 * intersection + smooth) / (union + smooth)
    return dice

# Dice Loss (Negative Dice Coefficient)
def dice_loss(y_true, y_pred):
    return -coefficient_dice(y_true, y_pred)

# Intersection over Union (IoU)
def iou(y_true, y_pred, smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    
    iou = (intersection + smooth) / (union - intersection + smooth)
    return iou

# IoU Loss (Negative IoU)
def iou_loss(y_true, y_pred):
    return -iou(y_true, y_pred)
def create_image_generator(data_frame, batch_size, image_color_mode, mask_color_mode, 
                           image_save_prefix, mask_save_prefix, save_to_dir, target_size, seed):
    # Check if columns exist
    if 'img_path' not in data_frame.columns or 'mask_path' not in data_frame.columns:
        raise ValueError("Columns 'img_path' and 'mask_path' not found in dataframe!")

    img_gen = ImageDataGenerator()
    mask_gen = ImageDataGenerator()

    # Generator for images
    img_gen = img_gen.flow_from_dataframe(
        dataframe=data_frame,
        x_col='img_path',  # Ensure this column exists
        class_mode=None,
        color_mode=image_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=image_save_prefix,
        seed=seed
    )

    # Generator for masks
    mask_gen = mask_gen.flow_from_dataframe(
        dataframe=data_frame,
        x_col='mask_path',  # Ensure this column exists
        class_mode=None,
        color_mode=mask_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=mask_save_prefix,
        seed=seed
    )

    return img_gen, mask_gen

EPOCHS = 35

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS,
    verbose=1
)
import numpy as np
from medpy.metric.binary import hd95, assd
import tensorflow as tf

# ----------------------
# Safe Metric Wrappers
# ----------------------
def safe_hd95(y_true, y_pred):
    """Compute HD95, return NaN if empty mask."""
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return hd95(y_pred, y_true)

def safe_assd(y_true, y_pred):
    """Compute ASSD, return NaN if empty mask."""
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return assd(y_pred, y_true)

def threshold(pred):
    """Convert predicted probabilities to binary mask."""
    return (pred > 0.5).astype(np.uint8)

def summary_stats(arr):
    """Calculate mean, SD, 95% CI ignoring NaNs."""
    arr = np.array(arr)
    arr = arr[~np.isnan(arr)]  # remove NaNs
    mean = np.mean(arr)
    sd = np.std(arr)
    ci = 1.96 * sd / np.sqrt(len(arr))
    return mean, sd, (mean-ci, mean+ci)

# ----------------------
# Results dictionary
# ----------------------
results = {
    "kidney": {"dice":[], "iou":[], "hd95":[], "assd":[]},
    "tumor": {"dice":[], "iou":[], "hd95":[], "assd":[]},
    "loss": []  # store per-sample loss if needed
}

# ----------------------
# Loop through test dataset
# ----------------------
print("ðŸ”¹ Evaluating model on test dataset...")
for imgs, masks in test_ds:  # batch size = 1 recommended
    preds = model.predict(imgs)
    preds_bin = threshold(preds)

    masks_np = masks.numpy().astype(np.uint8)

    # ---------------- Kidney Metrics ----------------
    kidney_true = (masks_np == 1).astype(np.uint8)
    kidney_pred = (preds_bin == 1).astype(np.uint8)

    results["kidney"]["dice"].append(dice_np(kidney_true, kidney_pred))
    results["kidney"]["iou"].append(iou_np(kidney_true, kidney_pred))
    results["kidney"]["hd95"].append(safe_hd95(kidney_true, kidney_pred))
    results["kidney"]["assd"].append(safe_assd(kidney_true, kidney_pred))

    # ---------------- Tumor Metrics ----------------
    tumor_true = (masks_np == 2).astype(np.uint8)
    tumor_pred = (preds_bin == 2).astype(np.uint8)

    results["tumor"]["dice"].append(dice_np(tumor_true, tumor_pred))
    results["tumor"]["iou"].append(iou_np(tumor_true, tumor_pred))
    results["tumor"]["hd95"].append(safe_hd95(tumor_true, tumor_pred))
    results["tumor"]["assd"].append(safe_assd(tumor_true, tumor_pred))

    # ---------------- Loss ----------------
    loss_val = model.evaluate(imgs, masks, verbose=0)
    results["loss"].append(loss_val[0])  # only store loss

# ----------------------
# Final Summary
# ----------------------
print("\n==================== FINAL METRICS ====================")
for cls in ["kidney", "tumor"]:
    print(f"\nðŸŽ¯ {cls.upper()} METRICS")
    for metric in ["dice", "iou", "hd95", "assd"]:
        mean_val, sd_val, ci = summary_stats(results[cls][metric])
        print(f"{metric.upper():<6}: {mean_val:.4f} Â± {sd_val:.4f} (95% CI: {ci[0]:.4f} â€“ {ci[1]:.4f})")

# Overall loss
mean_loss, sd_loss, ci_loss = summary_stats(results["loss"])
print(f"\nðŸ’¥ LOSS: {mean_loss:.4f} Â± {sd_loss:.4f} (95% CI: {ci_loss[0]:.4f} â€“ {ci_loss[1]:.4f})")
print("\nâœ… Evaluation complete.")

print(history.history.keys())

import cv2
import numpy as np
import matplotlib.pyplot as plt

# ---------------------------------------------------------
# 1ï¸âƒ£ Load Blood Cell Mask Image
# ---------------------------------------------------------
def load_blood_cell_mask(mask_path, image_size=(256, 256)):
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    if mask is None:
        raise ValueError(f"Mask not found: {mask_path}")
    mask = cv2.resize(mask, image_size).astype(np.uint8)
    return mask

# ---------------------------------------------------------
# 2ï¸âƒ£ Create Segmented Mask Region (Binary Mask)
# ---------------------------------------------------------
def create_mask_region(mask):
    _, binary_mask = cv2.threshold(mask, 128, 255, cv2.THRESH_BINARY)
    binary_mask = binary_mask.astype(np.float32) / 255.0
    return binary_mask

# ---------------------------------------------------------
# 3ï¸âƒ£ Display Mask + Segmented Region
# ---------------------------------------------------------
def display_mask_results(mask, mask_region):
    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1)
    plt.imshow(mask, cmap='gray')
    plt.title("Blood Cell Mask Image")
    plt.axis("off")

    plt.subplot(1, 2, 2)
    plt.imshow(mask_region, cmap='gray')
    plt.title("Segmented Mask Region (Binary)")
    plt.axis("off")

    plt.show()

# ---------------------------------------------------------
# 4ï¸âƒ£ USE BCCD KAGGLE PATHS
# ---------------------------------------------------------
image_path = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/original/002f20ad-2ace-499c-9335-c9080bc3e6b5.png"
mask_path  = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/mask/002f20ad-2ace-499c-9335-c9080bc3e6b5.png"

mask = load_blood_cell_mask(mask_path)
mask_region = create_mask_region(mask)

display_mask_results(mask, mask_region)

# ---------------------------------------------------------
# 5ï¸âƒ£ FIXED â€” Plot Dice & IoU Training Curves
# ---------------------------------------------------------
epochs = range(1, len(history.history['coffiecient_dice']) + 1)

plt.figure(figsize=(10, 4))

# Dice (Correct Key)
plt.subplot(1, 2, 1)
plt.plot(epochs, history.history['coffiecient_dice'], label='Train Dice')
plt.plot(epochs, history.history['val_coffiecient_dice'], label='Val Dice')
plt.xlabel('Epochs')
plt.ylabel('Dice Coefficient')
plt.title('Dice Coefficient Over Epochs')
plt.legend()

# IoU (Correct Key)
plt.subplot(1, 2, 2)
plt.plot(epochs, history.history['iou'], label='Train IoU')
plt.plot(epochs, history.history['val_iou'], label='Val IoU')
plt.xlabel('Epochs')
plt.ylabel('IoU Score')
plt.title('IoU Score Over Epochs')
plt.legend()

plt.tight_layout()
plt.show()

print(history.history.keys())

import tensorflow as tf
from tensorflow.keras import layers, Model, Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import backend as K

def fusion_net(input_shape=(256, 256, 1)):
    inputs = Input(input_shape)
    conv = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)
    conv = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv)
    output = layers.Conv2D(1, (1, 1), activation='sigmoid', padding='same')(conv)
    return Model(inputs=inputs, outputs=output, name="Fusion_Net")

# Function to fuse ConD-PDN and VHU-Net

def fuse_models(cond_pdn_model, vhu_net_model, input_shape=(256, 256, 1)):
    inputs = Input(input_shape)
    
    # Get outputs from both models
    cond_pdn_output = cond_pdn_model(inputs)
    vhu_net_output = vhu_net_model(inputs)
    
    # Fusion step: Averaging outputs
    fused_output = layers.Average()([cond_pdn_output, vhu_net_output])
    
    # Final output layer
    final_output = layers.Conv2D(1, (1, 1), activation='sigmoid', padding='same')(fused_output)
    
    return Model(inputs, final_output, name="Fused_ConD_VHU_Net")

# Instantiate models
input_shape = (256, 256, 1)
cond_pdn_model = cond_pdn(input_shape)
vhu_net_model = VHU_Net_Model(input_shape)

# Fuse the models
fused_model = fuse_models(cond_pdn_model, vhu_net_model, input_shape)

# Define Dice Loss and IoU

def Coffiecient_dice(y_true, y_pred, smooth=100):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    dice = (2 * intersection + smooth) / (union + smooth)
    return dice

def Dice_loss(y_true, y_pred):
    return -Coffiecient_dice(y_true, y_pred)

def Iou(y_true, y_pred, smooth=100):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_pred * y_true)
    union = K.sum(y_true) + K.sum(y_pred)  
    iou = (intersection + smooth) / (union - intersection + smooth)
    return iou

# Compile fused model
learning_rate = 1e-3  
optim = Adam(learning_rate=learning_rate)
fused_model.compile(optimizer=optim, loss=Dice_loss, metrics=[Iou, Coffiecient_dice])

# Print model summary
fused_model.summary()

import tensorflow as tf
from tensorflow.keras import backend as K

# Dice Coefficient
def coefficient_dice(y_true, y_pred, smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    
    dice = (2 * intersection + smooth) / (union + smooth)
    return dice

# Dice Loss (Negative Dice Coefficient)
def dice_loss(y_true, y_pred):
    return -coefficient_dice(y_true, y_pred)

# Intersection over Union (IoU)
def iou(y_true, y_pred, smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    
    iou = (intersection + smooth) / (union - intersection + smooth)
    return iou

# IoU Loss (Negative IoU)
def iou_loss(y_true, y_pred):
    return -iou(y_true, y_pred)
def create_image_generator(data_frame, batch_size, image_color_mode, mask_color_mode, 
                           image_save_prefix, mask_save_prefix, save_to_dir, target_size, seed):
    # Check if columns exist
    if 'img_path' not in data_frame.columns or 'mask_path' not in data_frame.columns:
        raise ValueError("Columns 'img_path' and 'mask_path' not found in dataframe!")

    img_gen = ImageDataGenerator()
    mask_gen = ImageDataGenerator()

    # Generator for images
    img_gen = img_gen.flow_from_dataframe(
        dataframe=data_frame,
        x_col='img_path',  # Ensure this column exists
        class_mode=None,
        color_mode=image_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=image_save_prefix,
        seed=seed
    )

    # Generator for masks
    mask_gen = mask_gen.flow_from_dataframe(
        dataframe=data_frame,
        x_col='mask_path',  # Ensure this column exists
        class_mode=None,
        color_mode=mask_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=mask_save_prefix,
        seed=seed
    )

    return img_gen, mask_gen

EPOCHS = 35

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS,
    verbose=1
)
import numpy as np
from medpy.metric.binary import hd95, assd
import tensorflow as tf

# ----------------------
# Safe Metric Wrappers
# ----------------------
def safe_hd95(y_true, y_pred):
    """Compute HD95, return NaN if empty mask."""
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return hd95(y_pred, y_true)

def safe_assd(y_true, y_pred):
    """Compute ASSD, return NaN if empty mask."""
    if y_true.sum() == 0 or y_pred.sum() == 0:
        return np.nan
    return assd(y_pred, y_true)

def threshold(pred):
    """Convert predicted probabilities to binary mask."""
    return (pred > 0.5).astype(np.uint8)

def summary_stats(arr):
    """Calculate mean, SD, 95% CI ignoring NaNs."""
    arr = np.array(arr)
    arr = arr[~np.isnan(arr)]  # remove NaNs
    mean = np.mean(arr)
    sd = np.std(arr)
    ci = 1.96 * sd / np.sqrt(len(arr))
    return mean, sd, (mean-ci, mean+ci)

# ----------------------
# Results dictionary
# ----------------------
results = {
    "kidney": {"dice":[], "iou":[], "hd95":[], "assd":[]},
    "tumor": {"dice":[], "iou":[], "hd95":[], "assd":[]},
    "loss": []  # store per-sample loss if needed
}

# ----------------------
# Loop through test dataset
# ----------------------
print("ðŸ”¹ Evaluating model on test dataset...")
for imgs, masks in test_ds:  # batch size = 1 recommended
    preds = model.predict(imgs)
    preds_bin = threshold(preds)

    masks_np = masks.numpy().astype(np.uint8)

    # ---------------- Kidney Metrics ----------------
    kidney_true = (masks_np == 1).astype(np.uint8)
    kidney_pred = (preds_bin == 1).astype(np.uint8)

    results["kidney"]["dice"].append(dice_np(kidney_true, kidney_pred))
    results["kidney"]["iou"].append(iou_np(kidney_true, kidney_pred))
    results["kidney"]["hd95"].append(safe_hd95(kidney_true, kidney_pred))
    results["kidney"]["assd"].append(safe_assd(kidney_true, kidney_pred))

    # ---------------- Tumor Metrics ----------------
    tumor_true = (masks_np == 2).astype(np.uint8)
    tumor_pred = (preds_bin == 2).astype(np.uint8)

    results["tumor"]["dice"].append(dice_np(tumor_true, tumor_pred))
    results["tumor"]["iou"].append(iou_np(tumor_true, tumor_pred))
    results["tumor"]["hd95"].append(safe_hd95(tumor_true, tumor_pred))
    results["tumor"]["assd"].append(safe_assd(tumor_true, tumor_pred))

    # ---------------- Loss ----------------
    loss_val = model.evaluate(imgs, masks, verbose=0)
    results["loss"].append(loss_val[0])  # only store loss

# ----------------------
# Final Summary
# ----------------------
print("\n==================== FINAL METRICS ====================")
for cls in ["kidney", "tumor"]:
    print(f"\nðŸŽ¯ {cls.upper()} METRICS")
    for metric in ["dice", "iou", "hd95", "assd"]:
        mean_val, sd_val, ci = summary_stats(results[cls][metric])
        print(f"{metric.upper():<6}: {mean_val:.4f} Â± {sd_val:.4f} (95% CI: {ci[0]:.4f} â€“ {ci[1]:.4f})")

# Overall loss
mean_loss, sd_loss, ci_loss = summary_stats(results["loss"])
print(f"\nðŸ’¥ LOSS: {mean_loss:.4f} Â± {sd_loss:.4f} (95% CI: {ci_loss[0]:.4f} â€“ {ci_loss[1]:.4f})")
print("\nâœ… Evaluation complete.")
print(history.history.keys())
import cv2
import numpy as np
import matplotlib.pyplot as plt

# ---------------------------------------------------------
# Create ONLY the FUSED IMAGE
# ---------------------------------------------------------
def create_fused_image(image_path, mask_path, image_size=(256, 256)):
    # Load grayscale blood cell image
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        raise ValueError(f"Image not found: {image_path}")
    img = cv2.resize(img, image_size).astype(np.float32) / 255.0

    # Load segmentation mask
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    if mask is None:
        raise ValueError(f"Mask not found: {mask_path}")
    mask = cv2.resize(mask, image_size).astype(np.uint8)

    # Convert mask â†’ binary
    _, binary_mask = cv2.threshold(mask, 128, 255, cv2.THRESH_BINARY)
    binary_mask = binary_mask.astype(np.float32) / 255.0

    # Fused image: mask = 1 â†’ highlight, background uses segmented image
    fused_image = np.where(binary_mask == 1, 1.0, img * binary_mask)

    return fused_image

# ---------------------------------------------------------
# DISPLAY FUSED IMAGE ONLY
# ---------------------------------------------------------
def display_fused_image(fused_img):
    plt.figure(figsize=(6, 6))
    plt.imshow(fused_img, cmap="gray")
    plt.title("Fused Blood Cell Image")
    plt.axis("off")
    plt.show()

# ---------------------------------------------------------
# USE BCCD KAGGLE PATHS
# ---------------------------------------------------------
image_path = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/original/002f20ad-2ace-499c-9335-c9080bc3e6b5.png"
mask_path  = "/kaggle/input/bccd-dataset-with-mask/BCCD Dataset with mask/train/mask/002f20ad-2ace-499c-9335-c9080bc3e6b5.png"

# Generate fused image
fused_img = create_fused_image(image_path, mask_path)

# Display result
display_fused_image(fused_img)
# Extract history
epochs = range(1, len(history.history['coffiecient_dice']) + 1)

# Auto-detect max values
max_dice = max(history.history['coffiecient_dice'] + history.history['val_coffiecient_dice'])
max_iou  = max(history.history['iou'] + history.history['val_iou'])

# Add margin above max
dice_top = max_dice + 0.05
iou_top  = max_iou + 0.05

plt.figure(figsize=(12, 5))

# ---------------- DICE PLOT ----------------
plt.subplot(1, 2, 1)
plt.plot(epochs, history.history['coffiecient_dice'], label='Train Dice', linewidth=2, marker='o')
plt.plot(epochs, history.history['val_coffiecient_dice'], label='Val Dice', linewidth=2, marker='o')

plt.xlabel('Epochs')
plt.ylabel('Dice Coefficient')
plt.title('Dice Coefficient Over Epochs')
plt.ylim(0.2, dice_top)      # <-- auto adjusted
plt.legend()

# ---------------- IOU PLOT ----------------
plt.subplot(1, 2, 2)
plt.plot(epochs, history.history['iou'], label='Train IoU', linewidth=2, marker='o')
plt.plot(epochs, history.history['val_iou'], label='Val IoU', linewidth=2, marker='o')

plt.xlabel('Epochs')
plt.ylabel('IoU Score')
plt.title('IoU Score Over Epochs')
plt.ylim(0.2, iou_top)       # <-- auto adjusted
plt.legend()

plt.tight_layout()
plt.show()

#....................Based on the reviwer requestion again run the model for evaluationmetric 
visuliaztion code is alredy run in Anaconda..........#

import os
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from skimage import measure


# Specify dataset directories
image_dir = "C:/Users/jefri/Downloads/archive (1)/BCCD Dataset with mask/train/image"
mask_dir = "C:/Users/jefri/Downloads/archive (1)/BCCD Dataset with mask/train/mask"

# Load image and mask file paths
image_paths = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir)
                      if f.endswith(('.png', '.jpg', '.jpeg'))])
mask_paths = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir)
                     if f.endswith(('.png', '.jpg', '.jpeg'))])

# Create DataFrame
test_df = pd.DataFrame({
    'image_path': image_paths,
    'mask_path': mask_paths
})
print(f"Loaded {len(test_df)} image-mask pairs.")

# Function: Contour Overlay Visualization
def overlay_contours(image, ground_truth, predicted, contour_level=0.5):
    gt_contours = measure.find_contours(ground_truth.squeeze(), level=contour_level)
    pred_contours = measure.find_contours(predicted.squeeze(), level=contour_level)
    
    plt.figure(figsize=(8, 8))
    plt.imshow(image, cmap='gray')
    
    for contour in gt_contours:
        plt.plot(contour[:, 1], contour[:, 0], linewidth=2, color='g', label='Ground Truth')
    for contour in pred_contours:
        plt.plot(contour[:, 1], contour[:, 0], linewidth=2, color='r', label='Prediction')
    
    plt.title("Contour Overlay\nGreen: Ground Truth, Red: Prediction")
    plt.axis('off')
    plt.show()

# Function: Error Map Visualization
def error_map_visualization(ground_truth, predicted):
    error = np.abs(ground_truth - predicted)
    plt.figure(figsize=(6, 6))
    plt.imshow(error.squeeze(), cmap='hot')
    plt.colorbar()
    plt.title("Error Map (Absolute Difference)")
    plt.axis('off')
    plt.show()

# Function to demonstrate visualizations
def demo_visualizations(df, prediction_func=None):
    import random
    idx = random.randint(0, len(df)-1)
    image_path = df.iloc[idx]['image_path']
    mask_path = df.iloc[idx]['mask_path']
    
    image = load_img(image_path, target_size=(224, 224))
    mask = load_img(mask_path, target_size=(224, 224), color_mode="grayscale")
    
    image_array = img_to_array(image) / 255.0
    mask_array = img_to_array(mask) / 255.0
    
    predicted_mask = prediction_func(image_array) if prediction_func else mask_array
    
    overlay_contours(image_array, mask_array, predicted_mask)
    error_map_visualization(mask_array, predicted_mask)

# Run the demo (replace prediction_func with your model prediction if available)
demo_visualizations(test_df, prediction_func=None)
import os
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from skimage import measure

# Specify dataset directories
image_dir = "C:/Users/jefri/Downloads/archive (1)/BCCD Dataset with mask/train/image"
mask_dir = "C:/Users/jefri/Downloads/archive (1)/BCCD Dataset with mask/train/mask"

# Load image and mask file paths
image_paths = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir)
                      if f.endswith(('.png', '.jpg', '.jpeg'))])
mask_paths = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir)
                     if f.endswith(('.png', '.jpg', '.jpeg'))])

# Create DataFrame
test_df = pd.DataFrame({
    'image_path': image_paths,
    'mask_path': mask_paths
})
print(f"Loaded {len(test_df)} image-mask pairs.")

# Function: Contour Overlay Visualization
def overlay_contours(image, ground_truth, predicted, contour_level=0.5):
    gt_contours = measure.find_contours(ground_truth.squeeze(), level=contour_level)
    pred_contours = measure.find_contours(predicted.squeeze(), level=contour_level)
    
    plt.figure(figsize=(8, 8))
    plt.imshow(image, cmap='gray')
    
    for contour in gt_contours:
        plt.plot(contour[:, 1], contour[:, 0], linewidth=2, color='g', label='Ground Truth')
    for contour in pred_contours:
        plt.plot(contour[:, 1], contour[:, 0], linewidth=2, color='r', label='Prediction')
    
    plt.title("Contour Overlay\nGreen: Ground Truth, Red: Prediction")
    plt.axis('off')
    plt.show()

# Function: Error Map Visualization
def error_map_visualization(ground_truth, predicted):
    error = np.abs(ground_truth - predicted)
    plt.figure(figsize=(6, 6))
    plt.imshow(error.squeeze(), cmap='hot')
    plt.colorbar()
    plt.title("Error Map (Absolute Difference)")
    plt.axis('off')
    plt.show()

# Function to demonstrate visualizations
def demo_visualizations(df, prediction_func=None):
    import random
    idx = random.randint(0, len(df)-1)
    image_path = df.iloc[idx]['image_path']
    mask_path = df.iloc[idx]['mask_path']
    
    image = load_img(image_path, target_size=(224, 224))
    mask = load_img(mask_path, target_size=(224, 224), color_mode="grayscale")
    
    image_array = img_to_array(image) / 255.0
    mask_array = img_to_array(mask) / 255.0
    
    predicted_mask = prediction_func(image_array) if prediction_func else mask_array
    
    overlay_contours(image_array, mask_array, predicted_mask)
    error_map_visualization(mask_array, predicted_mask)

# Run the demo (replace prediction_func with your model prediction if available)
demo_visualizations(test_df, prediction_func=None)
import os
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from skimage import measure

# Specify dataset directories
image_dir = "C:/Users/jefri/Downloads/archive (1)/BCCD Dataset with mask/train/image"
mask_dir = "C:/Users/jefri/Downloads/archive (1)/BCCD Dataset with mask/train/mask"
# Load image and mask file paths
image_paths = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir)
                      if f.endswith(('.png', '.jpg', '.jpeg'))])
mask_paths = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir)
                     if f.endswith(('.png', '.jpg', '.jpeg'))])

# Create DataFrame
test_df = pd.DataFrame({
    'image_path': image_paths,
    'mask_path': mask_paths
})
print(f"Loaded {len(test_df)} image-mask pairs.")

# Function: Contour Overlay Visualization
def overlay_contours(image, ground_truth, predicted, contour_level=0.5):
    gt_contours = measure.find_contours(ground_truth.squeeze(), level=contour_level)
    pred_contours = measure.find_contours(predicted.squeeze(), level=contour_level)
    
    plt.figure(figsize=(8, 8))
    plt.imshow(image, cmap='gray')
    
    for contour in gt_contours:
        plt.plot(contour[:, 1], contour[:, 0], linewidth=2, color='g', label='Ground Truth')
    for contour in pred_contours:
        plt.plot(contour[:, 1], contour[:, 0], linewidth=2, color='r', label='Prediction')
    
    plt.title("Contour Overlay\nGreen: Ground Truth, Red: Prediction")
    plt.axis('off')
    plt.show()

# Function: Error Map Visualization
def error_map_visualization(ground_truth, predicted):
    error = np.abs(ground_truth - predicted)
    plt.figure(figsize=(6, 6))
    plt.imshow(error.squeeze(), cmap='hot')
    plt.colorbar()
    plt.title("Error Map (Absolute Difference)")
    plt.axis('off')
    plt.show()

# Function to demonstrate visualizations
def demo_visualizations(df, prediction_func=None):
    import random
    idx = random.randint(0, len(df)-1)
    image_path = df.iloc[idx]['image_path']
    mask_path = df.iloc[idx]['mask_path']
    
    image = load_img(image_path, target_size=(224, 224))
    mask = load_img(mask_path, target_size=(224, 224), color_mode="grayscale")
    
    image_array = img_to_array(image) / 255.0
    mask_array = img_to_array(mask) / 255.0
    
    predicted_mask = prediction_func(image_array) if prediction_func else mask_array
    
    overlay_contours(image_array, mask_array, predicted_mask)
    error_map_visualization(mask_array, predicted_mask)

# Run the demo (replace prediction_func with your model prediction if available)
demo_visualizations(test_df, prediction_func=None)


#..................HAM10000 dataset...............................#
#......Dataset 3.....#
import glob
from glob import glob
folders = glob('C:/dataset/skin/*')
len(folders)

import os
path, dirs, filesimages = next(os.walk("C:/dataset/skin/image"))
path, dirs, filesmask = next(os.walk("C:/dataset/skin/mask"))
len(filesimages), len(filesmask), 

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
import warnings
warnings.filterwarnings('ignore')
from sklearn.model_selection import train_test_split
import tensorflow
from tensorflow import keras
import os
from tensorflow.keras import layers
from tensorflow.keras import backend as K
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input,Conv2D,MaxPool2D,Dropout,BatchNormalization,Conv2DTranspose,concatenate
from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint
from tensorflow.keras.preprocessing.image import ImageDataGenerator

import os
import pandas as pd

def create_df(image_dir, mask_dir):
    img_paths = []
    mask_paths = []
    
    # Ensure directories exist
    if not os.path.exists(image_dir) or not os.path.exists(mask_dir):
        raise ValueError("The specified directories do not exist.")
    
    # Get sorted lists of images and masks
    image_files = sorted(os.listdir(image_dir))
    mask_files = sorted(os.listdir(mask_dir))

    # Ensure matching images and masks
    for img_file, mask_file in zip(image_files, mask_files):
        img_path = os.path.join(image_dir, img_file)
        mask_path = os.path.join(mask_dir, mask_file)
        img_paths.append(img_path)
        mask_paths.append(mask_path)

    # Create DataFrame
    df = pd.DataFrame({'img_path': img_paths, 'mask_path': mask_paths})
    return df

# Specify dataset directories
image_dir = "C:/dataset/skin/image"
mask_dir = "C:/dataset/skin/mask"

# Create dataset DataFrame
df = create_df(image_dir, mask_dir)

# Display sample dataset
print(df.head())
df
import numpy as np
import cv2

def display_image_shapes(df, num_samples=10):
    num_samples = min(num_samples, len(df))  # Ensure num_samples does not exceed available rows

    random_indices = np.random.choice(df.index, size=num_samples, replace=False)  # Select random indices
    random_images = df.iloc[random_indices]['img_path'].values
    random_masks = df.iloc[random_indices]['mask_path'].values

    for i in range(num_samples):
        # Read image and mask
        image = cv2.imread(random_images[i])
        mask = cv2.imread(random_masks[i], cv2.IMREAD_GRAYSCALE)

        if image is None or mask is None:
            print(f"Warning: Unable to load image or mask at index {random_indices[i]}")
            continue

        # Print only shape values
        print(f"Sample {i+1}: Image Shape = {image.shape}, Mask Shape = {mask.shape}")

# Display only shapes
display_image_shapes(df)

import os
import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt
import albumentations as A
from albumentations.core.composition import OneOf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Function to visualize random images with their masks
def display_samples(df, num_samples=5):
    random_indices = np.random.choice(df.index, size=num_samples, replace=False)
    fig, axes = plt.subplots(num_samples, 2, figsize=(10, num_samples * 3))

    for i, idx in enumerate(random_indices):
        img = cv2.imread(df.iloc[idx]['img_path'])
        mask = cv2.imread(df.iloc[idx]['mask_path'], cv2.IMREAD_GRAYSCALE)

        axes[i, 0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        axes[i, 0].set_title("Original Image")
        axes[i, 0].axis("off")

        axes[i, 1].imshow(mask, cmap="gray")
        axes[i, 1].set_title("Mask")
        axes[i, 1].axis("off")

    plt.tight_layout()
    plt.show()

# Display 5 random samples
display_samples(df, num_samples=5)

# Define Augmentation Pipeline using Albumentations
augmentation = A.Compose([
    A.HorizontalFlip(p=0.5),   # Random horizontal flip
    A.VerticalFlip(p=0.5),     # Random vertical flip
    A.Rotate(limit=20, p=0.5), # Random rotation
    A.RandomBrightnessContrast(p=0.3),
    A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.3),
])

# Function to apply augmentation on an image-mask pair
def augment_image(image_path, mask_path):
    image = cv2.imread(image_path)
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

    augmented = augmentation(image=image, mask=mask)
    return augmented['image'], augmented['mask']

# Visualize Augmented Images
def display_augmented_samples(df, num_samples=5):
    random_indices = np.random.choice(df.index, size=num_samples, replace=False)
    fig, axes = plt.subplots(num_samples, 4, figsize=(15, num_samples * 3))

    for i, idx in enumerate(random_indices):
        img = cv2.imread(df.iloc[idx]['img_path'])
        mask = cv2.imread(df.iloc[idx]['mask_path'], cv2.IMREAD_GRAYSCALE)
        aug_img, aug_mask = augment_image(df.iloc[idx]['img_path'], df.iloc[idx]['mask_path'])

        # Original Image
        axes[i, 0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        axes[i, 0].set_title("Original Image")
        axes[i, 0].axis("off")

        # Original Mask
        axes[i, 1].imshow(mask, cmap="gray")
        axes[i, 1].set_title("Original Mask")
        axes[i, 1].axis("off")

        # Augmented Image
        axes[i, 2].imshow(cv2.cvtColor(aug_img, cv2.COLOR_BGR2RGB))
        axes[i, 2].set_title("Augmented Image")
        axes[i, 2].axis("off")

        # Augmented Mask
        axes[i, 3].imshow(aug_mask, cmap="gray")
        axes[i, 3].set_title("Augmented Mask")
        axes[i, 3].axis("off")

    plt.tight_layout()
    plt.show()

# Display 5 Augmented Samples
display_augmented_samples(df, num_samples=5)

import os
import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt
import seaborn as sns
import albumentations as A
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.manifold import TSNE
import umap
from sklearn.decomposition import PCA
import random

# Function to apply CLAHE (Contrast Limited Adaptive Histogram Equalization)
def apply_clahe(image):
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)  # Convert to LAB color space
    l, a, b = cv2.split(lab)  # Split channels
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l = clahe.apply(l)  # Apply CLAHE on L-channel
    lab = cv2.merge((l, a, b))  # Merge back
    return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)  # Convert back to BGR

# Function to apply Histogram Equalization (HE)
def apply_histogram_equalization(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    equalized = cv2.equalizeHist(gray)  # Apply histogram equalization
    return cv2.cvtColor(equalized, cv2.COLOR_GRAY2BGR)

# Define Augmentation Pipeline using Albumentations
augmentation = A.Compose([
    A.HorizontalFlip(p=0.5),   # Random horizontal flip
    A.VerticalFlip(p=0.5),     # Random vertical flip
    A.Rotate(limit=20, p=0.5), # Random rotation
    A.RandomBrightnessContrast(p=0.3),
    A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.3),  # Elastic Deformation
    A.OneOf([
        A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.5),  # CLAHE
        A.Equalize(p=0.5)  # Histogram Equalization
    ], p=0.5)
])

# Function to augment an image
def augment_image(image):
    augmented = augmentation(image=image)
    return augmented['image']

# Function to visualize preprocessing techniques
def display_preprocessing_stages(image1, image2):
    fig, axes = plt.subplots(2, 4, figsize=(20, 10))
    
    for i, img in enumerate([image1, image2]):
        clahe_image = apply_clahe(img)
        hist_eq_image = apply_histogram_equalization(img)
        augmented_image = augment_image(img)

        titles = ["Original", "CLAHE", "Histogram Equalization", "Augmented"]
        images = [img, clahe_image, hist_eq_image, augmented_image]

        for j, (ax, img, title) in enumerate(zip(axes[i], images, titles)):
            ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
            ax.set_title(f"Image {i+1} - {title}")
            ax.axis("off")

    plt.show()

# Function to visualize t-SNE and UMAP
def visualize_image_distribution(df, method='tsne'):
    images = np.stack(df['image_pixels'].values)  # Stack images into a single array
    images_flat = images.reshape(images.shape[0], -1)  # Flatten images
    images_pca = PCA(n_components=min(50, images_flat.shape[1])).fit_transform(images_flat)  # Reduce dimensions using PCA

    if method == 'tsne':
        perplexity_value = min(30, images_pca.shape[0] - 1)  # Ensure perplexity < n_samples
        reducer = TSNE(n_components=2, perplexity=perplexity_value, random_state=42)
    else:
        reducer = umap.UMAP(n_components=2, random_state=42)

    images_reduced = reducer.fit_transform(images_pca)

    plt.figure(figsize=(8, 6))
    plt.scatter(images_reduced[:, 0], images_reduced[:, 1], alpha=0.7, cmap='coolwarm')
    plt.title(f'{method.upper()} Visualization of Image Dataset')
    plt.xlabel('Component 1')
    plt.ylabel('Component 2')
    plt.show()

# --------------------- Select Two Random Images from Dataset ---------------------

# Corrected dataset paths
image_path = r"C:/dataset/skin/image"
mask_path = r"C:/dataset/skin/mask"
image_files = [f for f in os.listdir(image_path) if f.endswith(('.png', '.jpg', '.jpeg'))]

if len(image_files) < 2:
    raise ValueError("Not enough images found in the specified dataset path. Please check the folder path.")

random_images = random.sample(image_files, 2)
image1 = cv2.imread(os.path.join(image_path, random_images[0]))
image2 = cv2.imread(os.path.join(image_path, random_images[1]))

if image1 is None or image2 is None:
    raise ValueError(f"Failed to load one or both images. Please check the file paths.")

# Display Preprocessing Stages for Two Images
display_preprocessing_stages(image1, image2)

# Sample DataFrame Creation (Replace with actual image data)
df = pd.DataFrame({
    'image_pixels': [np.random.rand(32, 32, 3) for _ in range(50)]  # 50 random images (32x32 RGB)
})

# Display t-SNE and UMAP Visualizations
visualize_image_distribution(df, method='tsne')
visualize_image_distribution(df, method='umap')

# Importing necessary function for splitting data
from sklearn.model_selection import train_test_split

# Now you can use train_test_split without any issues

# Example usage (assuming you already have the df DataFrame):

train_df, test_df = train_test_split(df, test_size=0.1, random_state=42)  # Split into train and test sets
train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)  # Further split train into train and validation sets

# Check the resulting splits
print("Training set size:", len(train_df))
print("Validation set size:", len(val_df))
print("Test set size:", len(test_df))

from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import cv2

def create_image_generator(data_frame,
                           batch_size,
                           image_color_mode="rgb",
                           mask_color_mode="grayscale",
                           image_save_prefix="image",
                           mask_save_prefix="mask",
                           save_to_dir=None,
                           target_size=(256, 256),
                           seed=1):

    def normalize(img, mask):
        # Normalize image and mask
        img = img / 255.0
        mask = mask / 255.0
        mask[mask > 0.5] = 1
        mask[mask <= 0.5] = 0
        return img, mask

    # Image data generator
    img_gen = ImageDataGenerator()
    
    # Mask data generator
    mask_gen = ImageDataGenerator()

    # Generator for images
    img_gen = img_gen.flow_from_dataframe(
        dataframe=data_frame,
        x_col='img_path',
        class_mode=None,
        color_mode=image_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=image_save_prefix,
        seed=seed
    )

    # Generator for masks
    mask_gen = mask_gen.flow_from_dataframe(
        dataframe=data_frame,
        x_col='mask_path',
        class_mode=None,
        color_mode=mask_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=mask_save_prefix,
        seed=seed
    )

    # Combining the two generators
    combined_gen = zip(img_gen, mask_gen)

    for img, mask in combined_gen:
        yield normalize(img, mask)

EPOCHS = 35
BATCH_SIZE = 8
learning_rate = 1e-4
w, h = 600, 450  # target size for images, which should match the 'target_size' in your generators
train_gen = create_image_generator(train_df, batch_size=BATCH_SIZE, target_size=(w, h))
val_gen = create_image_generator(val_df, batch_size=BATCH_SIZE, target_size=(w, h))
test_gen = create_image_generator(test_df, batch_size=BATCH_SIZE, target_size=(w, h))

import tensorflow as tf
from tensorflow.keras import backend as K
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import layers, Model
from tensorflow.keras.layers import Input, SeparableConv2D, GroupNormalization, MaxPooling2D, Conv2DTranspose, Concatenate

# Disable Mixed Precision for CPU/GPU compatibility
tf.keras.mixed_precision.set_global_policy('float32')

# Enable XLA Compilation for faster execution
tf.config.optimizer.set_jit(True)

# Function to create a Double Convolution Block
def double_conv(x, n_filters):
    x = SeparableConv2D(n_filters, 3, padding='same', activation='relu')(x)
    x = SeparableConv2D(n_filters, 3, padding='same', activation='relu')(x)
    x = GroupNormalization(groups=8)(x)
    return x

# Encoder Block
def encoder_vit(x, n_filters):
    x = double_conv(x, n_filters)
    p = MaxPooling2D((2, 2))(x)
    return x, p

# Decoder Block with Skip Connections
def decoder(x, skip_connection, n_filters):
    x = Conv2DTranspose(n_filters, 3, strides=2, padding='same')(x)
    
    # Adjust skip connection size
    h_diff = skip_connection.shape[1] - x.shape[1]
    w_diff = skip_connection.shape[2] - x.shape[2]
    
    if h_diff != 0 or w_diff != 0:
        skip_connection = layers.Cropping2D(((h_diff // 2, h_diff - h_diff // 2),
                                             (w_diff // 2, w_diff - w_diff // 2)))(skip_connection)

    x = Concatenate()([x, skip_connection])
    x = double_conv(x, n_filters)
    return x

# VHU-Net Model
def VHU_Net_Model(input_shape):
    inputs = Input(input_shape)

    # Encoder path with reduced filters for faster training
    s1, p1 = encoder_vit(inputs, 16)
    s2, p2 = encoder_vit(p1, 32)
    s3, p3 = encoder_vit(p2, 64)
    s4, p4 = encoder_vit(p3, 128)  # Bottleneck

    # Bridge
    b = double_conv(p4, 128)

    # Decoder path
    b1 = decoder(b, s4, 64)
    b2 = decoder(b1, s3, 32)
    b3 = decoder(b2, s2, 16)
    b4 = decoder(b3, s1, 8)

    # Output Layer
    outputs = SeparableConv2D(1, 1, padding='same', activation='sigmoid')(b4)

    return Model(inputs, outputs, name='VHU-Net_Model')

# Dice Coefficient
def dice_coefficient(y_true, y_pred, smooth=100):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    return (2 * intersection + smooth) / (union + smooth)

# Dice Loss
def dice_loss(y_true, y_pred):
    return -dice_coefficient(y_true, y_pred)

# IoU Metric
def iou(y_true, y_pred, smooth=100):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_pred * y_true)
    union = K.sum(y_true) + K.sum(y_pred)  
    return (intersection + smooth) / (union - intersection + smooth)

# Optimized Dataset Loading
def load_dataset(path, batch_size):
    dataset = tf.keras.preprocessing.image_dataset_from_directory(
        path, image_size=(224, 224), batch_size=batch_size, label_mode='binary'
    )
    # Apply caching, shuffling, and prefetching
    dataset = dataset.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)
    return dataset

# Initialize Optimizer with JIT Compilation
optim = Adam(learning_rate=1e-3, jit_compile=True)

# Create Model
input_shape = (224, 224, 3)
model = VHU_Net_Model(input_shape)

# Compile Model with Optimized Execution
model.compile(optimizer=optim, loss=dice_loss, metrics=[iou, dice_coefficient], 
              steps_per_execution=5)  # Corrected

import tensorflow as tf
from tensorflow.keras import backend as K

# Dice Coefficient
def coefficient_dice(y_true, y_pred, smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    
    dice = (2 * intersection + smooth) / (union + smooth)
    return dice

# Dice Loss (Negative Dice Coefficient)
def dice_loss(y_true, y_pred):
    return -coefficient_dice(y_true, y_pred)

# Intersection over Union (IoU)
def iou(y_true, y_pred, smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    
    iou = (intersection + smooth) / (union - intersection + smooth)
    return iou

# IoU Loss (Negative IoU)
def iou_loss(y_true, y_pred):
    return -iou(y_true, y_pred)
def create_image_generator(data_frame, batch_size, image_color_mode, mask_color_mode, 
                           image_save_prefix, mask_save_prefix, save_to_dir, target_size, seed):
    # Check if columns exist
    if 'img_path' not in data_frame.columns or 'mask_path' not in data_frame.columns:
        raise ValueError("Columns 'img_path' and 'mask_path' not found in dataframe!")

    img_gen = ImageDataGenerator()
    mask_gen = ImageDataGenerator()

    # Generator for images
    img_gen = img_gen.flow_from_dataframe(
        dataframe=data_frame,
        x_col='img_path',  # Ensure this column exists
        class_mode=None,
        color_mode=image_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=image_save_prefix,
        seed=seed
    )

    # Generator for masks
    mask_gen = mask_gen.flow_from_dataframe(
        dataframe=data_frame,
        x_col='mask_path',  # Ensure this column exists
        class_mode=None,
        color_mode=mask_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=mask_save_prefix,
        seed=seed
    )

    return img_gen, mask_gen
import os
import pandas as pd
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
import math

# Define dataset paths
image_dir = "C:/dataset/skin/image"
mask_dir = "C:/dataset/skin/mask"

# Collect image and mask file paths
image_paths = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg'))]
mask_paths = [os.path.join(mask_dir, f) for f in os.listdir(mask_dir) if f.endswith(('.png', '.jpg'))]

# Create DataFrame
df = pd.DataFrame({'img_path': image_paths, 'mask_path': mask_paths})

# Split dataset into training and validation
train_df = df.sample(frac=0.8, random_state=42)
val_df = df.drop(train_df.index)

# Define batch size and epochs
BATCH_SIZE = 8
EPOCHS = 35

# Function to create ImageDataGenerator
def create_image_generator(data_frame, batch_size, image_color_mode, mask_color_mode, 
                           image_save_prefix, mask_save_prefix, save_to_dir, target_size, seed):

    img_gen = ImageDataGenerator(rescale=1./255)
    mask_gen = ImageDataGenerator(rescale=1./255)

    # Generator for images
    img_generator = img_gen.flow_from_dataframe(
        dataframe=data_frame,
        x_col='img_path',
        class_mode=None,
        color_mode=image_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=image_save_prefix,
        seed=seed
    )

    # Generator for masks
    mask_generator = mask_gen.flow_from_dataframe(
        dataframe=data_frame,
        x_col='mask_path',
        class_mode=None,
        color_mode=mask_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=mask_save_prefix,
        seed=seed
    )

    # Combine generators
    return zip(img_generator, mask_generator)

# Create data generators
train_gen = create_image_generator(train_df, BATCH_SIZE, 'rgb', 'grayscale', 
                                   'train_image', 'train_mask', None, (224, 224), 42)
val_gen = create_image_generator(val_df, BATCH_SIZE, 'rgb', 'grayscale', 
                                 'val_image', 'val_mask', None, (224, 224), 42)

# Calculate steps per epoch and validation steps
steps_per_epoch = math.ceil(len(train_df) / BATCH_SIZE)
val_steps = math.ceil(len(val_df) / BATCH_SIZE)

# Define model input shape
input_shape = (224, 224, 3)

# Load the VHU-Net model (Ensure the function VHU_Net_Model is defined in your code)
model = VHU_Net_Model(input_shape)

# Optimizer with JIT compilation for performance
optim = Adam(learning_rate=1e-3, jit_compile=True)

# Compile the model
model.compile(optimizer=optim, loss=dice_loss, metrics=[iou, dice_coefficient], 
              steps_per_execution=5)

# Train the model
history = model.fit(
    train_gen,  
    steps_per_epoch=steps_per_epoch,  
    validation_data=val_gen,  
    validation_steps=val_steps,  
    epochs=EPOCHS,  
    verbose=1  
)
import os
import numpy as np
import cv2
import matplotlib.pyplot as plt

# Function to load and preprocess a single image and mask
def load_image(image_path, mask_path, image_size=(256, 256), expand_factor=20):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    img = cv2.resize(img, image_size).astype(np.float32) / 255.0  # Normalize
    
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    mask = cv2.resize(mask, image_size).astype(np.uint8)
    
    # Apply Otsu's threshold to get kidney mask
    _, kidney_mask = cv2.threshold(mask, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    
    # Find bounding box of kidney mask
    coords = cv2.findNonZero(kidney_mask)
    x, y, w, h = cv2.boundingRect(coords)

    # Expand bounding box region
    x = max(0, x - expand_factor)
    y = max(0, y - expand_factor)
    w = min(image_size[0], x + w + expand_factor) - x
    h = min(image_size[1], y + h + expand_factor) - y

    # Extract expanded lesion region
    expanded_region = np.zeros_like(img)
    expanded_region[y:y+h, x:x+w] = img[y:y+h, x:x+w]

    # Extract tumor region
    tumor_mask = np.where(mask >= 128, 1, 0).astype(np.uint8)

    # Create fused image
    fused_image = np.stack([expanded_region]*3, axis=-1)
    fused_image[:, :, 0] = np.where(tumor_mask==1, 255, fused_image[:, :, 0])
    fused_image[:, :, 1] = np.where(tumor_mask==1, 255, fused_image[:, :, 1])
    fused_image[:, :, 2] = np.where(tumor_mask==1, 255, fused_image[:, :, 2])

    return img, expanded_region, mask, tumor_mask, fused_image

# Load dataset paths
image_path = r"E:\Dataset\segmenattaion\skin\image222\ISIC_0024306.jpg"
mask_path = r"E:\Dataset\segmenattaion\skin\Mask2222\ISIC_0024306_segmentation.png"

# Load images
X_img, Exp_region, Mask_img, Tumor_mask, Fused_img = load_image(image_path, mask_path)

# Function to display Skin Image and Segmented Lesion Region
def display_skin_and_region():
    plt.figure(figsize=(10, 5))
    
    plt.subplot(1, 2, 1)
    plt.imshow(X_img, cmap='gray')
    plt.title("Skin Image")
    
    plt.subplot(1, 2, 2)
    plt.imshow(Exp_region, cmap='gray')
    plt.title("Segmented Lesion Region")
    
    plt.show()
display_skin_and_region()
import matplotlib.pyplot as plt

# Extract training history
epochs = range(1, len(history.history['loss']) + 1)

# Plot Loss
plt.figure(figsize=(6, 4))
plt.plot(epochs, history.history['loss'], label='Train Loss')
plt.plot(epochs, history.history['val_loss'], label='Val Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss Over Epochs')
plt.legend()

plt.show()
import tensorflow as tf
from tensorflow.keras import layers, Model, Input
from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, Reshape, Multiply

# Criss-Cross Attention
def criss_cross_attention(x):
    avg_pool = GlobalAveragePooling2D()(x)
    avg_pool = Reshape((1, 1, x.shape[-1]))(avg_pool)
    avg_pool = Conv2D(x.shape[-1], 1, padding='same', activation='sigmoid')(avg_pool)
    return Multiply()([x, avg_pool])

# Define Encoder Block (Using a standard convolutional approach)
def encoder_block(x, filters):
    conv = Conv2D(filters, (3, 3), activation='relu', padding='same')(x)
    conv = Conv2D(filters, (3, 3), activation='relu', padding='same')(conv)
    return conv, layers.MaxPooling2D(pool_size=(2, 2))(conv)

# Define Decoder Block
def decoder_block(x, skip, filters):
    up = layers.UpSampling2D(size=(2, 2))(x)
    merge = layers.Concatenate()([up, skip])
    conv = Conv2D(filters, (3, 3), activation='relu', padding='same')(merge)
    conv = Conv2D(filters, (3, 3), activation='relu', padding='same')(conv)
    return conv

# Define ConD-PDN Model
def cond_pdn(input_shape=(256, 256, 1)):
    inputs = Input(input_shape)

    # Encoder
    s1, p1 = encoder_block(inputs, 64)
    s2, p2 = encoder_block(p1, 128)
    s3, p3 = encoder_block(p2, 256)
    s4, p4 = encoder_block(p3, 512)

    # Bridge with Criss-Cross Attention
    b = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)
    b = Conv2D(1024, (3, 3), activation='relu', padding='same')(b)
    b = criss_cross_attention(b)

    # Decoder
    d1 = decoder_block(b, s4, 512)
    d2 = decoder_block(d1, s3, 256)
    d3 = decoder_block(d2, s2, 128)
    d4 = decoder_block(d3, s1, 64)

    # Output Layer
    outputs = Conv2D(1, (1, 1), activation='sigmoid', padding='same')(d4)

    # Create Model
    model = Model(inputs, outputs, name='ConD_PDN_with_cca')

    return model

# **Dice Coefficient**
def Coffiecient_dice(y_true, y_pred, smooth=100):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    dice = (2 * intersection + smooth) / (union + smooth)
    return dice

# **Dice Loss**
def Dice_loss(y_true, y_pred):
    return -Coffiecient_dice(y_true, y_pred)

# **IoU Metric**
def Iou(y_true, y_pred, smooth=100):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_pred * y_true)
    union = K.sum(y_true) + K.sum(y_pred)  
    iou = (intersection + smooth) / (union - intersection + smooth)
    return iou

# Define learning rate
learning_rate = 1e-3  

# Initialize optimizer
optim = Adam(learning_rate=learning_rate)

# Compile the model
model.compile(optimizer=optim, loss=Dice_loss, metrics=[Iou, Coffiecient_dice])


import tensorflow as tf
from tensorflow.keras import backend as K

# Dice Coefficient
def coefficient_dice(y_true, y_pred, smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    
    dice = (2 * intersection + smooth) / (union + smooth)
    return dice

# Dice Loss (Negative Dice Coefficient)
def dice_loss(y_true, y_pred):
    return -coefficient_dice(y_true, y_pred)

# Intersection over Union (IoU)
def iou(y_true, y_pred, smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    
    iou = (intersection + smooth) / (union - intersection + smooth)
    return iou

# IoU Loss (Negative IoU)
def iou_loss(y_true, y_pred):
    return -iou(y_true, y_pred)

def create_image_generator(data_frame, batch_size, image_color_mode, mask_color_mode, 
                           image_save_prefix, mask_save_prefix, save_to_dir, target_size, seed):
    # Check if columns exist
    if 'img_path' not in data_frame.columns or 'mask_path' not in data_frame.columns:
        raise ValueError("Columns 'img_path' and 'mask_path' not found in dataframe!")

    img_gen = ImageDataGenerator()
    mask_gen = ImageDataGenerator()

    # Generator for images
    img_gen = img_gen.flow_from_dataframe(
        dataframe=data_frame,
        x_col='img_path',  # Ensure this column exists
        class_mode=None,
        color_mode=image_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=image_save_prefix,
        seed=seed
    )

    # Generator for masks
    mask_gen = mask_gen.flow_from_dataframe(
        dataframe=data_frame,
        x_col='mask_path',  # Ensure this column exists
        class_mode=None,
        color_mode=mask_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=mask_save_prefix,
        seed=seed
    )

    return img_gen, mask_gen

import math

# Calculate steps per epoch and validation steps
steps_per_epoch = math.ceil(len(train_df) / BATCH_SIZE)
val_steps = math.ceil(len(val_df) / BATCH_SIZE)

# Train the ConD-PDN Model
history = model.fit(
    train_gen,  # The generator for training data
    steps_per_epoch=steps_per_epoch,  # Number of steps per epoch
    validation_data=val_gen,  # The generator for validation data
    validation_steps=val_steps,  # Number of steps for validation
    epochs=EPOCHS,  # Number of epochs
    verbose=1  # Verbosity level of output
)
print(history.history.keys())
import matplotlib.pyplot as plt

# Extract training history
epochs = range(1, len(history.history['Coffiecient_dice']) + 1)

# Plot Dice Coefficient
plt.figure(figsize=(10, 4))
plt.subplot(1, 2, 1)
plt.plot(epochs, history.history['Coffiecient_dice'], label='Train Dice Coefficient')
plt.plot(epochs, history.history['val_Coffiecient_dice'], label='Val Dice Coefficient')
plt.xlabel('Epochs')
plt.ylabel('Dice Coefficient')
plt.title('Dice Coefficient Over Epochs')
plt.legend()

# Plot IoU
plt.subplot(1, 2, 2)
plt.plot(epochs, history.history['Iou'], label='Train IoU')
plt.plot(epochs, history.history['val_Iou'], label='Val IoU')
plt.xlabel('Epochs')
plt.ylabel('IoU Score')
plt.title('IoU Score Over Epochs')
plt.legend()

plt.tight_layout()
plt.show()
# Function to display Skin Lesion Mask and Segmented Lesion Mask Region
def display_masks():
    plt.figure(figsize=(10, 5))
    
    plt.subplot(1, 2, 1)
    plt.imshow(Mask_img, cmap='gray')
    plt.title("Skin Lesion Mask Image")
    
    plt.subplot(1, 2, 2)
    plt.imshow(Tumor_mask, cmap='gray')
    plt.title("Segmented Lesion Mask Region")
    
    plt.show()
display_masks()

import matplotlib.pyplot as plt

# Extract training history
epochs = range(1, len(history.history['loss']) + 1)

# Plot Loss
plt.figure(figsize=(6, 4))
plt.plot(epochs, history.history['loss'], label='Train Loss')
plt.plot(epochs, history.history['val_loss'], label='Val Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss Over Epochs')
plt.legend()

plt.show()
import tensorflow as tf
from tensorflow.keras import layers, Model, Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import backend as K

def fusion_net(input_shape=(256, 256, 1)):
    inputs = Input(input_shape)
    conv = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)
    conv = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv)
    output = layers.Conv2D(1, (1, 1), activation='sigmoid', padding='same')(conv)
    return Model(inputs=inputs, outputs=output, name="Fusion_Net")

# Function to fuse ConD-PDN and VHU-Net

def fuse_models(cond_pdn_model, vhu_net_model, input_shape=(256, 256, 1)):
    inputs = Input(input_shape)
    
    # Get outputs from both models
    cond_pdn_output = cond_pdn_model(inputs)
    vhu_net_output = vhu_net_model(inputs)
    
    # Fusion step: Averaging outputs
    fused_output = layers.Average()([cond_pdn_output, vhu_net_output])
    
    # Final output layer
    final_output = layers.Conv2D(1, (1, 1), activation='sigmoid', padding='same')(fused_output)
    
    return Model(inputs, final_output, name="Fused_ConD_VHU_Net")

# Instantiate models
input_shape = (256, 256, 1)
cond_pdn_model = cond_pdn(input_shape)
vhu_net_model = VHU_Net_Model(input_shape)

# Fuse the models
fused_model = fuse_models(cond_pdn_model, vhu_net_model, input_shape)

# Define Dice Loss and IoU

def Coffiecient_dice(y_true, y_pred, smooth=100):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    dice = (2 * intersection + smooth) / (union + smooth)
    return dice

def Dice_loss(y_true, y_pred):
    return -Coffiecient_dice(y_true, y_pred)

def Iou(y_true, y_pred, smooth=100):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    intersection = K.sum(y_pred * y_true)
    union = K.sum(y_true) + K.sum(y_pred)  
    iou = (intersection + smooth) / (union - intersection + smooth)
    return iou

# Compile fused model
learning_rate = 1e-3  
optim = Adam(learning_rate=learning_rate)
fused_model.compile(optimizer=optim, loss=Dice_loss, metrics=[Iou, Coffiecient_dice])

# Print model summary
fused_model.summary()
import tensorflow as tf
from tensorflow.keras import backend as K

# Dice Coefficient
def coefficient_dice(y_true, y_pred, smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    
    dice = (2 * intersection + smooth) / (union + smooth)
    return dice

# Dice Loss (Negative Dice Coefficient)
def dice_loss(y_true, y_pred):
    return -coefficient_dice(y_true, y_pred)

# Intersection over Union (IoU)
def iou(y_true, y_pred, smooth=1e-5):
    y_true = K.flatten(y_true)
    y_pred = K.flatten(y_pred)
    
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    
    iou = (intersection + smooth) / (union - intersection + smooth)
    return iou

# IoU Loss (Negative IoU)
def iou_loss(y_true, y_pred):
    return -iou(y_true, y_pred)

def create_image_generator(data_frame, batch_size, image_color_mode, mask_color_mode, 
                           image_save_prefix, mask_save_prefix, save_to_dir, target_size, seed):
    # Check if columns exist
    if 'img_path' not in data_frame.columns or 'mask_path' not in data_frame.columns:
        raise ValueError("Columns 'img_path' and 'mask_path' not found in dataframe!")

    img_gen = ImageDataGenerator()
    mask_gen = ImageDataGenerator()

    # Generator for images
    img_gen = img_gen.flow_from_dataframe(
        dataframe=data_frame,
        x_col='img_path',  # Ensure this column exists
        class_mode=None,
        color_mode=image_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=image_save_prefix,
        seed=seed
    )

    # Generator for masks
    mask_gen = mask_gen.flow_from_dataframe(
        dataframe=data_frame,
        x_col='mask_path',  # Ensure this column exists
        class_mode=None,
        color_mode=mask_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=mask_save_prefix,
        seed=seed
    )

    return img_gen, mask_gen
import math

# Calculate steps per epoch and validation steps
steps_per_epoch = math.ceil(len(train_df) / BATCH_SIZE)
val_steps = math.ceil(len(val_df) / BATCH_SIZE)

# Train the Fusion model
history = model.fit(
    train_gen,  # The generator for training data
    steps_per_epoch=steps_per_epoch,  # Number of steps per epoch
    validation_data=val_gen,  # The generator for validation data
    validation_steps=val_steps,  # Number of steps for validation
    epochs=EPOCHS,  # Number of epochs
    verbose=1  # Verbosity level of output
)
import matplotlib.pyplot as plt

# Extract training history
epochs = range(1, len(history.history['Coffiecient_dice']) + 1)

# Plot Dice Coefficient
plt.figure(figsize=(10, 4))
plt.subplot(1, 2, 1)
plt.plot(epochs, history.history['Coffiecient_dice'], label='Train Dice Coefficient')
plt.plot(epochs, history.history['val_Coffiecient_dice'], label='Val Dice Coefficient')
plt.xlabel('Epochs')
plt.ylabel('Dice Coefficient')
plt.title('Dice Coefficient Over Epochs')
plt.legend()

# Plot IoU
plt.subplot(1, 2, 2)
plt.plot(epochs, history.history['Iou'], label='Train IoU')
plt.plot(epochs, history.history['val_Iou'], label='Val IoU')
plt.xlabel('Epochs')
plt.ylabel('IoU Score')
plt.title('IoU Score Over Epochs')
plt.legend()

plt.tight_layout()
plt.show()
import matplotlib.pyplot as plt

# Extract training history
epochs = range(1, len(history.history['loss']) + 1)

# Plot Loss
plt.figure(figsize=(6, 4))
plt.plot(epochs, history.history['loss'], label='Train Loss')
plt.plot(epochs, history.history['val_loss'], label='Val Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss Over Epochs')
plt.legend()

plt.show()
# Function to display Fused Image
def display_fused_image():
    plt.figure(figsize=(5, 5))
    plt.imshow(Fused_img)  # RGB display
    plt.title("Fused Image")
    plt.axis('off')
    plt.show()

display_fused_image()
